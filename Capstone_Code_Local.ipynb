{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53F6wpODKPzL"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XZPkWE-B3_H"
      },
      "outputs": [],
      "source": [
        "# # install finrl library\n",
        "# !pip install wrds\n",
        "# !pip install swig\n",
        "# !pip install -q condacolab\n",
        "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMwr0aXFROYr"
      },
      "outputs": [],
      "source": [
        "# !pip install yfinance\n",
        "# !pip install edgartools\n",
        "# !pip install py-xbrl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pyu9g5SBc-UV"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "# matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import requests\n",
        "import json\n",
        "import random\n",
        "import cvxpy\n",
        "# from cvxpy import *\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import ParameterGrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwy0LWObB948",
        "outputId": "b811afc2-42d0-46cf-c4c4-40d54c6268a5"
      },
      "outputs": [],
      "source": [
        "# from finrl import config\n",
        "# from finrl import config_tickers\n",
        "# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "# from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "# from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "# from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "# from finrl.meta.data_processor import DataProcessor\n",
        "# from finrl.meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cdSFMr4umyK"
      },
      "source": [
        "# Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSMDU_bPtCJb"
      },
      "source": [
        "We decided to look at diversifying our portfolio constituents rather than specifically focusing on mining companies. We're going to look at the S&P 500 Dividend Aristocrats. This is an index of the S&P 500 constituents that have increased their dividend yearly for at least the last 25 years. As of today, 03/26/2024, there are 67 companies in this index. Note that this is not a point-in-time representation of the index. Rather, we're taking the current list of 67 constituents, and building our own index with these 67 diversified companies from a past start time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "QdJhOjh2ryo5",
        "outputId": "7de7d2dc-1bb8-458f-9089-cc994ec74d22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sector</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Consumer Discretionary</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Consumer Staples</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Energy</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Financials</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Health Care</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Industrials</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Information Technology</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Materials</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Real Estate</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Utilities</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOTAL</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Company\n",
              "Sector                         \n",
              "Consumer Discretionary        4\n",
              "Consumer Staples             15\n",
              "Energy                        2\n",
              "Financials                    7\n",
              "Health Care                   7\n",
              "Industrials                  15\n",
              "Information Technology        2\n",
              "Materials                     8\n",
              "Real Estate                   3\n",
              "Utilities                     3\n",
              "TOTAL                        66"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sp_da = pd.read_html('https://en.wikipedia.org/wiki/S%26P_500_Dividend_Aristocrats')[0]\n",
        "tickers = sp_da['Ticker symbol'].str.replace('.', '-').tolist()\n",
        "\n",
        "# View sector distribution\n",
        "sector_distribution = pd.DataFrame(sp_da.groupby(['Sector']).count()['Company'])\n",
        "\n",
        "sector_distribution.loc['TOTAL'] = sector_distribution.sum()\n",
        "\n",
        "sector_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CckdLT4pahCF"
      },
      "source": [
        "As of today, the dividend aristocrats include 67 companies in 10 sectors. This shows that diversification is feasible within that group of assets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "kN1_HQg5dnR4",
        "outputId": "13b3c288-021c-40d1-9380-44dc9a57e2f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[                       0%                       ]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[***                    6%                       ]  4 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[******                12%                       ]  8 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[********              17%                       ]  11 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********             18%                       ]  12 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********            20%                       ]  13 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[************          26%                       ]  17 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**************        29%                       ]  19 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**************        30%                       ]  20 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[***************       32%                       ]  21 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*****************     35%                       ]  23 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*****************     36%                       ]  24 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[********************* 44%                       ]  29 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************52%                       ]  34 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************55%*                      ]  36 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************58%***                    ]  38 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************59%***                    ]  39 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************61%****                   ]  40 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************62%*****                  ]  41 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************65%******                 ]  43 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************68%********               ]  45 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************70%*********              ]  46 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************71%*********              ]  47 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************76%***********            ]  50 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************77%************           ]  51 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************80%*************          ]  53 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************82%**************         ]  54 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************85%****************       ]  56 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************88%*****************      ]  58 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************89%******************     ]  59 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************92%*******************    ]  61 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[**********************97%********************** ]  64 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  66 of 66 completed"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\yfinance\\utils.py:718: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
            "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABBV</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AMCR</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>NaN</td>\n",
              "      <td>8.99</td>\n",
              "      <td>6.41</td>\n",
              "      <td>24.78</td>\n",
              "      <td>6.92</td>\n",
              "      <td>6.17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.33</td>\n",
              "      <td>17.21</td>\n",
              "      <td>8.03</td>\n",
              "      <td>...</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.56</td>\n",
              "      <td>18.91</td>\n",
              "      <td>15.58</td>\n",
              "      <td>10.29</td>\n",
              "      <td>22.67</td>\n",
              "      <td>9.41</td>\n",
              "      <td>14.47</td>\n",
              "      <td>5.43</td>\n",
              "      <td>18.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>NaN</td>\n",
              "      <td>8.74</td>\n",
              "      <td>6.35</td>\n",
              "      <td>24.78</td>\n",
              "      <td>6.73</td>\n",
              "      <td>6.17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.30</td>\n",
              "      <td>16.69</td>\n",
              "      <td>7.83</td>\n",
              "      <td>...</td>\n",
              "      <td>4.43</td>\n",
              "      <td>9.44</td>\n",
              "      <td>18.04</td>\n",
              "      <td>15.24</td>\n",
              "      <td>9.97</td>\n",
              "      <td>21.69</td>\n",
              "      <td>9.13</td>\n",
              "      <td>13.93</td>\n",
              "      <td>5.48</td>\n",
              "      <td>17.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>NaN</td>\n",
              "      <td>8.72</td>\n",
              "      <td>6.25</td>\n",
              "      <td>24.54</td>\n",
              "      <td>6.70</td>\n",
              "      <td>6.28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.29</td>\n",
              "      <td>16.79</td>\n",
              "      <td>8.08</td>\n",
              "      <td>...</td>\n",
              "      <td>4.44</td>\n",
              "      <td>9.37</td>\n",
              "      <td>17.80</td>\n",
              "      <td>15.04</td>\n",
              "      <td>10.09</td>\n",
              "      <td>21.20</td>\n",
              "      <td>9.11</td>\n",
              "      <td>13.64</td>\n",
              "      <td>5.46</td>\n",
              "      <td>18.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>NaN</td>\n",
              "      <td>9.02</td>\n",
              "      <td>6.28</td>\n",
              "      <td>24.87</td>\n",
              "      <td>6.83</td>\n",
              "      <td>6.49</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.26</td>\n",
              "      <td>17.90</td>\n",
              "      <td>7.96</td>\n",
              "      <td>...</td>\n",
              "      <td>4.51</td>\n",
              "      <td>9.56</td>\n",
              "      <td>17.31</td>\n",
              "      <td>14.97</td>\n",
              "      <td>10.51</td>\n",
              "      <td>20.19</td>\n",
              "      <td>9.38</td>\n",
              "      <td>13.79</td>\n",
              "      <td>5.40</td>\n",
              "      <td>19.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>NaN</td>\n",
              "      <td>9.12</td>\n",
              "      <td>6.38</td>\n",
              "      <td>25.44</td>\n",
              "      <td>6.97</td>\n",
              "      <td>6.39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.35</td>\n",
              "      <td>19.15</td>\n",
              "      <td>8.03</td>\n",
              "      <td>...</td>\n",
              "      <td>4.46</td>\n",
              "      <td>9.62</td>\n",
              "      <td>17.47</td>\n",
              "      <td>15.24</td>\n",
              "      <td>10.53</td>\n",
              "      <td>21.24</td>\n",
              "      <td>9.31</td>\n",
              "      <td>14.83</td>\n",
              "      <td>5.46</td>\n",
              "      <td>19.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-01</th>\n",
              "      <td>179.09</td>\n",
              "      <td>111.54</td>\n",
              "      <td>62.35</td>\n",
              "      <td>245.31</td>\n",
              "      <td>85.19</td>\n",
              "      <td>129.18</td>\n",
              "      <td>9.45</td>\n",
              "      <td>88.74</td>\n",
              "      <td>243.42</td>\n",
              "      <td>117.85</td>\n",
              "      <td>...</td>\n",
              "      <td>338.16</td>\n",
              "      <td>124.73</td>\n",
              "      <td>427.09</td>\n",
              "      <td>95.46</td>\n",
              "      <td>80.07</td>\n",
              "      <td>177.82</td>\n",
              "      <td>120.30</td>\n",
              "      <td>60.00</td>\n",
              "      <td>395.73</td>\n",
              "      <td>116.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-02</th>\n",
              "      <td>179.02</td>\n",
              "      <td>111.47</td>\n",
              "      <td>62.70</td>\n",
              "      <td>247.66</td>\n",
              "      <td>84.93</td>\n",
              "      <td>126.48</td>\n",
              "      <td>9.31</td>\n",
              "      <td>88.21</td>\n",
              "      <td>239.84</td>\n",
              "      <td>117.77</td>\n",
              "      <td>...</td>\n",
              "      <td>333.96</td>\n",
              "      <td>123.06</td>\n",
              "      <td>426.11</td>\n",
              "      <td>94.49</td>\n",
              "      <td>79.93</td>\n",
              "      <td>176.24</td>\n",
              "      <td>118.55</td>\n",
              "      <td>59.16</td>\n",
              "      <td>387.69</td>\n",
              "      <td>119.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-03</th>\n",
              "      <td>175.69</td>\n",
              "      <td>110.73</td>\n",
              "      <td>62.65</td>\n",
              "      <td>245.13</td>\n",
              "      <td>85.18</td>\n",
              "      <td>128.87</td>\n",
              "      <td>9.18</td>\n",
              "      <td>88.31</td>\n",
              "      <td>239.60</td>\n",
              "      <td>116.97</td>\n",
              "      <td>...</td>\n",
              "      <td>334.29</td>\n",
              "      <td>119.52</td>\n",
              "      <td>426.46</td>\n",
              "      <td>96.24</td>\n",
              "      <td>79.45</td>\n",
              "      <td>175.49</td>\n",
              "      <td>118.49</td>\n",
              "      <td>59.43</td>\n",
              "      <td>386.94</td>\n",
              "      <td>119.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-04</th>\n",
              "      <td>166.35</td>\n",
              "      <td>109.57</td>\n",
              "      <td>63.24</td>\n",
              "      <td>241.49</td>\n",
              "      <td>84.36</td>\n",
              "      <td>121.12</td>\n",
              "      <td>9.17</td>\n",
              "      <td>86.80</td>\n",
              "      <td>237.11</td>\n",
              "      <td>116.13</td>\n",
              "      <td>...</td>\n",
              "      <td>329.86</td>\n",
              "      <td>118.79</td>\n",
              "      <td>428.42</td>\n",
              "      <td>94.94</td>\n",
              "      <td>76.55</td>\n",
              "      <td>172.22</td>\n",
              "      <td>116.26</td>\n",
              "      <td>59.50</td>\n",
              "      <td>385.91</td>\n",
              "      <td>119.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-05</th>\n",
              "      <td>168.43</td>\n",
              "      <td>110.65</td>\n",
              "      <td>63.46</td>\n",
              "      <td>244.85</td>\n",
              "      <td>85.42</td>\n",
              "      <td>123.45</td>\n",
              "      <td>9.21</td>\n",
              "      <td>87.20</td>\n",
              "      <td>238.68</td>\n",
              "      <td>116.23</td>\n",
              "      <td>...</td>\n",
              "      <td>331.85</td>\n",
              "      <td>117.22</td>\n",
              "      <td>431.59</td>\n",
              "      <td>95.41</td>\n",
              "      <td>76.67</td>\n",
              "      <td>171.77</td>\n",
              "      <td>116.64</td>\n",
              "      <td>59.85</td>\n",
              "      <td>393.82</td>\n",
              "      <td>121.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6103 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ABBV    ABT   ADM    ADP   AFL    ALB  AMCR   AOS    APD    ATO  \\\n",
              "Date                                                                           \n",
              "2000-01-03    NaN   8.99  6.41  24.78  6.92   6.17   NaN  2.33  17.21   8.03   \n",
              "2000-01-04    NaN   8.74  6.35  24.78  6.73   6.17   NaN  2.30  16.69   7.83   \n",
              "2000-01-05    NaN   8.72  6.25  24.54  6.70   6.28   NaN  2.29  16.79   8.08   \n",
              "2000-01-06    NaN   9.02  6.28  24.87  6.83   6.49   NaN  2.26  17.90   7.96   \n",
              "2000-01-07    NaN   9.12  6.38  25.44  6.97   6.39   NaN  2.35  19.15   8.03   \n",
              "...           ...    ...   ...    ...   ...    ...   ...   ...    ...    ...   \n",
              "2024-04-01 179.09 111.54 62.35 245.31 85.19 129.18  9.45 88.74 243.42 117.85   \n",
              "2024-04-02 179.02 111.47 62.70 247.66 84.93 126.48  9.31 88.21 239.84 117.77   \n",
              "2024-04-03 175.69 110.73 62.65 245.13 85.18 128.87  9.18 88.31 239.60 116.97   \n",
              "2024-04-04 166.35 109.57 63.24 241.49 84.36 121.12  9.17 86.80 237.11 116.13   \n",
              "2024-04-05 168.43 110.65 63.46 244.85 85.42 123.45  9.21 87.20 238.68 116.23   \n",
              "\n",
              "            ...    SHW    SJM   SPGI   SWK   SYY    TGT   TROW   WMT    WST  \\\n",
              "Date        ...                                                               \n",
              "2000-01-03  ...   4.60   9.56  18.91 15.58 10.29  22.67   9.41 14.47   5.43   \n",
              "2000-01-04  ...   4.43   9.44  18.04 15.24  9.97  21.69   9.13 13.93   5.48   \n",
              "2000-01-05  ...   4.44   9.37  17.80 15.04 10.09  21.20   9.11 13.64   5.46   \n",
              "2000-01-06  ...   4.51   9.56  17.31 14.97 10.51  20.19   9.38 13.79   5.40   \n",
              "2000-01-07  ...   4.46   9.62  17.47 15.24 10.53  21.24   9.31 14.83   5.46   \n",
              "...         ...    ...    ...    ...   ...   ...    ...    ...   ...    ...   \n",
              "2024-04-01  ... 338.16 124.73 427.09 95.46 80.07 177.82 120.30 60.00 395.73   \n",
              "2024-04-02  ... 333.96 123.06 426.11 94.49 79.93 176.24 118.55 59.16 387.69   \n",
              "2024-04-03  ... 334.29 119.52 426.46 96.24 79.45 175.49 118.49 59.43 386.94   \n",
              "2024-04-04  ... 329.86 118.79 428.42 94.94 76.55 172.22 116.26 59.50 385.91   \n",
              "2024-04-05  ... 331.85 117.22 431.59 95.41 76.67 171.77 116.64 59.85 393.82   \n",
              "\n",
              "              XOM  \n",
              "Date               \n",
              "2000-01-03  18.33  \n",
              "2000-01-04  17.98  \n",
              "2000-01-05  18.96  \n",
              "2000-01-06  19.94  \n",
              "2000-01-07  19.88  \n",
              "...           ...  \n",
              "2024-04-01 116.99  \n",
              "2024-04-02 119.28  \n",
              "2024-04-03 119.30  \n",
              "2024-04-04 119.72  \n",
              "2024-04-05 121.37  \n",
              "\n",
              "[6103 rows x 66 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_date = \"2000-01-01\"\n",
        "end_date = \"2024-04-07\"\n",
        "\n",
        "data = yf.download(\n",
        "    tickers,\n",
        "    start=start_date,\n",
        "    end=end_date,\n",
        "    auto_adjust=True)['Close']\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxqDRtE7ugAD"
      },
      "source": [
        "et's try to identify start and end dates for each of these constituents to determine if we feel like there's enough data for each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxTMWoQDvNe"
      },
      "outputs": [],
      "source": [
        "# Plot the time series for each ticker\n",
        "fig, ax = plt.subplots(figsize=(18, 12))  # Increase figure size for better readability\n",
        "for ticker in data.columns:\n",
        "  ax.plot(data.index, data[ticker], label=ticker)\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Closing Price')\n",
        "ax.set_title('Closing Prices Over Time')\n",
        "ax.legend()\n",
        "\n",
        "# Rotating the x-axis label to make them more readable\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "# plt.s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "HyZ5i0MNvjRn",
        "outputId": "9f96cfcf-f033-43e8-87d3-81aec9a032bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Start Date</th>\n",
              "      <th>End Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KVUE</th>\n",
              "      <td>2023-05-04</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ABBV</th>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMCR</th>\n",
              "      <td>2012-05-15</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IBM</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ITW</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ESS</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EXPD</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAST</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FRT</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-04-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Start Date   End Date\n",
              "KVUE 2023-05-04 2024-04-05\n",
              "ABBV 2013-01-02 2024-04-05\n",
              "AMCR 2012-05-15 2024-04-05\n",
              "IBM  2000-01-03 2024-04-05\n",
              "ITW  2000-01-03 2024-04-05\n",
              "...         ...        ...\n",
              "ESS  2000-01-03 2024-04-05\n",
              "EXPD 2000-01-03 2024-04-05\n",
              "FAST 2000-01-03 2024-04-05\n",
              "FRT  2000-01-03 2024-04-05\n",
              "XOM  2000-01-03 2024-04-05\n",
              "\n",
              "[66 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price_date_range = pd.DataFrame()\n",
        "price_date_range['Start Date'] = data.apply(lambda x:x.first_valid_index())\n",
        "price_date_range['End Date'] = data.apply(lambda x:x.last_valid_index())\n",
        "\n",
        "price_date_range.sort_values(by='Start Date', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHdfAzhClOt-"
      },
      "source": [
        "Count how many tickers don't have data available until the end of the period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quJIKPkcwN0S",
        "outputId": "4527c2f3-6826-4661-e112-f54968c6622c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# any tickers that get dropped before the current EndDate\n",
        "data.iloc[-1].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OdLyitMgp7v"
      },
      "source": [
        "Drop all tickers that start later than 2000-01-03 or have no data until the end of the period. Update `tickers` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Qab7CyOcwL4X",
        "outputId": "bac0b714-8990-4e83-f409-30a256584bf8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>8.99</td>\n",
              "      <td>6.41</td>\n",
              "      <td>24.78</td>\n",
              "      <td>6.92</td>\n",
              "      <td>6.17</td>\n",
              "      <td>2.33</td>\n",
              "      <td>17.21</td>\n",
              "      <td>8.03</td>\n",
              "      <td>17.60</td>\n",
              "      <td>5.68</td>\n",
              "      <td>...</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.56</td>\n",
              "      <td>18.91</td>\n",
              "      <td>15.58</td>\n",
              "      <td>10.29</td>\n",
              "      <td>22.67</td>\n",
              "      <td>9.41</td>\n",
              "      <td>14.47</td>\n",
              "      <td>5.43</td>\n",
              "      <td>18.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>8.74</td>\n",
              "      <td>6.35</td>\n",
              "      <td>24.78</td>\n",
              "      <td>6.73</td>\n",
              "      <td>6.17</td>\n",
              "      <td>2.30</td>\n",
              "      <td>16.69</td>\n",
              "      <td>7.83</td>\n",
              "      <td>17.14</td>\n",
              "      <td>5.58</td>\n",
              "      <td>...</td>\n",
              "      <td>4.43</td>\n",
              "      <td>9.44</td>\n",
              "      <td>18.04</td>\n",
              "      <td>15.24</td>\n",
              "      <td>9.97</td>\n",
              "      <td>21.69</td>\n",
              "      <td>9.13</td>\n",
              "      <td>13.93</td>\n",
              "      <td>5.48</td>\n",
              "      <td>17.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>8.72</td>\n",
              "      <td>6.25</td>\n",
              "      <td>24.54</td>\n",
              "      <td>6.70</td>\n",
              "      <td>6.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>16.79</td>\n",
              "      <td>8.08</td>\n",
              "      <td>17.26</td>\n",
              "      <td>5.67</td>\n",
              "      <td>...</td>\n",
              "      <td>4.44</td>\n",
              "      <td>9.37</td>\n",
              "      <td>17.80</td>\n",
              "      <td>15.04</td>\n",
              "      <td>10.09</td>\n",
              "      <td>21.20</td>\n",
              "      <td>9.11</td>\n",
              "      <td>13.64</td>\n",
              "      <td>5.46</td>\n",
              "      <td>18.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>9.02</td>\n",
              "      <td>6.28</td>\n",
              "      <td>24.87</td>\n",
              "      <td>6.83</td>\n",
              "      <td>6.49</td>\n",
              "      <td>2.26</td>\n",
              "      <td>17.90</td>\n",
              "      <td>7.96</td>\n",
              "      <td>17.98</td>\n",
              "      <td>6.01</td>\n",
              "      <td>...</td>\n",
              "      <td>4.51</td>\n",
              "      <td>9.56</td>\n",
              "      <td>17.31</td>\n",
              "      <td>14.97</td>\n",
              "      <td>10.51</td>\n",
              "      <td>20.19</td>\n",
              "      <td>9.38</td>\n",
              "      <td>13.79</td>\n",
              "      <td>5.40</td>\n",
              "      <td>19.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>9.12</td>\n",
              "      <td>6.38</td>\n",
              "      <td>25.44</td>\n",
              "      <td>6.97</td>\n",
              "      <td>6.39</td>\n",
              "      <td>2.35</td>\n",
              "      <td>19.15</td>\n",
              "      <td>8.03</td>\n",
              "      <td>18.98</td>\n",
              "      <td>6.06</td>\n",
              "      <td>...</td>\n",
              "      <td>4.46</td>\n",
              "      <td>9.62</td>\n",
              "      <td>17.47</td>\n",
              "      <td>15.24</td>\n",
              "      <td>10.53</td>\n",
              "      <td>21.24</td>\n",
              "      <td>9.31</td>\n",
              "      <td>14.83</td>\n",
              "      <td>5.46</td>\n",
              "      <td>19.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-01</th>\n",
              "      <td>111.54</td>\n",
              "      <td>62.35</td>\n",
              "      <td>245.31</td>\n",
              "      <td>85.19</td>\n",
              "      <td>129.18</td>\n",
              "      <td>88.74</td>\n",
              "      <td>243.42</td>\n",
              "      <td>117.85</td>\n",
              "      <td>244.05</td>\n",
              "      <td>27.62</td>\n",
              "      <td>...</td>\n",
              "      <td>338.16</td>\n",
              "      <td>124.73</td>\n",
              "      <td>427.09</td>\n",
              "      <td>95.46</td>\n",
              "      <td>80.07</td>\n",
              "      <td>177.82</td>\n",
              "      <td>120.30</td>\n",
              "      <td>60.00</td>\n",
              "      <td>395.73</td>\n",
              "      <td>116.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-02</th>\n",
              "      <td>111.47</td>\n",
              "      <td>62.70</td>\n",
              "      <td>247.66</td>\n",
              "      <td>84.93</td>\n",
              "      <td>126.48</td>\n",
              "      <td>88.21</td>\n",
              "      <td>239.84</td>\n",
              "      <td>117.77</td>\n",
              "      <td>241.02</td>\n",
              "      <td>27.28</td>\n",
              "      <td>...</td>\n",
              "      <td>333.96</td>\n",
              "      <td>123.06</td>\n",
              "      <td>426.11</td>\n",
              "      <td>94.49</td>\n",
              "      <td>79.93</td>\n",
              "      <td>176.24</td>\n",
              "      <td>118.55</td>\n",
              "      <td>59.16</td>\n",
              "      <td>387.69</td>\n",
              "      <td>119.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-03</th>\n",
              "      <td>110.73</td>\n",
              "      <td>62.65</td>\n",
              "      <td>245.13</td>\n",
              "      <td>85.18</td>\n",
              "      <td>128.87</td>\n",
              "      <td>88.31</td>\n",
              "      <td>239.60</td>\n",
              "      <td>116.97</td>\n",
              "      <td>243.59</td>\n",
              "      <td>27.50</td>\n",
              "      <td>...</td>\n",
              "      <td>334.29</td>\n",
              "      <td>119.52</td>\n",
              "      <td>426.46</td>\n",
              "      <td>96.24</td>\n",
              "      <td>79.45</td>\n",
              "      <td>175.49</td>\n",
              "      <td>118.49</td>\n",
              "      <td>59.43</td>\n",
              "      <td>386.94</td>\n",
              "      <td>119.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-04</th>\n",
              "      <td>109.57</td>\n",
              "      <td>63.24</td>\n",
              "      <td>241.49</td>\n",
              "      <td>84.36</td>\n",
              "      <td>121.12</td>\n",
              "      <td>86.80</td>\n",
              "      <td>237.11</td>\n",
              "      <td>116.13</td>\n",
              "      <td>243.05</td>\n",
              "      <td>27.20</td>\n",
              "      <td>...</td>\n",
              "      <td>329.86</td>\n",
              "      <td>118.79</td>\n",
              "      <td>428.42</td>\n",
              "      <td>94.94</td>\n",
              "      <td>76.55</td>\n",
              "      <td>172.22</td>\n",
              "      <td>116.26</td>\n",
              "      <td>59.50</td>\n",
              "      <td>385.91</td>\n",
              "      <td>119.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-05</th>\n",
              "      <td>110.65</td>\n",
              "      <td>63.46</td>\n",
              "      <td>244.85</td>\n",
              "      <td>85.42</td>\n",
              "      <td>123.45</td>\n",
              "      <td>87.20</td>\n",
              "      <td>238.68</td>\n",
              "      <td>116.23</td>\n",
              "      <td>246.17</td>\n",
              "      <td>27.05</td>\n",
              "      <td>...</td>\n",
              "      <td>331.85</td>\n",
              "      <td>117.22</td>\n",
              "      <td>431.59</td>\n",
              "      <td>95.41</td>\n",
              "      <td>76.67</td>\n",
              "      <td>171.77</td>\n",
              "      <td>116.64</td>\n",
              "      <td>59.85</td>\n",
              "      <td>393.82</td>\n",
              "      <td>121.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6103 rows × 63 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ABT   ADM    ADP   AFL    ALB   AOS    APD    ATO    BDX   BEN  \\\n",
              "Date                                                                           \n",
              "2000-01-03   8.99  6.41  24.78  6.92   6.17  2.33  17.21   8.03  17.60  5.68   \n",
              "2000-01-04   8.74  6.35  24.78  6.73   6.17  2.30  16.69   7.83  17.14  5.58   \n",
              "2000-01-05   8.72  6.25  24.54  6.70   6.28  2.29  16.79   8.08  17.26  5.67   \n",
              "2000-01-06   9.02  6.28  24.87  6.83   6.49  2.26  17.90   7.96  17.98  6.01   \n",
              "2000-01-07   9.12  6.38  25.44  6.97   6.39  2.35  19.15   8.03  18.98  6.06   \n",
              "...           ...   ...    ...   ...    ...   ...    ...    ...    ...   ...   \n",
              "2024-04-01 111.54 62.35 245.31 85.19 129.18 88.74 243.42 117.85 244.05 27.62   \n",
              "2024-04-02 111.47 62.70 247.66 84.93 126.48 88.21 239.84 117.77 241.02 27.28   \n",
              "2024-04-03 110.73 62.65 245.13 85.18 128.87 88.31 239.60 116.97 243.59 27.50   \n",
              "2024-04-04 109.57 63.24 241.49 84.36 121.12 86.80 237.11 116.13 243.05 27.20   \n",
              "2024-04-05 110.65 63.46 244.85 85.42 123.45 87.20 238.68 116.23 246.17 27.05   \n",
              "\n",
              "            ...    SHW    SJM   SPGI   SWK   SYY    TGT   TROW   WMT    WST  \\\n",
              "Date        ...                                                               \n",
              "2000-01-03  ...   4.60   9.56  18.91 15.58 10.29  22.67   9.41 14.47   5.43   \n",
              "2000-01-04  ...   4.43   9.44  18.04 15.24  9.97  21.69   9.13 13.93   5.48   \n",
              "2000-01-05  ...   4.44   9.37  17.80 15.04 10.09  21.20   9.11 13.64   5.46   \n",
              "2000-01-06  ...   4.51   9.56  17.31 14.97 10.51  20.19   9.38 13.79   5.40   \n",
              "2000-01-07  ...   4.46   9.62  17.47 15.24 10.53  21.24   9.31 14.83   5.46   \n",
              "...         ...    ...    ...    ...   ...   ...    ...    ...   ...    ...   \n",
              "2024-04-01  ... 338.16 124.73 427.09 95.46 80.07 177.82 120.30 60.00 395.73   \n",
              "2024-04-02  ... 333.96 123.06 426.11 94.49 79.93 176.24 118.55 59.16 387.69   \n",
              "2024-04-03  ... 334.29 119.52 426.46 96.24 79.45 175.49 118.49 59.43 386.94   \n",
              "2024-04-04  ... 329.86 118.79 428.42 94.94 76.55 172.22 116.26 59.50 385.91   \n",
              "2024-04-05  ... 331.85 117.22 431.59 95.41 76.67 171.77 116.64 59.85 393.82   \n",
              "\n",
              "              XOM  \n",
              "Date               \n",
              "2000-01-03  18.33  \n",
              "2000-01-04  17.98  \n",
              "2000-01-05  18.96  \n",
              "2000-01-06  19.94  \n",
              "2000-01-07  19.88  \n",
              "...           ...  \n",
              "2024-04-01 116.99  \n",
              "2024-04-02 119.28  \n",
              "2024-04-03 119.30  \n",
              "2024-04-04 119.72  \n",
              "2024-04-05 121.37  \n",
              "\n",
              "[6103 rows x 63 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data.loc[:, data.iloc[-1].notnull() & data.iloc[0].notnull()]\n",
        "tickers = list(data.columns)\n",
        "\n",
        "data # should be 64 columns now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ECpGSdeGwqm9",
        "outputId": "3bdea23d-df55-4e28-b1b3-2e7dc081ce5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-10</th>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-01</th>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-02</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-03</th>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-04</th>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-05</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6102 rows × 63 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ABT   ADM   ADP   AFL   ALB   AOS   APD   ATO   BDX   BEN  ...  \\\n",
              "Date                                                                    ...   \n",
              "2000-01-04 -0.03 -0.01  0.00 -0.03  0.00 -0.01 -0.03 -0.03 -0.03 -0.02  ...   \n",
              "2000-01-05 -0.00 -0.02 -0.01 -0.01  0.02 -0.00  0.01  0.03  0.01  0.02  ...   \n",
              "2000-01-06  0.03  0.01  0.01  0.02  0.03 -0.01  0.06 -0.02  0.04  0.06  ...   \n",
              "2000-01-07  0.01  0.02  0.02  0.02 -0.02  0.04  0.07  0.01  0.05  0.01  ...   \n",
              "2000-01-10 -0.01  0.00  0.02 -0.06 -0.00  0.01 -0.06 -0.01 -0.02  0.01  ...   \n",
              "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
              "2024-04-01 -0.01 -0.01 -0.02 -0.01 -0.02 -0.00  0.00 -0.01 -0.01 -0.02  ...   \n",
              "2024-04-02 -0.00  0.01  0.01 -0.00 -0.02 -0.01 -0.01 -0.00 -0.01 -0.01  ...   \n",
              "2024-04-03 -0.01 -0.00 -0.01  0.00  0.02  0.00 -0.00 -0.01  0.01  0.01  ...   \n",
              "2024-04-04 -0.01  0.01 -0.01 -0.01 -0.06 -0.02 -0.01 -0.01 -0.00 -0.01  ...   \n",
              "2024-04-05  0.01  0.00  0.01  0.01  0.02  0.00  0.01  0.00  0.01 -0.01  ...   \n",
              "\n",
              "             SHW   SJM  SPGI   SWK   SYY   TGT  TROW   WMT   WST   XOM  \n",
              "Date                                                                    \n",
              "2000-01-04 -0.04 -0.01 -0.05 -0.02 -0.03 -0.04 -0.03 -0.04  0.01 -0.02  \n",
              "2000-01-05  0.00 -0.01 -0.01 -0.01  0.01 -0.02 -0.00 -0.02 -0.00  0.05  \n",
              "2000-01-06  0.02  0.02 -0.03 -0.00  0.04 -0.05  0.03  0.01 -0.01  0.05  \n",
              "2000-01-07 -0.01  0.01  0.01  0.02  0.00  0.05 -0.01  0.07  0.01 -0.00  \n",
              "2000-01-10 -0.02 -0.01  0.07 -0.01  0.00 -0.02  0.01 -0.02  0.02 -0.01  \n",
              "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "2024-04-01 -0.03 -0.01  0.00 -0.03 -0.01  0.00 -0.01 -0.00  0.00  0.01  \n",
              "2024-04-02 -0.01 -0.01 -0.00 -0.01 -0.00 -0.01 -0.01 -0.01 -0.02  0.02  \n",
              "2024-04-03  0.00 -0.03  0.00  0.02 -0.01 -0.00 -0.00  0.00 -0.00  0.00  \n",
              "2024-04-04 -0.01 -0.01  0.00 -0.01 -0.04 -0.02 -0.02  0.00 -0.00  0.00  \n",
              "2024-04-05  0.01 -0.01  0.01  0.00  0.00 -0.00  0.00  0.01  0.02  0.01  \n",
              "\n",
              "[6102 rows x 63 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's turn prices into log returns\n",
        "rets = np.log(data).diff()\n",
        "rets = rets.dropna()\n",
        "rets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmisfT6Eg8Km"
      },
      "source": [
        "# Include additional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Yt7WBL3v_e2L",
        "outputId": "d52b0ac3-18e1-4728-946d-12b8e97f955c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>level_1</th>\n",
              "      <th>ret</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>ABT</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>ADM</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>ADP</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>AFL</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>ALB</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date level_1   ret\n",
              "0 2000-01-04     ABT -0.03\n",
              "1 2000-01-04     ADM -0.01\n",
              "2 2000-01-04     ADP  0.00\n",
              "3 2000-01-04     AFL -0.03\n",
              "4 2000-01-04     ALB  0.00"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# first need to pivot the rets df\n",
        "rets_long = pd.DataFrame(rets.stack())\n",
        "rets_long = rets_long.reset_index()\n",
        "rets_long = rets_long.rename(columns={0: 'ret'})\n",
        "rets_long.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRXgsZfT0OJW"
      },
      "source": [
        "## Fundamentals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6rbC6f2ZkhOg"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/My Drive/CapstoneProject/data/fundamental\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kLEeh0fNbA8z"
      },
      "outputs": [],
      "source": [
        "# dividend yield = dividends per share/current share price --> dividendPayout and commonStockSharesOutstanding and price from yfinance\n",
        "# payout ratio = total dividends / net income --> dividendPayout and netIncome\n",
        "# operating cash flow ratio = operating cash flow / net revenue --> operatingCashflow and totalRevenue and costOfRevenue\n",
        "# return on assets = net income / total assets --> netIncome and totalAssets\n",
        "# net profit margin = net income / revenue --> netIncome and totalRevenue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "XoTkyzwXqAow",
        "outputId": "9cb67c4d-082f-48c6-9492-a84f283509ad"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/CapstoneProject/data/fundamental/IncomeStatement/MMM_IS.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# let's look at a few tickers first before we try to combine everything\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMMM\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m income_statement \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroot_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/IncomeStatement/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtic\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_IS.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m balance_sheet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/BalanceSheet/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_BS.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m cash_flow \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/CashFlow/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_CF.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/CapstoneProject/data/fundamental/IncomeStatement/MMM_IS.csv'"
          ]
        }
      ],
      "source": [
        "# let's look at a few tickers first before we try to combine everything\n",
        "tic = 'MMM'\n",
        "income_statement = pd.read_csv(f'{root_dir}/IncomeStatement/{tic}_IS.csv')\n",
        "balance_sheet = pd.read_csv(f'{root_dir}/BalanceSheet/{tic}_BS.csv')\n",
        "cash_flow = pd.read_csv(f'{root_dir}/CashFlow/{tic}_CF.csv')\n",
        "df = pd.merge(income_statement, balance_sheet, on='fiscalDateEnding', how='outer').merge(cash_flow, on='fiscalDateEnding', how='outer')\n",
        "df = df.sort_values('fiscalDateEnding')\n",
        "df.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "3cx3YVE7vEET",
        "outputId": "c33decb0-dcfc-47cd-9257-04d01eb9b00d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bec01244-8343-4edf-ba07-6e87e5a465b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fiscalDateEnding</th>\n",
              "      <th>grossProfit</th>\n",
              "      <th>totalRevenue</th>\n",
              "      <th>costOfRevenue</th>\n",
              "      <th>costofGoodsAndServicesSold</th>\n",
              "      <th>operatingIncome</th>\n",
              "      <th>sellingGeneralAndAdministrative</th>\n",
              "      <th>researchAndDevelopment</th>\n",
              "      <th>operatingExpenses</th>\n",
              "      <th>investmentIncomeNet</th>\n",
              "      <th>...</th>\n",
              "      <th>dividendPayoutCommonStock</th>\n",
              "      <th>dividendPayoutPreferredStock</th>\n",
              "      <th>proceedsFromIssuanceOfCommonStock</th>\n",
              "      <th>proceedsFromIssuanceOfLongTermDebtAndCapitalSecuritiesNet</th>\n",
              "      <th>proceedsFromIssuanceOfPreferredStock</th>\n",
              "      <th>proceedsFromRepurchaseOfEquity</th>\n",
              "      <th>proceedsFromSaleOfTreasuryStock</th>\n",
              "      <th>changeInCashAndCashEquivalents</th>\n",
              "      <th>changeInExchangeRate</th>\n",
              "      <th>netIncome_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-08-31</td>\n",
              "      <td>319000000</td>\n",
              "      <td>791700000</td>\n",
              "      <td>472700000</td>\n",
              "      <td>472700000</td>\n",
              "      <td>116600000</td>\n",
              "      <td>201500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>201500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-11-30</td>\n",
              "      <td>421700000</td>\n",
              "      <td>924600000</td>\n",
              "      <td>502900000</td>\n",
              "      <td>502900000</td>\n",
              "      <td>177900000</td>\n",
              "      <td>238300000</td>\n",
              "      <td>48900000.00</td>\n",
              "      <td>238300000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-02-28</td>\n",
              "      <td>310200000</td>\n",
              "      <td>764500000</td>\n",
              "      <td>454300000</td>\n",
              "      <td>454300000</td>\n",
              "      <td>100800000</td>\n",
              "      <td>209400000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>209400000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-05-31</td>\n",
              "      <td>326700000</td>\n",
              "      <td>798300000</td>\n",
              "      <td>471600000</td>\n",
              "      <td>471600000</td>\n",
              "      <td>97500000</td>\n",
              "      <td>229200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>229200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-08-31</td>\n",
              "      <td>334800000</td>\n",
              "      <td>782200000</td>\n",
              "      <td>668600000</td>\n",
              "      <td>459800000</td>\n",
              "      <td>126000000</td>\n",
              "      <td>208800000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>221200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>34700000.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-31800000.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>500000.00</td>\n",
              "      <td>15600000.00</td>\n",
              "      <td>102400000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2010-11-30</td>\n",
              "      <td>446000000</td>\n",
              "      <td>979500000</td>\n",
              "      <td>794000000</td>\n",
              "      <td>533400000</td>\n",
              "      <td>185400000</td>\n",
              "      <td>260600000</td>\n",
              "      <td>52700000.00</td>\n",
              "      <td>272800000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>34500000.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-16600000.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27200000.00</td>\n",
              "      <td>16600000.00</td>\n",
              "      <td>133600000.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 88 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bec01244-8343-4edf-ba07-6e87e5a465b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bec01244-8343-4edf-ba07-6e87e5a465b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bec01244-8343-4edf-ba07-6e87e5a465b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6efe2e4f-9335-4bd2-953d-57c095a9a587\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6efe2e4f-9335-4bd2-953d-57c095a9a587')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6efe2e4f-9335-4bd2-953d-57c095a9a587 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  fiscalDateEnding  grossProfit  totalRevenue  costOfRevenue  \\\n",
              "0       2009-08-31    319000000     791700000      472700000   \n",
              "1       2009-11-30    421700000     924600000      502900000   \n",
              "2       2010-02-28    310200000     764500000      454300000   \n",
              "3       2010-05-31    326700000     798300000      471600000   \n",
              "4       2010-08-31    334800000     782200000      668600000   \n",
              "5       2010-11-30    446000000     979500000      794000000   \n",
              "\n",
              "   costofGoodsAndServicesSold  operatingIncome  \\\n",
              "0                   472700000        116600000   \n",
              "1                   502900000        177900000   \n",
              "2                   454300000        100800000   \n",
              "3                   471600000         97500000   \n",
              "4                   459800000        126000000   \n",
              "5                   533400000        185400000   \n",
              "\n",
              "   sellingGeneralAndAdministrative  researchAndDevelopment  operatingExpenses  \\\n",
              "0                        201500000                     NaN          201500000   \n",
              "1                        238300000             48900000.00          238300000   \n",
              "2                        209400000                     NaN          209400000   \n",
              "3                        229200000                     NaN          229200000   \n",
              "4                        208800000                     NaN          221200000   \n",
              "5                        260600000             52700000.00          272800000   \n",
              "\n",
              "   investmentIncomeNet  ...  dividendPayoutCommonStock  \\\n",
              "0                  NaN  ...                        NaN   \n",
              "1                  NaN  ...                        NaN   \n",
              "2                  NaN  ...                        NaN   \n",
              "3                  NaN  ...                        NaN   \n",
              "4                  NaN  ...                34700000.00   \n",
              "5                  NaN  ...                34500000.00   \n",
              "\n",
              "   dividendPayoutPreferredStock  proceedsFromIssuanceOfCommonStock  \\\n",
              "0                           NaN                                NaN   \n",
              "1                           NaN                                NaN   \n",
              "2                           NaN                                NaN   \n",
              "3                           NaN                                NaN   \n",
              "4                           NaN                                NaN   \n",
              "5                           NaN                                NaN   \n",
              "\n",
              "   proceedsFromIssuanceOfLongTermDebtAndCapitalSecuritiesNet  \\\n",
              "0                                                NaN           \n",
              "1                                                NaN           \n",
              "2                                                NaN           \n",
              "3                                                NaN           \n",
              "4                                                NaN           \n",
              "5                                                NaN           \n",
              "\n",
              "   proceedsFromIssuanceOfPreferredStock  proceedsFromRepurchaseOfEquity  \\\n",
              "0                                   NaN                             NaN   \n",
              "1                                   NaN                             NaN   \n",
              "2                                   NaN                             NaN   \n",
              "3                                   NaN                             NaN   \n",
              "4                                   NaN                    -31800000.00   \n",
              "5                                   NaN                    -16600000.00   \n",
              "\n",
              "   proceedsFromSaleOfTreasuryStock  changeInCashAndCashEquivalents  \\\n",
              "0                              NaN                             NaN   \n",
              "1                              NaN                             NaN   \n",
              "2                              NaN                             NaN   \n",
              "3                              NaN                             NaN   \n",
              "4                              NaN                       500000.00   \n",
              "5                              NaN                     27200000.00   \n",
              "\n",
              "   changeInExchangeRate  netIncome_y  \n",
              "0                   NaN          NaN  \n",
              "1                   NaN          NaN  \n",
              "2                   NaN          NaN  \n",
              "3                   NaN          NaN  \n",
              "4           15600000.00 102400000.00  \n",
              "5           16600000.00 133600000.00  \n",
              "\n",
              "[6 rows x 88 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tic = 'MKC'\n",
        "income_statement = pd.read_csv(f'{root_dir}/IncomeStatement/{tic}_IS.csv')\n",
        "balance_sheet = pd.read_csv(f'{root_dir}/BalanceSheet/{tic}_BS.csv')\n",
        "cash_flow = pd.read_csv(f'{root_dir}/CashFlow/{tic}_CF.csv')\n",
        "df = pd.merge(income_statement, balance_sheet, on='fiscalDateEnding', how='outer').merge(cash_flow, on='fiscalDateEnding', how='outer')\n",
        "df = df.sort_values('fiscalDateEnding')\n",
        "df.head(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jS8ABQCqc43"
      },
      "source": [
        "## We notice a few things\n",
        "\n",
        "\n",
        "*   Time scales are different (notice that MMM reported on 2009-09-30 and MKC reported on 2009-08-31)\n",
        "*   They have a much later time start than our price data.\n",
        "*   They have different start dates.\n",
        "*   They have different amounts of NaN at different features.\n",
        "\n",
        "The first bullet will be handled with re-scaling the data. The remaining bullets will all affect our ultimate start date, and we'll have to getter a better sense for the data available in the other tickers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44V9we7QXHhy",
        "outputId": "6179639f-551b-45c6-8d18-a03592a2fd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ABT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ADM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ADP...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing AFL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ALB...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing AOS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing APD...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ATO...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing BDX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing BEN...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing BF-B...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing BRO...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CAH...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CAT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CB...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CHD...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CHRW...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CINF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CLX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CTAS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CVX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing DOV...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ECL...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ED...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing EMR...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ESS...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing EXPD...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing FAST...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06da924d5ac6>:13: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  df = df.resample('Q').last() # resample to quarters so datasets all match\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing FRT...\n"
          ]
        }
      ],
      "source": [
        "master_df = pd.DataFrame()\n",
        "\n",
        "for tic in tickers:\n",
        "  print(f'Processing {tic}...')\n",
        "  income_statement = pd.read_csv(f'{root_dir}/IncomeStatement/{tic}_IS.csv')\n",
        "  balance_sheet = pd.read_csv(f'{root_dir}/BalanceSheet/{tic}_BS.csv')\n",
        "  cash_flow = pd.read_csv(f'{root_dir}/CashFlow/{tic}_CF.csv')\n",
        "  df = pd.merge(income_statement, balance_sheet, on='fiscalDateEnding', how='outer').merge(cash_flow, on='fiscalDateEnding', how='outer')\n",
        "  df = df.rename(columns={'fiscalDateEnding': 'Date'})\n",
        "  df = df.sort_values('Date')\n",
        "  df.set_index('Date', inplace=True)\n",
        "  df.index = pd.to_datetime(df.index)\n",
        "  df = df.resample('Q').last() # resample to quarters so datasets all match\n",
        "\n",
        "  data_items_needed = ['dividendPayout', 'commonStockSharesOutstanding', 'netIncome_x', 'operatingCashflow', 'totalRevenue', 'costOfRevenue', 'totalAssets']\n",
        "\n",
        "  subset_df = df[data_items_needed]\n",
        "  subset_df = pd.merge(subset_df, data[[tic]], on='Date')\n",
        "  subset_df = subset_df.rename(columns={tic: 'Price'})\n",
        "\n",
        "  # calculate factors\n",
        "  subset_df['dividendYield'] = subset_df.dividendPayout / subset_df.commonStockSharesOutstanding / subset_df.Price\n",
        "  subset_df['payoutRatio'] = subset_df.dividendPayout / subset_df.netIncome_x\n",
        "  subset_df['operatingcashFlowRatio'] = subset_df.operatingCashflow / (subset_df.totalRevenue - subset_df.costOfRevenue)\n",
        "  subset_df['ROA'] = subset_df.netIncome_x / subset_df.totalAssets\n",
        "  subset_df['netProfitMargin'] = subset_df.netIncome_x / subset_df.totalRevenue\n",
        "  subset_df['ticker'] = tic\n",
        "\n",
        "  subset_df.drop(['Price'] + data_items_needed, axis=1, inplace=True)\n",
        "\n",
        "  master_df = pd.concat([master_df, subset_df], axis=0)\n",
        "  master_df = master_df.sort_values(by=['Date', 'ticker'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmDp6VHOuQFr"
      },
      "outputs": [],
      "source": [
        "master_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvjpPF3E2T8t"
      },
      "outputs": [],
      "source": [
        "master_df.groupby('Date')['ticker'].nunique() # 62 companies starting at 2009-09-30. seems decent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3gn5blI2ZAx"
      },
      "outputs": [],
      "source": [
        "# let's look at the constituents by date\n",
        "date_check = master_df.reset_index()\n",
        "date_check = date_check.groupby('ticker').agg({'Date':['min', 'max']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASWVcr2Z4AQJ",
        "outputId": "e2a3517e-37f5-4e04-c4ef-ac94af2b833f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<DatetimeArray>\n",
              "['2023-06-30 00:00:00']\n",
              "Length: 1, dtype: datetime64[ns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_check[('Date', 'max')].unique() # so constituents aren't in-and-out. once in they're there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "MNvFLGZN3wd6",
        "outputId": "3a07995c-2f2c-4e19-e91b-e70b4caac930"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"date_check\",\n  \"rows\": 63,\n  \"fields\": [\n    {\n      \"column\": [\n        \"ticker\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"MDT\",\n          \"HRL\",\n          \"ABT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Date\",\n        \"min\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2008-03-31 00:00:00\",\n        \"max\": \"2017-03-31 00:00:00\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2008-06-30 00:00:00\",\n          \"2009-09-30 00:00:00\",\n          \"2008-03-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Date\",\n        \"max\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-06-30 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2023-06-30 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-56d30734-451c-411a-a314-d8e38cd27dcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Date</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABT</th>\n",
              "      <td>2008-03-31</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BF-B</th>\n",
              "      <td>2008-03-31</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CVX</th>\n",
              "      <td>2008-03-31</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TROW</th>\n",
              "      <td>2008-03-31</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ECL</th>\n",
              "      <td>2008-06-30</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NDSN</th>\n",
              "      <td>2009-09-30</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MKC</th>\n",
              "      <td>2009-09-30</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CTAS</th>\n",
              "      <td>2009-09-30</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MDT</th>\n",
              "      <td>2013-09-30</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LIN</th>\n",
              "      <td>2017-03-31</td>\n",
              "      <td>2023-06-30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56d30734-451c-411a-a314-d8e38cd27dcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56d30734-451c-411a-a314-d8e38cd27dcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56d30734-451c-411a-a314-d8e38cd27dcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d39004b5-9e3b-4a46-b0f5-560dc6a48374\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d39004b5-9e3b-4a46-b0f5-560dc6a48374')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d39004b5-9e3b-4a46-b0f5-560dc6a48374 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             Date           \n",
              "              min        max\n",
              "ticker                      \n",
              "ABT    2008-03-31 2023-06-30\n",
              "BF-B   2008-03-31 2023-06-30\n",
              "CVX    2008-03-31 2023-06-30\n",
              "TROW   2008-03-31 2023-06-30\n",
              "ECL    2008-06-30 2023-06-30\n",
              "...           ...        ...\n",
              "NDSN   2009-09-30 2023-06-30\n",
              "MKC    2009-09-30 2023-06-30\n",
              "CTAS   2009-09-30 2023-06-30\n",
              "MDT    2013-09-30 2023-06-30\n",
              "LIN    2017-03-31 2023-06-30\n",
              "\n",
              "[63 rows x 2 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_check.sort_values(('Date', 'min'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsOHnRJe4H2-"
      },
      "outputs": [],
      "source": [
        "# Let's now start at '2009-09-30' and get rid of MDT and LIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdZU4MzZ4TiC"
      },
      "outputs": [],
      "source": [
        "new_start_date = '2009-09-30'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcsnBe2wzO3S",
        "outputId": "0d2283e6-4cbd-4f61-e838-17f647c976e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'MDT', 'LIN'}\n",
            "61\n"
          ]
        }
      ],
      "source": [
        "keep_tickers = master_df.loc[new_start_date]['ticker'].tolist()\n",
        "x_tickers = set(tickers).intersection(set(keep_tickers))\n",
        "miss_tickers = set(tickers).difference(set(keep_tickers))\n",
        "print(miss_tickers)\n",
        "print(len(x_tickers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ZZVBhWXe4WUY",
        "outputId": "0c33d3bd-a476-4eac-bf9d-29a3483dc80b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"fundamental_df\",\n  \"rows\": 2501,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2009-09-30 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"2017-06-30 00:00:00\",\n          \"2014-06-30 00:00:00\",\n          \"2011-09-30 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dividendYield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3026162065191993,\n        \"min\": -0.12967928200422846,\n        \"max\": 10.695479333796454,\n        \"num_unique_values\": 2400,\n        \"samples\": [\n          0.005742412251846827,\n          0.006674524553963145,\n          0.008239114554210364\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payoutRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.3766628821396525,\n        \"min\": -137.2,\n        \"max\": 91.85325414501361,\n        \"num_unique_values\": 2423,\n        \"samples\": [\n          0.1941391662800514,\n          0.4297520661157025,\n          0.29101283880171186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operatingcashFlowRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69.11455715663588,\n        \"min\": -47.37960607602297,\n        \"max\": 3425.71875,\n        \"num_unique_values\": 2457,\n        \"samples\": [\n          0.5952380952380952,\n          0.6929886970997985,\n          1.217741935483871\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05569842549033443,\n        \"min\": -0.12562852548559178,\n        \"max\": 2.632183908045977,\n        \"num_unique_values\": 2431,\n        \"samples\": [\n          0.02532048223430989,\n          0.010632630532565177,\n          0.01619853532196124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"netProfitMargin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.732060114828656,\n        \"min\": -0.9975609756097561,\n        \"max\": 2877.0,\n        \"num_unique_values\": 2483,\n        \"samples\": [\n          0.08967924939995636,\n          0.1033265098631399,\n          0.19116234390009607\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"ABT\",\n          \"AOS\",\n          \"PEP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "fundamental_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b26568d7-0a89-47e2-80fb-a7a00b8be8db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dividendYield</th>\n",
              "      <th>payoutRatio</th>\n",
              "      <th>operatingcashFlowRatio</th>\n",
              "      <th>ROA</th>\n",
              "      <th>netProfitMargin</th>\n",
              "      <th>Ticker</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.39</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.19</td>\n",
              "      <td>ABT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.18</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>ADM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.14</td>\n",
              "      <td>ADP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.36</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>AFL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.10</td>\n",
              "      <td>ALB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b26568d7-0a89-47e2-80fb-a7a00b8be8db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b26568d7-0a89-47e2-80fb-a7a00b8be8db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b26568d7-0a89-47e2-80fb-a7a00b8be8db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-680e19e5-0db7-49ae-91e0-91e6d3f3535d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-680e19e5-0db7-49ae-91e0-91e6d3f3535d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-680e19e5-0db7-49ae-91e0-91e6d3f3535d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            dividendYield  payoutRatio  operatingcashFlowRatio  ROA  \\\n",
              "Date                                                                  \n",
              "2009-09-30           0.02         0.42                    1.39 0.03   \n",
              "2009-09-30           0.01         0.18                    2.05 0.02   \n",
              "2009-09-30           0.01         0.58                    0.27 0.01   \n",
              "2009-09-30           0.02         0.36                   -0.78 0.00   \n",
              "2009-09-30            NaN         0.22                    1.14  NaN   \n",
              "\n",
              "            netProfitMargin Ticker  \n",
              "Date                                \n",
              "2009-09-30             0.19    ABT  \n",
              "2009-09-30             0.03    ADM  \n",
              "2009-09-30             0.14    ADP  \n",
              "2009-09-30             0.08    AFL  \n",
              "2009-09-30             0.10    ALB  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df = master_df.loc[new_start_date:]\n",
        "fundamental_df = new_df[~new_df['ticker'].isin(['MDT', 'LIN'])]\n",
        "fundamental_df = fundamental_df.rename(columns={'ticker': 'Ticker'})\n",
        "fundamental_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAR3RyMe1eHN",
        "outputId": "eef9daf0-42f4-44f1-f627-b4e34c48708e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# let's just check that they're gone\n",
        "print('MDT' in fundamental_df.Ticker.unique())\n",
        "print('LIN' in fundamental_df.Ticker.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qDfgLsoFwFBo",
        "outputId": "256211d0-d227-4656-e488-17cd2a127a47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2008-03-31 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"2016-06-30 00:00:00\",\n          \"2021-06-30 00:00:00\",\n          \"2016-03-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dividendYield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 0,\n        \"max\": 42,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payoutRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 29,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operatingcashFlowRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 29,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          1,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 0,\n        \"max\": 42,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2,\n          31,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"netProfitMargin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1,\n          7,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9b1a9c4f-ac3b-4517-980a-452102b4f6cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dividendYield</th>\n",
              "      <th>payoutRatio</th>\n",
              "      <th>operatingcashFlowRatio</th>\n",
              "      <th>ROA</th>\n",
              "      <th>netProfitMargin</th>\n",
              "      <th>ticker</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2008-03-31</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-06-30</th>\n",
              "      <td>31</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-09-30</th>\n",
              "      <td>41</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>41</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-12-31</th>\n",
              "      <td>41</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>41</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-03-31</th>\n",
              "      <td>42</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-06-30</th>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-12-31</th>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-31</th>\n",
              "      <td>19</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-06-30</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-09-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-31</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-03-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-09-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-31</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-09-30</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-06-30</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-31</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-31</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-31</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-03-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-09-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-03-31</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-06-30</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-12-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-31</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b1a9c4f-ac3b-4517-980a-452102b4f6cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b1a9c4f-ac3b-4517-980a-452102b4f6cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b1a9c4f-ac3b-4517-980a-452102b4f6cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd8624f2-f398-46bd-883a-48cf5265447b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd8624f2-f398-46bd-883a-48cf5265447b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd8624f2-f398-46bd-883a-48cf5265447b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            dividendYield  payoutRatio  operatingcashFlowRatio  ROA  \\\n",
              "Date                                                                  \n",
              "2008-03-31              4            4                       4    4   \n",
              "2008-06-30             31           21                      21   31   \n",
              "2008-09-30             41           29                      29   41   \n",
              "2008-12-31             41           25                      25   41   \n",
              "2009-03-31             42           24                      23   42   \n",
              "2009-06-30             24           15                      16   24   \n",
              "2009-09-30             20           11                      11   19   \n",
              "2009-12-31             19           12                      12   19   \n",
              "2010-03-31             19           10                      10   19   \n",
              "2010-06-30              6            4                       4    6   \n",
              "2010-09-30              1            1                       0    0   \n",
              "2010-12-31              3            2                       1    2   \n",
              "2011-03-31              0            0                       0    0   \n",
              "2011-06-30              0            0                       0    0   \n",
              "2011-09-30              1            1                       0    0   \n",
              "2012-12-31              2            1                       0    1   \n",
              "2013-09-30              2            2                       1    1   \n",
              "2013-12-31              2            2                       1    1   \n",
              "2014-03-31              2            2                       2    2   \n",
              "2014-06-30              2            1                       1    2   \n",
              "2014-09-30              1            1                       1    1   \n",
              "2014-12-31              3            2                       1    2   \n",
              "2015-03-31              2            2                       2    1   \n",
              "2015-06-30              0            0                       0    0   \n",
              "2015-09-30              1            1                       0    0   \n",
              "2015-12-31              1            1                       0    0   \n",
              "2016-03-31              0            0                       0    0   \n",
              "2016-06-30              0            0                       0    0   \n",
              "2016-09-30              0            0                       0    0   \n",
              "2017-03-31              1            1                       1    1   \n",
              "2017-06-30              1            1                       1    1   \n",
              "2018-12-31              0            0                       0    0   \n",
              "2019-09-30              0            0                       0    0   \n",
              "2019-12-31              1            1                       0    0   \n",
              "2020-03-31              0            0                       0    0   \n",
              "2020-06-30              0            0                       0    0   \n",
              "2020-09-30              0            0                       0    0   \n",
              "2020-12-31              0            0                       0    0   \n",
              "2021-03-31              0            0                       0    0   \n",
              "2021-06-30              0            0                       0    0   \n",
              "2021-09-30              0            0                       0    0   \n",
              "2021-12-31              0            0                       0    0   \n",
              "2022-03-31              0            0                       0    0   \n",
              "2022-06-30              0            0                       0    0   \n",
              "2022-09-30              0            0                       0    0   \n",
              "2023-03-31              0            0                       0    0   \n",
              "2023-06-30              0            0                       0    0   \n",
              "\n",
              "            netProfitMargin  ticker  \n",
              "Date                                 \n",
              "2008-03-31                3       0  \n",
              "2008-06-30                7       0  \n",
              "2008-09-30                9       0  \n",
              "2008-12-31               10       0  \n",
              "2009-03-31                9       0  \n",
              "2009-06-30                6       0  \n",
              "2009-09-30                2       0  \n",
              "2009-12-31                5       0  \n",
              "2010-03-31                3       0  \n",
              "2010-06-30                1       0  \n",
              "2010-09-30                0       0  \n",
              "2010-12-31                1       0  \n",
              "2011-03-31                0       0  \n",
              "2011-06-30                0       0  \n",
              "2011-09-30                0       0  \n",
              "2012-12-31                0       0  \n",
              "2013-09-30                0       0  \n",
              "2013-12-31                0       0  \n",
              "2014-03-31                1       0  \n",
              "2014-06-30                0       0  \n",
              "2014-09-30                0       0  \n",
              "2014-12-31                0       0  \n",
              "2015-03-31                1       0  \n",
              "2015-06-30                0       0  \n",
              "2015-09-30                0       0  \n",
              "2015-12-31                0       0  \n",
              "2016-03-31                0       0  \n",
              "2016-06-30                0       0  \n",
              "2016-09-30                0       0  \n",
              "2017-03-31                0       0  \n",
              "2017-06-30                0       0  \n",
              "2018-12-31                0       0  \n",
              "2019-09-30                0       0  \n",
              "2019-12-31                0       0  \n",
              "2020-03-31                0       0  \n",
              "2020-06-30                0       0  \n",
              "2020-09-30                0       0  \n",
              "2020-12-31                0       0  \n",
              "2021-03-31                0       0  \n",
              "2021-06-30                0       0  \n",
              "2021-09-30                0       0  \n",
              "2021-12-31                0       0  \n",
              "2022-03-31                0       0  \n",
              "2022-06-30                0       0  \n",
              "2022-09-30                0       0  \n",
              "2023-03-31                0       0  \n",
              "2023-06-30                0       0  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get number of missing values at each date\n",
        "pd.DataFrame(master_df.groupby('Date').apply(lambda x: x.isnull().sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiS6oVsS5i7N"
      },
      "outputs": [],
      "source": [
        "# might want to have a start date of 2010-06-30....which would still have the same 62 tickers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-US63je6f1i"
      },
      "outputs": [],
      "source": [
        "fundamental_df.set_index(['Ticker'], append=True, inplace=True)\n",
        "fundamental_df = fundamental_df.loc['2010-06-30':]\n",
        "fundamental_df = fundamental_df.ffill().bfill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCvuAmPx9QJ4"
      },
      "outputs": [],
      "source": [
        "fundamental_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYidWWc5CHy5"
      },
      "outputs": [],
      "source": [
        "monthly_ff = fundamental_df.reset_index(level=['Ticker'])\n",
        "monthly_ff = monthly_ff.groupby(['Ticker']).resample('M').ffill()\n",
        "monthly_ff.drop('Ticker', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWFvxd29Ck3Q"
      },
      "outputs": [],
      "source": [
        "monthly_ff.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N_M-TwKoVQF"
      },
      "outputs": [],
      "source": [
        "monthly_ff.index.get_level_values(1).unique() # so we should have 157 rows for the final dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys-Ep1aKjWol"
      },
      "source": [
        "## Bond Yield Curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbpOferkCc0E"
      },
      "source": [
        "Yield curves of U.S. Treasuries were obtained from treasury.gov for the period between 2000 and 2023 for all available maturities.\n",
        "\n",
        "Since the number of available maturities varied over time, polynomial interpolation with 4th-degree polynomials was used to harmonize the sampling among all curves. A total of four points per polynomial were obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8rbRln_CE5iP",
        "outputId": "ff017e95-1d0e-47e1-faff-e08c8f64f7b2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by PolynomialFeatures.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-96f8834c47c0>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolynomials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0minterpolating_polynomials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_curve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mx_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-96f8834c47c0>\u001b[0m in \u001b[0;36mfit_polynomials\u001b[0;34m(yield_curves, degree)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myield_curves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurve\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myield_curves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_curves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-96f8834c47c0>\u001b[0m in \u001b[0;36mfit_polynomial\u001b[0;34m(yield_curve, degree)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpoly_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaturities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Fit polynomial regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 )\n\u001b[1;32m   1473\u001b[0m             ):\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/preprocessing/_polynomial.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1073\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by PolynomialFeatures."
          ]
        }
      ],
      "source": [
        "# use cached version\n",
        "yield_curve = pd.read_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/master_yield_curve.csv\", index_col='Date')\n",
        "yield_curve.index = pd.to_datetime(yield_curve.index)\n",
        "\n",
        "def fit_polynomial(yield_curve, degree=4):\n",
        "    \"\"\"Fits polynomials to an yield curve in a dataframe.\"\"\"\n",
        "\n",
        "    rates = yield_curve.dropna()\n",
        "    maturities = np.array([(int(i[:-3])/12 if i[-2:] == 'Mo' else int(i[:-3])) for i in rates.index])\n",
        "\n",
        "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "\n",
        "    poly_features = poly.fit_transform(maturities.reshape(-1, 1))\n",
        "\n",
        "    # Fit polynomial regression model\n",
        "    poly_reg_model = LinearRegression()\n",
        "    poly_reg_model.fit(poly_features, rates)\n",
        "\n",
        "    return poly_reg_model\n",
        "\n",
        "def fit_polynomials(yield_curves, degree=4):\n",
        "    \"Fits polynomials to all yield curves in a dataframe.\"\n",
        "    df = pd.DataFrame(index=yield_curves.index,columns=range(degree + 1))\n",
        "    for curve in yield_curves.index:\n",
        "        model = fit_polynomial(yield_curves.loc[curve,:])\n",
        "        df.loc[curve, 0] = model.intercept_\n",
        "        df.loc[curve, 1:] = model.coef_\n",
        "    return df\n",
        "\n",
        "def resample_yield_curves(x, polynomials):\n",
        "    \"Resamples a series of polynomials at specified intervals.\"\n",
        "    return np.apply_along_axis(lambda p:np.polyval(p, x), 1, polynomials)\n",
        "\n",
        "interpolating_polynomials = fit_polynomials(yield_curve)\n",
        "\n",
        "x_values = np.array([0.1, 0.3, 0.6, 0.9])\n",
        "\n",
        "resampled_curves = resample_yield_curves(x_values, interpolating_polynomials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmPDwI62Fp5E"
      },
      "outputs": [],
      "source": [
        "# Tidy up dataframe\n",
        "yield_m = pd.DataFrame(resampled_curves, index=yield_curve.index, columns=x_values)\n",
        "yield_m.index = pd.to_datetime(yield_m.index)\n",
        "\n",
        "yield_m.sort_index(inplace=True)\n",
        "\n",
        "# Apply log difference\n",
        "yield_m = np.log(yield_m).diff()\n",
        "yield_m = yield_m.dropna()\n",
        "yield_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKOhWXLDBcFN"
      },
      "outputs": [],
      "source": [
        "##### JOHN VERSION TO KEEP MOVING ####\n",
        "# use cached version\n",
        "yield_curve = pd.read_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/master_yield_curve.csv\", index_col='Date')\n",
        "yield_curve.index = pd.to_datetime(yield_curve.index)\n",
        "yield_curve = yield_curve[['1 Yr', '3 Yr']]\n",
        "yield_m = yield_curve.resample('M').last()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCMmMp0Y_Vrb"
      },
      "source": [
        "## Merging the datasets together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIR99mvrCDdi"
      },
      "outputs": [],
      "source": [
        "# need monthly returns from original price data\n",
        "data_m = data.resample('M').last()\n",
        "rets_m = np.log(data_m).diff()\n",
        "rets_m = rets_m.dropna()\n",
        "rets_m_long = pd.DataFrame(rets_m.stack())\n",
        "rets_m_long = rets_m_long.reset_index()\n",
        "rets_m_long = rets_m_long.rename(columns={0: 'ret'})\n",
        "rets_m_long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKiyxkvRqWzo"
      },
      "outputs": [],
      "source": [
        "# data_m.to_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/monthly_prices.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Oi034PiQEewU",
        "outputId": "ab7d7f14-08b3-4f4c-ef8c-bec8c23ebfff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 9577,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-06-30 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 157,\n        \"samples\": [\n          \"2020-12-31 00:00:00\",\n          \"2014-03-31 00:00:00\",\n          \"2021-07-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"ABT\",\n          \"AOS\",\n          \"PEP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06395662331846812,\n        \"min\": -0.4341311847769642,\n        \"max\": 0.3775794202082716,\n        \"num_unique_values\": 9573,\n        \"samples\": [\n          0.029518182591034225,\n          -0.012522957474403462,\n          0.016590862910230708\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dividendYield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3754744526987668,\n        \"min\": -0.12967928200422846,\n        \"max\": 10.695479333796454,\n        \"num_unique_values\": 2278,\n        \"samples\": [\n          0.009246886124278741,\n          0.012905675313151694,\n          0.0066787247959309674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payoutRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8627042353312997,\n        \"min\": -137.2,\n        \"max\": 91.85325414501361,\n        \"num_unique_values\": 2276,\n        \"samples\": [\n          0.3406204617627084,\n          0.3040625170179165,\n          0.5549645390070922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operatingcashFlowRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.70475200741634,\n        \"min\": -47.37960607602297,\n        \"max\": 3425.71875,\n        \"num_unique_values\": 2307,\n        \"samples\": [\n          -1.3793103448275863,\n          0.41904202482784664,\n          1.4820191355988124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017052689834916753,\n        \"min\": -0.12562852548559178,\n        \"max\": 0.21171303737577252,\n        \"num_unique_values\": 2305,\n        \"samples\": [\n          0.019341637364165526,\n          0.006744256266569716,\n          0.03934481594056062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"netProfitMargin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56.248672970839046,\n        \"min\": -0.9975609756097561,\n        \"max\": 2877.0,\n        \"num_unique_values\": 2310,\n        \"samples\": [\n          0.13897679324894516,\n          0.08065739570164349,\n          0.14439140811455847\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.293287329265428,\n        \"min\": 0.05,\n        \"max\": 5.4,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          1.75,\n          0.33,\n          1.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0647129082851394,\n        \"min\": 0.11,\n        \"max\": 4.51,\n        \"num_unique_values\": 115,\n        \"samples\": [\n          1.42,\n          0.51,\n          0.89\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dfb951a7-7b2b-4c09-801f-c884a4f19fdf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>ret</th>\n",
              "      <th>dividendYield</th>\n",
              "      <th>payoutRatio</th>\n",
              "      <th>operatingcashFlowRatio</th>\n",
              "      <th>ROA</th>\n",
              "      <th>netProfitMargin</th>\n",
              "      <th>1 Yr</th>\n",
              "      <th>3 Yr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-06-30</td>\n",
              "      <td>ABT</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-06-30</td>\n",
              "      <td>ADM</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.22</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-06-30</td>\n",
              "      <td>ADP</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-06-30</td>\n",
              "      <td>AFL</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-1.34</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-06-30</td>\n",
              "      <td>ALB</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9572</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>TGT</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9573</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>TROW</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.30</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9574</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>WMT</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9575</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>WST</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.21</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>XOM</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9577 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfb951a7-7b2b-4c09-801f-c884a4f19fdf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfb951a7-7b2b-4c09-801f-c884a4f19fdf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfb951a7-7b2b-4c09-801f-c884a4f19fdf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdc348b9-fc39-42a9-baca-7b630a864091\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdc348b9-fc39-42a9-baca-7b630a864091')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdc348b9-fc39-42a9-baca-7b630a864091 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_962eb01a-2de8-4767-b470-d3a1ce411aa7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_962eb01a-2de8-4767-b470-d3a1ce411aa7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Date Ticker   ret  dividendYield  payoutRatio  \\\n",
              "0    2010-06-30    ABT -0.02           0.03         0.53   \n",
              "1    2010-06-30    ADM  0.02           0.01         0.22   \n",
              "2    2010-06-30    ADP -0.01           0.01         0.84   \n",
              "3    2010-06-30    AFL -0.04           0.02         0.23   \n",
              "4    2010-06-30    ALB -0.08           0.00         0.16   \n",
              "...         ...    ...   ...            ...          ...   \n",
              "9572 2023-06-30    TGT  0.01           0.01         0.52   \n",
              "9573 2023-06-30   TROW  0.06           0.01         0.59   \n",
              "9574 2023-06-30    WMT  0.07           0.01         0.92   \n",
              "9575 2023-06-30    WST  0.13           0.00         0.09   \n",
              "9576 2023-06-30    XOM  0.05           0.01         0.49   \n",
              "\n",
              "      operatingcashFlowRatio  ROA  netProfitMargin  1 Yr  3 Yr  \n",
              "0                       0.96 0.02             0.15  0.32  1.00  \n",
              "1                      -0.10 0.01             0.03  0.32  1.00  \n",
              "2                       0.44 0.01             0.09  0.32  1.00  \n",
              "3                      -1.34 0.01             0.12  0.32  1.00  \n",
              "4                       0.96 0.03             0.14  0.32  1.00  \n",
              "...                      ...  ...              ...   ...   ...  \n",
              "9572                    1.07 0.02             0.04  5.40  4.49  \n",
              "9573                    0.49 0.04             0.30  5.40  4.49  \n",
              "9574                    0.13 0.01             0.01  5.40  4.49  \n",
              "9575                    0.86 0.04             0.21  5.40  4.49  \n",
              "9576                    0.12 0.02             0.10  5.40  4.49  \n",
              "\n",
              "[9577 rows x 10 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# merge to final dataset\n",
        "dataset = rets_m_long.merge(monthly_ff, on=['Date', 'Ticker']).merge(yield_m, on='Date')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbFHUHxnYlNZ"
      },
      "outputs": [],
      "source": [
        "# dataset.to_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCDuq7_ip0oT",
        "outputId": "af607f62-cf6a-414a-a82d-e53dec3d147f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157\n",
            "61\n"
          ]
        }
      ],
      "source": [
        "# quick check\n",
        "print(dataset.Date.nunique())\n",
        "print(dataset.Ticker.nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsDyrpxxx5DD"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndGLMlhaxp47"
      },
      "outputs": [],
      "source": [
        "# subplots of line plots for each price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl8Rr2GDyASo"
      },
      "outputs": [],
      "source": [
        "# subplots of line plots for each return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CApaKFgYyEL9"
      },
      "outputs": [],
      "source": [
        "# analyze and potentially remove some tickers if need be"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SNCk8uDyFFJ"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POAQOHApyT_i"
      },
      "source": [
        "## MVO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w62O8V336Hj"
      },
      "outputs": [],
      "source": [
        "# get annualized expected returns and covariance matrix\n",
        "rets_exp = rets.mean()*252\n",
        "rets_cov = rets.cov()*252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2wzb40l46FW",
        "outputId": "425ebbf1-90e4-457f-af3e-6a0770f98aaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ticker\n",
              "ABT    0.10\n",
              "ADM    0.09\n",
              "ADP    0.09\n",
              "AFL    0.10\n",
              "ALB    0.12\n",
              "       ... \n",
              "TGT    0.08\n",
              "TROW   0.10\n",
              "WMT    0.06\n",
              "WST    0.18\n",
              "XOM    0.08\n",
              "Length: 64, dtype: float64"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rets_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "4spd040646DD",
        "outputId": "104c2cb6-1e8d-4f81-c0b6-33cae244abec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rets_cov"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-930f854e-7e3e-43f8-83c5-3f1e2c171913\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABT</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADM</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADP</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFL</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALB</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TGT</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TROW</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WMT</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WST</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XOM</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 64 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-930f854e-7e3e-43f8-83c5-3f1e2c171913')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-930f854e-7e3e-43f8-83c5-3f1e2c171913 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-930f854e-7e3e-43f8-83c5-3f1e2c171913');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebe135a3-647c-4986-aa63-594a6572f259\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebe135a3-647c-4986-aa63-594a6572f259')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebe135a3-647c-4986-aa63-594a6572f259 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_db88fcd8-2f9b-4066-a1b3-a4f5295a90f8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rets_cov')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_db88fcd8-2f9b-4066-a1b3-a4f5295a90f8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rets_cov');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker  ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  SPGI  \\\n",
              "Ticker                                                    ...                   \n",
              "ABT    0.06 0.02 0.02 0.03 0.03 0.02 0.03 0.02 0.03 0.03  ... 0.02 0.01  0.03   \n",
              "ADM    0.02 0.10 0.03 0.04 0.04 0.03 0.04 0.02 0.02 0.05  ... 0.03 0.02  0.03   \n",
              "ADP    0.02 0.03 0.06 0.04 0.04 0.03 0.03 0.02 0.02 0.04  ... 0.03 0.02  0.04   \n",
              "AFL    0.03 0.04 0.04 0.13 0.06 0.05 0.05 0.03 0.02 0.07  ... 0.04 0.02  0.05   \n",
              "ALB    0.03 0.04 0.04 0.06 0.15 0.05 0.06 0.03 0.03 0.07  ... 0.04 0.02  0.05   \n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
              "TGT    0.02 0.03 0.03 0.04 0.04 0.04 0.04 0.02 0.02 0.05  ... 0.04 0.02  0.04   \n",
              "TROW   0.03 0.05 0.05 0.07 0.07 0.06 0.06 0.03 0.03 0.10  ... 0.05 0.03  0.06   \n",
              "WMT    0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.01 0.03  ... 0.02 0.01  0.02   \n",
              "WST    0.02 0.02 0.03 0.03 0.04 0.03 0.03 0.02 0.02 0.04  ... 0.03 0.02  0.03   \n",
              "XOM    0.02 0.04 0.03 0.04 0.04 0.03 0.04 0.02 0.02 0.04  ... 0.02 0.02  0.03   \n",
              "\n",
              "Ticker  SWK  SYY  TGT  TROW  WMT  WST  XOM  \n",
              "Ticker                                      \n",
              "ABT    0.03 0.02 0.02  0.03 0.02 0.02 0.02  \n",
              "ADM    0.04 0.03 0.03  0.05 0.02 0.02 0.04  \n",
              "ADP    0.04 0.03 0.03  0.05 0.02 0.03 0.03  \n",
              "AFL    0.06 0.04 0.04  0.07 0.02 0.03 0.04  \n",
              "ALB    0.06 0.03 0.04  0.07 0.02 0.04 0.04  \n",
              "...     ...  ...  ...   ...  ...  ...  ...  \n",
              "TGT    0.05 0.03 0.11  0.06 0.04 0.03 0.03  \n",
              "TROW   0.07 0.04 0.06  0.13 0.03 0.04 0.04  \n",
              "WMT    0.02 0.02 0.04  0.03 0.05 0.02 0.02  \n",
              "WST    0.04 0.02 0.03  0.04 0.02 0.09 0.02  \n",
              "XOM    0.04 0.03 0.03  0.04 0.02 0.02 0.07  \n",
              "\n",
              "[64 rows x 64 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rets_cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dDS9OODi46A0",
        "outputId": "7692e693-9053-40a6-dc88-d7c970a576f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Variable' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-f9b4ec1e2e6c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# return and risk in proper matrix form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets_exp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrisk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquad_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrets_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
          ]
        }
      ],
      "source": [
        "x = Variable(rets.shape[1])\n",
        "\n",
        "# return and risk in proper matrix form\n",
        "ret = rets_exp*x\n",
        "risk = quad_form(x, rets_cov)\n",
        "\n",
        "# optimize with constraints (long-only and all weights sum to 1)\n",
        "prob = Problem(Minimize(risk), [sum(x)==1, x >= 0])\n",
        "\n",
        "prob.solve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT5xrV6A9BpX"
      },
      "outputs": [],
      "source": [
        "weights = pd.DataFrame([x.value*100], columns=rets.columns).round(2).T.rename(columns={0:'Pct'})\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdhuuaZd91sp"
      },
      "outputs": [],
      "source": [
        "# show non-zero weights\n",
        "nz_wts = weights[weights.Pct > 0]\n",
        "nz_wts = nz_wts.sort_values(by='Pct', ascending=False)\n",
        "nz_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spl9DVqX-LH4"
      },
      "outputs": [],
      "source": [
        "nz_wts.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYr2Ey1Yyi5Y"
      },
      "source": [
        "## Neural Nets (MLP, RNN, CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSabK_8kSqxM"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Set random seed for numpy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set random seed for Python built-in random module\n",
        "random.seed(42)\n",
        "\n",
        "# Set random seed for TensorFlow\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5amFHLG2Y4g5"
      },
      "outputs": [],
      "source": [
        "# # toggle if you want to skip initial data prep\n",
        "# dataset = pd.read_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/dataset.csv\")\n",
        "# dataset.Date = pd.to_datetime(dataset.Date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku_LlTuCQcS_"
      },
      "outputs": [],
      "source": [
        "df = dataset.set_index(['Date', 'Ticker'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "CB_SkTQiXQ8U",
        "outputId": "cb73ff61-c586-417e-cc96-7beab6ed684b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pivot"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c4396a3-ef2a-4688-90eb-45de12cf7164\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1 Yr_ABT</th>\n",
              "      <th>1 Yr_ADM</th>\n",
              "      <th>1 Yr_ADP</th>\n",
              "      <th>1 Yr_AFL</th>\n",
              "      <th>1 Yr_ALB</th>\n",
              "      <th>1 Yr_AOS</th>\n",
              "      <th>1 Yr_APD</th>\n",
              "      <th>1 Yr_ATO</th>\n",
              "      <th>1 Yr_BDX</th>\n",
              "      <th>1 Yr_BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>ret_SHW</th>\n",
              "      <th>ret_SJM</th>\n",
              "      <th>ret_SPGI</th>\n",
              "      <th>ret_SWK</th>\n",
              "      <th>ret_SYY</th>\n",
              "      <th>ret_TGT</th>\n",
              "      <th>ret_TROW</th>\n",
              "      <th>ret_WMT</th>\n",
              "      <th>ret_WST</th>\n",
              "      <th>ret_XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-06-30</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-31</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-31</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-09-30</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-31</th>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>5.02</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.64</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>4.80</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>5.18</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>5.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157 rows × 488 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c4396a3-ef2a-4688-90eb-45de12cf7164')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c4396a3-ef2a-4688-90eb-45de12cf7164 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c4396a3-ef2a-4688-90eb-45de12cf7164');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ff0d691-d523-46b3-a703-74fc776e917a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ff0d691-d523-46b3-a703-74fc776e917a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ff0d691-d523-46b3-a703-74fc776e917a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_92c39986-337c-4bb6-afb1-8559b27ccb7d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_pivot')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_92c39986-337c-4bb6-afb1-8559b27ccb7d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_pivot');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            1 Yr_ABT  1 Yr_ADM  1 Yr_ADP  1 Yr_AFL  1 Yr_ALB  1 Yr_AOS  \\\n",
              "Date                                                                     \n",
              "2010-06-30      0.32      0.32      0.32      0.32      0.32      0.32   \n",
              "2010-07-31      0.29      0.29      0.29      0.29      0.29      0.29   \n",
              "2010-08-31      0.25      0.25      0.25      0.25      0.25      0.25   \n",
              "2010-09-30      0.27      0.27      0.27      0.27      0.27      0.27   \n",
              "2010-10-31      0.22      0.22      0.22      0.22      0.22      0.22   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2023-02-28      5.02      5.02      5.02      5.02      5.02      5.02   \n",
              "2023-03-31      4.64      4.64      4.64      4.64      4.64      4.64   \n",
              "2023-04-30      4.80      4.80      4.80      4.80      4.80      4.80   \n",
              "2023-05-31      5.18      5.18      5.18      5.18      5.18      5.18   \n",
              "2023-06-30      5.40      5.40      5.40      5.40      5.40      5.40   \n",
              "\n",
              "            1 Yr_APD  1 Yr_ATO  1 Yr_BDX  1 Yr_BEN  ...  ret_SHW  ret_SJM  \\\n",
              "Date                                                ...                     \n",
              "2010-06-30      0.32      0.32      0.32      0.32  ...    -0.10     0.09   \n",
              "2010-07-31      0.29      0.29      0.29      0.29  ...    -0.00     0.02   \n",
              "2010-08-31      0.25      0.25      0.25      0.25  ...     0.02    -0.04   \n",
              "2010-09-30      0.27      0.27      0.27      0.27  ...     0.07     0.03   \n",
              "2010-10-31      0.22      0.22      0.22      0.22  ...    -0.03     0.06   \n",
              "...              ...       ...       ...       ...  ...      ...      ...   \n",
              "2023-02-28      5.02      5.02      5.02      5.02  ...    -0.06    -0.03   \n",
              "2023-03-31      4.64      4.64      4.64      4.64  ...     0.02     0.06   \n",
              "2023-04-30      4.80      4.80      4.80      4.80  ...     0.06    -0.02   \n",
              "2023-05-31      5.18      5.18      5.18      5.18  ...    -0.04    -0.05   \n",
              "2023-06-30      5.40      5.40      5.40      5.40  ...     0.15     0.01   \n",
              "\n",
              "            ret_SPGI  ret_SWK  ret_SYY  ret_TGT  ret_TROW  ret_WMT  ret_WST  \\\n",
              "Date                                                                          \n",
              "2010-06-30      0.01    -0.10    -0.03    -0.10     -0.10    -0.05    -0.08   \n",
              "2010-07-31      0.09     0.14     0.08     0.04      0.08     0.06     0.00   \n",
              "2010-08-31     -0.10    -0.08    -0.12     0.00     -0.10    -0.01    -0.08   \n",
              "2010-09-30      0.18     0.14     0.05     0.04      0.14     0.07     0.02   \n",
              "2010-10-31      0.13     0.01     0.03    -0.03      0.10     0.01     0.04   \n",
              "...              ...      ...      ...      ...       ...      ...      ...   \n",
              "2023-02-28     -0.09    -0.04    -0.04    -0.02     -0.04    -0.01     0.18   \n",
              "2023-03-31      0.01    -0.05     0.04    -0.02      0.02     0.04     0.09   \n",
              "2023-04-30      0.05     0.07    -0.00    -0.05     -0.01     0.02     0.04   \n",
              "2023-05-31      0.02    -0.14    -0.09    -0.18     -0.05    -0.02    -0.08   \n",
              "2023-06-30      0.09     0.23     0.06     0.01      0.06     0.07     0.13   \n",
              "\n",
              "            ret_XOM  \n",
              "Date                 \n",
              "2010-06-30    -0.06  \n",
              "2010-07-31     0.04  \n",
              "2010-08-31    -0.00  \n",
              "2010-09-30     0.04  \n",
              "2010-10-31     0.07  \n",
              "...             ...  \n",
              "2023-02-28    -0.05  \n",
              "2023-03-31    -0.00  \n",
              "2023-04-30     0.08  \n",
              "2023-05-31    -0.14  \n",
              "2023-06-30     0.05  \n",
              "\n",
              "[157 rows x 488 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pivot = df.pivot_table(index='Date', columns='Ticker')\n",
        "df_pivot.columns = ['_'.join(col) for col in df_pivot.columns]\n",
        "df_pivot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XsVZafyJ3qE"
      },
      "outputs": [],
      "source": [
        "# let's establish train, validation, and test periods here:\n",
        "trainval_split = 0.85\n",
        "trainval_date_index = df_pivot.index[:int(trainval_split*df_pivot.shape[0])]\n",
        "test_date_index = df_pivot.index[int(trainval_split*df_pivot.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNi7TLpngxBt"
      },
      "outputs": [],
      "source": [
        "# parameters needed for later\n",
        "feature_len = df_pivot.shape[1] - len(x_tickers)\n",
        "label_len = len(x_tickers)\n",
        "# date_index = df_pivot.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_f4-bYogcnR"
      },
      "outputs": [],
      "source": [
        "# need to scale our dataset\n",
        "df_pivot.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# let's re-scale all of the data points\n",
        "scaler = MinMaxScaler()\n",
        "df_pivot_scaled = pd.DataFrame(scaler.fit_transform(df_pivot))\n",
        "\n",
        "# now set test dataset aside for post-training evaluation\n",
        "df_trainval = df_pivot_scaled.iloc[:int(trainval_split*df_pivot.shape[0])]\n",
        "df_test = df_pivot_scaled.iloc[int(trainval_split*df_pivot.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFazESAte1cf",
        "outputId": "1ed98a70-63cd-4263-b215-3be609aee846"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(133, 488)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_trainval.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnY9R1bke29R",
        "outputId": "313d3117-8038-4006-a71c-48e2bdf704c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 488)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HH5Nj8BtiApO"
      },
      "outputs": [],
      "source": [
        "# custom loss function for gradient ascent Sharpe Ratio\n",
        "def negative_sharpe_loss(wts, rets):\n",
        "  mean_return = tf.reduce_mean(tf.reduce_sum(wts * rets, axis=1))\n",
        "  std_return = tf.math.reduce_std(tf.reduce_sum(wts * rets, axis=1))\n",
        "\n",
        "  return -mean_return / std_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po19-_RGuadx"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POFc9J0PjqBv",
        "outputId": "aa08ca3e-665c-45c5-d5f1-1c88cdec53b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "427"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# mlp_input_shape = df_pivot.iloc[:, :-len(x_tickers)].shape[1]\n",
        "mlp_input_shape = df_trainval.iloc[:, :-len(x_tickers)].shape[1]\n",
        "mlp_input_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WANgSq7DOgwo"
      },
      "source": [
        "### MLP Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_lCNj3rOgPI"
      },
      "outputs": [],
      "source": [
        "# # hyperparameters\n",
        "# act_fun = \"relu\"\n",
        "# hidden_layer = 25\n",
        "# n_dropout = 0.2\n",
        "# l_rate = 1e-5\n",
        "# epochs = 100\n",
        "# adam = tf.keras.optimizers.Adam(learning_rate=l_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCbfm1MmP4mo"
      },
      "outputs": [],
      "source": [
        "asset_num = len(x_tickers)\n",
        "n_train = 24\n",
        "n_val = 6\n",
        "batch = 50\n",
        "# validation_split=0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ljwFCdvOgL3"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [64, 128, 256],\n",
        "    'num_hidden_layers': [1, 2],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'optimizer': ['adam', 'sgd'],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'epochs': [50, 100, 200],\n",
        "    'dropout_rate': [0.0, 0.1, 0.2]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXa1BljoPmXC"
      },
      "outputs": [],
      "source": [
        "# Define MLP model\n",
        "def create_MLP_model(custom_loss, asset_num, input_shape, params):\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  for i in range(hl_num):\n",
        "    if i==0:\n",
        "      model.add(tf.keras.layers.Dense(units=params['hidden_layer_sizes'], activation=params['activation'], input_shape=(input_shape,)))\n",
        "    else:\n",
        "      model.add(tf.keras.layers.Dense(units=params['hidden_layer_sizes'], activation=params['activation']))\n",
        "\n",
        "    if n_dropout > 0.0:\n",
        "      model.add(tf.keras.layers.Dropout(params['dropout_rate']))\n",
        "  model.add(tf.keras.layers.Dense(units=asset_num, activation=\"softmax\")) # <- softmax creates long-only portfolios\n",
        "\n",
        "  optimizer_instance = tf.keras.optimizers.get(params['optimizer'])\n",
        "  optimizer_instance.learning_rate = params['learning_rate']\n",
        "\n",
        "  model.compile(optimizer=optimizer_instance, loss=custom_loss)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTUVZI8ePW4C"
      },
      "outputs": [],
      "source": [
        "def walk_forward(n_train, n_val, df, epochs, batch, model, asset_num, best_params, best_score):\n",
        "  n_splits = (df.shape[0] - n_train) // n_val + 1\n",
        "  avg_score = 0.0\n",
        "\n",
        "  preds = []\n",
        "\n",
        "  for i in range(0, df.shape[0] - n_train, n_val):\n",
        "\n",
        "    X_train, y_train = df.iloc[i : i + n_train, :-asset_num], df.iloc[i : i + n_train, -asset_num:]\n",
        "    X_val, y_val = df.iloc[i + n_train : i + n_train + n_val, :-asset_num], df.iloc[i + n_train : i + n_train + n_val, -asset_num:]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch,\n",
        "        validation_data = (X_val, y_val),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val, verbose=0)\n",
        "    preds.append(y_pred)\n",
        "\n",
        "    score = model.evaluate(X_val, y_val, verbose=0)\n",
        "    avg_score += score / n_splits\n",
        "\n",
        "  return preds, avg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf1Q1uyMPBsg",
        "outputId": "b8abc3c8-e934-4ec6-ff93-4273f25f199f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -23.2619 - val_loss: -12.3537\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -21.3563 - val_loss: -12.3941\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -24.5041 - val_loss: -12.4606\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.7386 - val_loss: -12.5388\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -23.2721 - val_loss: -12.6336\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -19.4218 - val_loss: -12.6644\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.5397 - val_loss: -12.6888\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -23.6186 - val_loss: -12.7029\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -23.4036 - val_loss: -12.6975\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -24.3752 - val_loss: -12.6747\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -22.3779 - val_loss: -12.6030\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.1367 - val_loss: -12.5407\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -24.2814 - val_loss: -12.5356\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -24.1638 - val_loss: -12.5434\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -19.8656 - val_loss: -12.5620\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -23.2103 - val_loss: -12.5789\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -25.9313 - val_loss: -12.6004\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.9190 - val_loss: -12.5669\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -18.1427 - val_loss: -12.5867\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.5317 - val_loss: -12.6467\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -26.0277 - val_loss: -12.6968\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.7249 - val_loss: -12.7365\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -23.0939 - val_loss: -12.8499\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -21.7258 - val_loss: -12.9602\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -24.5432 - val_loss: -12.9360\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -21.2025 - val_loss: -12.9622\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -24.5695 - val_loss: -13.0021\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -25.3671 - val_loss: -12.9859\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -25.0404 - val_loss: -12.9056\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -25.8222 - val_loss: -12.7909\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -24.1095 - val_loss: -12.7247\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -25.0024 - val_loss: -12.7202\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.7162 - val_loss: -12.6531\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -24.3807 - val_loss: -12.6208\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -25.1707 - val_loss: -12.6508\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -27.7607 - val_loss: -12.7492\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -24.6108 - val_loss: -12.9154\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -26.3105 - val_loss: -13.0554\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -24.0987 - val_loss: -13.0974\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -27.6328 - val_loss: -13.1280\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -28.1362 - val_loss: -13.2063\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -27.6679 - val_loss: -13.3392\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -22.0405 - val_loss: -13.5787\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -26.4181 - val_loss: -13.6938\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -25.0729 - val_loss: -13.7655\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -23.5071 - val_loss: -13.9325\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -27.1003 - val_loss: -14.0104\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -25.6957 - val_loss: -13.9860\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -22.2364 - val_loss: -13.8874\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -24.6346 - val_loss: -13.9265\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.4608 - val_loss: -13.9782\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -22.0378 - val_loss: -14.0253\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -27.0801 - val_loss: -14.1980\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -27.3233 - val_loss: -14.2183\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -24.0544 - val_loss: -14.1054\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -25.6603 - val_loss: -14.0885\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.1015 - val_loss: -14.0097\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -22.5671 - val_loss: -13.8464\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -25.1245 - val_loss: -13.6023\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -23.7181 - val_loss: -13.3602\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -20.8158 - val_loss: -13.0831\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -28.1791 - val_loss: -12.9413\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -28.5362 - val_loss: -12.8842\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -24.7483 - val_loss: -12.9503\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -25.5805 - val_loss: -12.7629\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -19.1914 - val_loss: -12.6568\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -23.0792 - val_loss: -12.4883\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -30.5575 - val_loss: -12.1618\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -22.6905 - val_loss: -12.2571\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -16.5111 - val_loss: -11.4920\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.4976 - val_loss: -11.7959\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.2297 - val_loss: -12.2120\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.0097 - val_loss: -12.7105\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -14.7356 - val_loss: -13.1360\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.5214 - val_loss: -13.4465\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.8077 - val_loss: -13.5508\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -17.7790 - val_loss: -13.6556\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.8134 - val_loss: -13.5926\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -14.9183 - val_loss: -13.5036\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.3903 - val_loss: -13.2930\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.6926 - val_loss: -12.9824\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.1178 - val_loss: -12.6439\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.8893 - val_loss: -12.3129\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.2900 - val_loss: -12.0833\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.2104 - val_loss: -11.9267\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -19.1719 - val_loss: -11.8261\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.9787 - val_loss: -11.7629\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -20.7294 - val_loss: -11.6930\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.3664 - val_loss: -11.6488\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -20.0568 - val_loss: -11.6146\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -16.2476 - val_loss: -11.5220\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -16.9024 - val_loss: -11.4072\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -20.1035 - val_loss: -11.2779\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.0265 - val_loss: -11.1470\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.0538 - val_loss: -11.0748\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.2150 - val_loss: -11.0119\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -19.2881 - val_loss: -10.9728\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.6716 - val_loss: -10.9037\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -20.2375 - val_loss: -10.8290\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.1013 - val_loss: -10.8360\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.4968 - val_loss: -10.7415\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.6608 - val_loss: -10.6487\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.6177 - val_loss: -10.5334\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.9946 - val_loss: -10.3829\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.9628 - val_loss: -10.2163\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -20.5484 - val_loss: -10.0508\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -20.8687 - val_loss: -9.9120\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -20.5288 - val_loss: -9.7333\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.3443 - val_loss: -9.5243\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -20.3289 - val_loss: -9.3143\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -20.5380 - val_loss: -9.1129\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.1503 - val_loss: -8.9673\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -20.5323 - val_loss: -8.8215\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -21.2318 - val_loss: -8.6753\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -21.0507 - val_loss: -8.5206\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.3376 - val_loss: -8.3500\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.8766 - val_loss: -8.1939\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.0083 - val_loss: -8.0493\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -21.4970 - val_loss: -7.9312\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -19.7361 - val_loss: -7.8120\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.0827 - val_loss: -7.6821\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -18.7918 - val_loss: -7.6155\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -18.0254 - val_loss: -7.5798\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -20.7315 - val_loss: -7.5189\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.2203 - val_loss: -7.5275\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -20.9963 - val_loss: -7.5109\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.7605 - val_loss: -7.4821\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.1377 - val_loss: -7.4665\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -20.3228 - val_loss: -7.4148\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -21.8211 - val_loss: -7.3995\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.6882 - val_loss: -7.3884\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -20.2772 - val_loss: -7.4529\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -22.3048 - val_loss: -7.4873\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.1246 - val_loss: -7.5559\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -20.8906 - val_loss: -7.5398\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.3166 - val_loss: -7.5092\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -22.8731 - val_loss: -7.3864\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.7728 - val_loss: -7.4118\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -14.7833 - val_loss: -7.4675\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -22.0075 - val_loss: -7.4805\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -23.8557 - val_loss: -7.4386\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -20.6789 - val_loss: -7.3489\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -22.5023 - val_loss: -7.4160\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -25.2268 - val_loss: -7.4364\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.5570 - val_loss: -7.4398\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.1462 - val_loss: -7.4989\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -14.9956 - val_loss: -7.5443\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -21.1668 - val_loss: -7.4879\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.5175 - val_loss: -7.3954\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -18.6888 - val_loss: -7.3995\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -21.2219 - val_loss: -7.3733\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -24.7107 - val_loss: -7.3327\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -25.0691 - val_loss: -7.1691\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.1336 - val_loss: -7.1626\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -26.1975 - val_loss: -7.1113\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -25.0765 - val_loss: -6.9707\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -18.9705 - val_loss: -6.9947\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -28.2905 - val_loss: -7.0574\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -27.1045 - val_loss: -7.1030\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -27.2944 - val_loss: -7.1891\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -27.4621 - val_loss: -7.1563\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -22.4713 - val_loss: -7.0551\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.8989 - val_loss: -6.9393\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -23.2411 - val_loss: -6.9789\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.3346 - val_loss: -7.0199\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.9409 - val_loss: -7.0816\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -22.4851 - val_loss: -7.0438\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.7714 - val_loss: -7.0571\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -22.0608 - val_loss: -7.0113\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -11.6290 - val_loss: -10.9583\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.7048 - val_loss: -10.3068\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.6324 - val_loss: -10.1450\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -12.5738 - val_loss: -9.9362\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -11.9627 - val_loss: -9.7056\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -12.6391 - val_loss: -9.4963\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -14.0416 - val_loss: -9.3367\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -12.7263 - val_loss: -9.2070\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -12.2263 - val_loss: -9.1078\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.0195 - val_loss: -9.0215\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -14.2705 - val_loss: -8.9618\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -13.6220 - val_loss: -8.9195\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -15.4626 - val_loss: -8.8793\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -13.9275 - val_loss: -8.8502\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -13.3025 - val_loss: -8.8337\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.5934 - val_loss: -8.8313\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -14.3029 - val_loss: -8.8307\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -13.5235 - val_loss: -8.8364\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -14.9461 - val_loss: -8.8549\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -13.3804 - val_loss: -8.8799\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -13.9572 - val_loss: -8.9085\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.2862 - val_loss: -8.9350\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -13.9940 - val_loss: -8.9658\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -13.4907 - val_loss: -8.9975\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.2951 - val_loss: -9.0318\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -14.3206 - val_loss: -9.0684\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -15.1623 - val_loss: -9.1110\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -15.7629 - val_loss: -9.1563\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.3292 - val_loss: -9.2115\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -15.0751 - val_loss: -9.2769\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.0205 - val_loss: -9.3486\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.2202 - val_loss: -9.4289\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -14.2723 - val_loss: -9.5383\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -15.5540 - val_loss: -9.6754\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.2251 - val_loss: -9.8521\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.0347 - val_loss: -10.0417\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.4909 - val_loss: -10.2504\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -16.3024 - val_loss: -10.4324\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -16.2321 - val_loss: -10.5651\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.5792 - val_loss: -10.6541\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.0808 - val_loss: -10.7025\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.3658 - val_loss: -10.7169\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -17.3334 - val_loss: -10.7075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.1034 - val_loss: -10.6727\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -16.7946 - val_loss: -10.6306\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -17.5734 - val_loss: -10.5539\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.1597 - val_loss: -10.4179\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.6636 - val_loss: -10.2742\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -17.0521 - val_loss: -10.1145\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.7595 - val_loss: -9.9382\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.0171 - val_loss: -9.8032\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.5719 - val_loss: -9.7557\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.0584 - val_loss: -9.7160\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.2390 - val_loss: -9.7351\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.1164 - val_loss: -9.7938\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.6375 - val_loss: -9.9203\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.5029 - val_loss: -10.0527\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.1101 - val_loss: -10.2055\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.5486 - val_loss: -10.3310\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.5806 - val_loss: -10.3913\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.9952 - val_loss: -10.4673\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.9249 - val_loss: -10.4902\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.1199 - val_loss: -10.4832\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -17.4670 - val_loss: -10.4134\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -16.0130 - val_loss: -10.3148\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.7007 - val_loss: -10.2615\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.3222 - val_loss: -10.2193\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.7543 - val_loss: -10.2069\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -16.3752 - val_loss: -10.1884\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.1960 - val_loss: -10.2077\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -15.3899 - val_loss: -10.2357\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.6648 - val_loss: -10.2631\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.6343 - val_loss: -10.3029\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.3123 - val_loss: -10.3308\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.7033 - val_loss: -10.3751\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.3275 - val_loss: -10.3988\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -19.3828 - val_loss: -10.4176\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.2805 - val_loss: -10.4431\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -17.1697 - val_loss: -10.4620\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.7074 - val_loss: -10.5221\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -16.0965 - val_loss: -10.5747\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.9878 - val_loss: -10.6482\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.5665 - val_loss: -10.7188\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -16.7066 - val_loss: -10.7571\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -17.5519 - val_loss: -10.7865\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.3787 - val_loss: -10.7877\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -17.3024 - val_loss: -10.7682\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -19.2836 - val_loss: -10.7491\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -18.8960 - val_loss: -10.7230\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -19.2089 - val_loss: -10.6969\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -18.6998 - val_loss: -10.6825\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.9316 - val_loss: -10.6605\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -17.8728 - val_loss: -10.6477\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.9371 - val_loss: -10.6303\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.8371 - val_loss: -10.6011\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.5489 - val_loss: -10.5639\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.5603 - val_loss: -10.5087\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.0531 - val_loss: -10.4414\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.0718 - val_loss: -10.3749\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.7801 - val_loss: -10.3183\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -14.2488 - val_loss: -20.6024\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -14.5135 - val_loss: -20.9258\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.0734 - val_loss: -21.1972\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -13.3258 - val_loss: -21.7154\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.1750 - val_loss: -22.2415\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.6357 - val_loss: -22.6529\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.3582 - val_loss: -22.8561\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -13.8554 - val_loss: -22.8746\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -13.1679 - val_loss: -22.8640\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -14.7727 - val_loss: -22.8294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -15.7214 - val_loss: -22.8702\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -15.2693 - val_loss: -22.9698\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -13.3076 - val_loss: -23.0777\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -15.7439 - val_loss: -23.4124\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.6625 - val_loss: -23.7831\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.4833 - val_loss: -24.1532\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.7238 - val_loss: -24.4835\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -12.1371 - val_loss: -24.7844\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -15.0077 - val_loss: -25.0627\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.4317 - val_loss: -25.2966\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.6911 - val_loss: -25.4508\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -16.4981 - val_loss: -25.7310\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -15.5892 - val_loss: -25.9778\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -14.2729 - val_loss: -26.2218\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -16.2380 - val_loss: -26.5771\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -15.8940 - val_loss: -26.7512\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.1314 - val_loss: -26.9077\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -15.3586 - val_loss: -26.9404\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -14.8904 - val_loss: -26.8543\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -13.5174 - val_loss: -26.5308\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.8468 - val_loss: -25.9401\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -14.3972 - val_loss: -25.3369\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.8107 - val_loss: -24.7682\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -15.1531 - val_loss: -24.0011\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -15.9838 - val_loss: -23.3484\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.4821 - val_loss: -22.8137\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -15.4309 - val_loss: -22.4108\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -11.9258 - val_loss: -22.0986\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -14.2779 - val_loss: -21.9642\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.4079 - val_loss: -21.9648\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.5760 - val_loss: -22.0958\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -15.9935 - val_loss: -22.3823\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -15.2240 - val_loss: -22.7903\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.9683 - val_loss: -23.1737\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -14.6384 - val_loss: -23.3697\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.8467 - val_loss: -23.6680\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -14.4873 - val_loss: -23.8195\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.4590 - val_loss: -24.0459\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -16.5364 - val_loss: -23.9718\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.3548 - val_loss: -23.8742\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.1561 - val_loss: -23.5953\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.6663 - val_loss: -23.0540\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.9881 - val_loss: -22.5612\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.8602 - val_loss: -22.0368\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -15.1369 - val_loss: -21.5526\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.3122 - val_loss: -21.1548\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.6861 - val_loss: -20.8422\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -17.1753 - val_loss: -20.6598\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -14.9578 - val_loss: -20.6324\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.9404 - val_loss: -20.7973\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.2741 - val_loss: -21.1990\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -15.8409 - val_loss: -21.4171\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -14.8358 - val_loss: -21.6220\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.6533 - val_loss: -21.8229\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.4084 - val_loss: -21.8402\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -13.9116 - val_loss: -21.8401\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -16.8104 - val_loss: -21.4766\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -16.4230 - val_loss: -20.9540\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.3103 - val_loss: -20.2960\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.5128 - val_loss: -19.6367\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.5335 - val_loss: -18.9786\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.5133 - val_loss: -18.4613\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -15.9785 - val_loss: -18.0423\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.6806 - val_loss: -17.8624\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.3523 - val_loss: -17.8600\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.3769 - val_loss: -17.9956\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.9891 - val_loss: -18.0959\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.5726 - val_loss: -18.4207\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.8347 - val_loss: -18.7292\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -17.4216 - val_loss: -19.1600\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -14.7494 - val_loss: -19.5359\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.0316 - val_loss: -19.7266\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -18.1351 - val_loss: -19.6896\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.4764 - val_loss: -19.6630\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -15.2748 - val_loss: -19.5574\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -16.6385 - val_loss: -19.3642\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.9033 - val_loss: -19.2782\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -16.6206 - val_loss: -19.1996\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -16.9697 - val_loss: -18.9496\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.9567 - val_loss: -18.6546\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.7776 - val_loss: -18.5547\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.9084 - val_loss: -18.3924\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.8696 - val_loss: -18.3767\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.7940 - val_loss: -18.2200\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.4643 - val_loss: -18.0733\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.0338 - val_loss: -17.7667\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -18.2366 - val_loss: -17.4455\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.0325 - val_loss: -17.1116\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.3997 - val_loss: -16.7538\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -15.5064 - val_loss: -16.5041\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -15.5352 - val_loss: -9.7694\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.5499 - val_loss: -9.7730\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -16.4538 - val_loss: -9.8442\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -15.5591 - val_loss: -9.9574\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -17.5079 - val_loss: -10.1424\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.4288 - val_loss: -10.4276\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -14.7660 - val_loss: -10.7893\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -13.1106 - val_loss: -11.1910\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -12.5367 - val_loss: -11.5440\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -16.5826 - val_loss: -11.7955\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.0585 - val_loss: -12.0940\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -17.7831 - val_loss: -12.2113\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.8008 - val_loss: -12.4520\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -17.3622 - val_loss: -12.5893\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.7785 - val_loss: -12.8668\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.8257 - val_loss: -12.9849\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -18.1733 - val_loss: -12.9512\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.5370 - val_loss: -12.7425\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -17.4095 - val_loss: -12.5587\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -19.0713 - val_loss: -12.6298\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.5733 - val_loss: -12.6443\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -13.2323 - val_loss: -12.6627\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.7616 - val_loss: -12.8081\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -14.4735 - val_loss: -12.9593\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -20.2260 - val_loss: -13.0035\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.7617 - val_loss: -12.9992\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -17.8588 - val_loss: -12.6720\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.8816 - val_loss: -12.3818\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -17.6326 - val_loss: -12.1659\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.7766 - val_loss: -12.0585\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.2218 - val_loss: -12.0899\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.7840 - val_loss: -12.1177\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -13.5252 - val_loss: -12.2912\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -19.2350 - val_loss: -12.5166\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -19.1821 - val_loss: -12.8159\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.5611 - val_loss: -13.0599\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -19.4829 - val_loss: -13.5461\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.2207 - val_loss: -13.9184\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.2902 - val_loss: -13.9421\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -18.7497 - val_loss: -13.6230\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -16.1568 - val_loss: -13.1490\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -18.9945 - val_loss: -12.6991\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.4185 - val_loss: -12.4194\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.4114 - val_loss: -12.3273\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.8271 - val_loss: -12.2719\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -18.2662 - val_loss: -12.3298\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -18.6354 - val_loss: -12.5648\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.1694 - val_loss: -12.8702\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -18.7279 - val_loss: -13.1159\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.1996 - val_loss: -13.4076\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -14.3446 - val_loss: -13.5736\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -19.5613 - val_loss: -13.6413\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -17.5280 - val_loss: -13.5096\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.5414 - val_loss: -13.4583\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.3905 - val_loss: -13.2456\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.2601 - val_loss: -12.9656\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -16.1926 - val_loss: -12.6720\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -20.5108 - val_loss: -12.4402\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -17.6633 - val_loss: -12.2183\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.9938 - val_loss: -12.2262\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.1061 - val_loss: -12.3787\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.8835 - val_loss: -12.4801\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.5141 - val_loss: -12.6505\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -17.8957 - val_loss: -12.6439\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -19.4633 - val_loss: -12.5129\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.1190 - val_loss: -12.4159\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.0386 - val_loss: -12.5255\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.6190 - val_loss: -12.9503\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.6365 - val_loss: -13.3898\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -19.3493 - val_loss: -13.6629\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -16.6419 - val_loss: -14.0043\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -18.8993 - val_loss: -14.3679\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.9769 - val_loss: -14.3241\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -16.1907 - val_loss: -14.0402\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -18.5365 - val_loss: -13.4921\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -15.3647 - val_loss: -12.7803\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -15.0022 - val_loss: -12.2631\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.7560 - val_loss: -11.9636\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -19.1048 - val_loss: -12.1091\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -16.6354 - val_loss: -12.3299\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.0498 - val_loss: -12.6993\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -20.3942 - val_loss: -12.8539\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -17.9803 - val_loss: -12.9794\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.5739 - val_loss: -13.0766\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -19.5088 - val_loss: -13.1656\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -17.6682 - val_loss: -13.3900\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -18.6157 - val_loss: -13.3746\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -19.6201 - val_loss: -13.2954\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -19.3612 - val_loss: -13.4571\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -19.7086 - val_loss: -13.5429\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -20.9492 - val_loss: -13.7887\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -20.5527 - val_loss: -13.5266\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -18.5005 - val_loss: -13.4292\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -18.7666 - val_loss: -13.2951\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.6014 - val_loss: -13.2143\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -17.8637 - val_loss: -13.1413\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -19.8329 - val_loss: -13.3814\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.1762 - val_loss: -13.6457\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.3052 - val_loss: -13.9763\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.6128 - val_loss: -14.1937\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -13.2162 - val_loss: -14.7144\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -12.3069 - val_loss: -17.4367\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.8038 - val_loss: -20.9311\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -15.0663 - val_loss: -21.3076\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -14.2757 - val_loss: -20.9834\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -13.9958 - val_loss: -20.7096\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -14.7357 - val_loss: -21.0245\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -13.5598 - val_loss: -21.3017\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.0375 - val_loss: -20.8472\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.9187 - val_loss: -19.7106\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.6710 - val_loss: -18.7340\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -14.7493 - val_loss: -18.1981\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -12.0950 - val_loss: -18.3620\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.9858 - val_loss: -18.3052\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -13.4905 - val_loss: -18.1759\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.1573 - val_loss: -18.4633\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -14.4003 - val_loss: -19.0076\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.7213 - val_loss: -19.7207\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.8885 - val_loss: -21.2613\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -13.7312 - val_loss: -20.7322\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.0765 - val_loss: -19.8299\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -14.9244 - val_loss: -19.9792\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.7669 - val_loss: -20.7037\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.7622 - val_loss: -20.5879\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -13.9147 - val_loss: -20.7463\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -13.2640 - val_loss: -20.8071\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.2382 - val_loss: -20.5761\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.4904 - val_loss: -19.8382\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.2012 - val_loss: -19.3447\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.8084 - val_loss: -18.9429\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -15.7072 - val_loss: -18.5622\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -15.0931 - val_loss: -17.9154\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -14.7637 - val_loss: -17.3117\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -15.9972 - val_loss: -16.9299\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.8178 - val_loss: -16.6723\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -15.4083 - val_loss: -16.5277\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.9802 - val_loss: -16.6310\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.2696 - val_loss: -16.4221\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.2159 - val_loss: -16.2609\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.2077 - val_loss: -16.2064\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.0224 - val_loss: -15.9839\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.9212 - val_loss: -15.5738\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.6374 - val_loss: -15.2147\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.6242 - val_loss: -15.1985\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.7729 - val_loss: -15.4356\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.1374 - val_loss: -15.7561\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.0167 - val_loss: -16.1256\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.1060 - val_loss: -16.1656\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.3427 - val_loss: -16.0667\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -15.9896 - val_loss: -15.7065\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.6776 - val_loss: -15.3396\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -12.8843 - val_loss: -15.0253\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.8096 - val_loss: -15.0662\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -13.4146 - val_loss: -15.6371\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.1976 - val_loss: -16.5514\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.0042 - val_loss: -17.0055\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.7161 - val_loss: -17.1679\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -17.8618 - val_loss: -16.4268\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.2168 - val_loss: -14.9348\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -18.0321 - val_loss: -12.8133\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.5061 - val_loss: -10.8598\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -13.6190 - val_loss: -9.8330\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -15.5605 - val_loss: -9.7480\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.2436 - val_loss: -10.2071\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.5293 - val_loss: -10.4093\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.8680 - val_loss: -10.8855\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.2648 - val_loss: -11.4726\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -17.5280 - val_loss: -11.3995\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -19.0441 - val_loss: -10.7728\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -19.8383 - val_loss: -10.3362\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.5251 - val_loss: -10.0805\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.9498 - val_loss: -10.4647\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.7649 - val_loss: -11.3127\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.7261 - val_loss: -12.8021\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -18.9929 - val_loss: -14.6602\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -16.6950 - val_loss: -15.4720\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.2682 - val_loss: -16.0709\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -19.9817 - val_loss: -16.5614\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.2658 - val_loss: -16.1266\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.4716 - val_loss: -14.2470\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -19.4072 - val_loss: -12.1593\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -23.0283 - val_loss: -10.6069\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.8168 - val_loss: -9.6916\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -22.8445 - val_loss: -9.3522\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -22.2619 - val_loss: -9.6130\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -19.1962 - val_loss: -10.1988\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.3167 - val_loss: -10.6808\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.2851 - val_loss: -10.4946\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.3612 - val_loss: -10.1326\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.6500 - val_loss: -9.6909\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -18.7910 - val_loss: -9.1143\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.8767 - val_loss: -8.5776\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.1345 - val_loss: -8.4996\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.8535 - val_loss: -8.4491\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -18.5789 - val_loss: -8.6998\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -17.3909 - val_loss: -9.1816\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -21.4944 - val_loss: -10.2862\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -21.0588 - val_loss: -10.6659\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -19.1210 - val_loss: -10.2873\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -19.6044 - val_loss: -9.5186\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -15.8167 - val_loss: -10.2360\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -13.0892 - val_loss: -10.8159\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -13.7252 - val_loss: -11.3601\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.4100 - val_loss: -10.6827\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.4072 - val_loss: -9.5611\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -16.6720 - val_loss: -8.8519\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -14.8944 - val_loss: -8.2468\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -13.9733 - val_loss: -8.1328\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.3777 - val_loss: -8.4146\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -15.5237 - val_loss: -9.0745\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.4978 - val_loss: -10.1957\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.7074 - val_loss: -10.6086\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -12.3186 - val_loss: -10.6911\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -14.6342 - val_loss: -10.5231\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.2204 - val_loss: -9.9259\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -14.3159 - val_loss: -9.5113\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.4508 - val_loss: -9.3173\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.8669 - val_loss: -9.2490\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.1687 - val_loss: -9.2474\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -16.8467 - val_loss: -9.3912\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -16.7813 - val_loss: -9.7592\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.9802 - val_loss: -10.3187\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.5517 - val_loss: -11.1689\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.2430 - val_loss: -11.7858\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.6262 - val_loss: -12.1117\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -15.4691 - val_loss: -12.1110\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -15.8099 - val_loss: -12.0016\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -14.7960 - val_loss: -11.8497\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.0749 - val_loss: -11.3309\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.7076 - val_loss: -10.4127\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.4578 - val_loss: -9.6689\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.7189 - val_loss: -9.3206\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -16.3452 - val_loss: -9.1644\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.9951 - val_loss: -9.2310\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.8760 - val_loss: -9.5728\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -12.4680 - val_loss: -10.1784\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -13.5745 - val_loss: -10.9625\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -17.0902 - val_loss: -11.4918\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -16.7323 - val_loss: -11.7147\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -12.0787 - val_loss: -11.8679\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.0851 - val_loss: -11.7241\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -16.9285 - val_loss: -11.3075\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.9555 - val_loss: -10.8729\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -17.2407 - val_loss: -10.4303\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -13.3419 - val_loss: -10.0886\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.3978 - val_loss: -9.9486\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -17.3769 - val_loss: -9.9279\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.8916 - val_loss: -9.9923\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.1988 - val_loss: -10.2474\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.6298 - val_loss: -10.7707\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.3149 - val_loss: -11.1115\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.3122 - val_loss: -11.1642\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -16.3863 - val_loss: -10.9482\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.0621 - val_loss: -10.6634\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.6838 - val_loss: -10.3340\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.5457 - val_loss: -10.0861\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.2900 - val_loss: -9.6980\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -16.8574 - val_loss: -9.8237\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.5068 - val_loss: -10.0836\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.2859 - val_loss: -10.1562\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.3565 - val_loss: -10.5075\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -18.5425 - val_loss: -10.4518\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.2036 - val_loss: -10.8027\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.2140 - val_loss: -10.9952\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.9414 - val_loss: -10.9102\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -14.8661 - val_loss: -10.7025\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -16.9982 - val_loss: -10.3651\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -17.3203 - val_loss: -9.8400\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -17.4909 - val_loss: -9.5241\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.6564 - val_loss: -9.3981\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.0690 - val_loss: -9.5314\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.5346 - val_loss: -9.7853\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.7330 - val_loss: -10.1751\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.8184 - val_loss: -10.6566\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -15.6167 - val_loss: -11.1779\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -17.6501 - val_loss: -11.3917\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.5421 - val_loss: -11.5666\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.6986 - val_loss: -11.4991\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.8883 - val_loss: -11.0313\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.1747 - val_loss: -10.3999\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.1815 - val_loss: -9.7331\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -14.0740 - val_loss: -9.0913\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.6550 - val_loss: -8.8215\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.7158 - val_loss: -8.7663\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -14.3116 - val_loss: -8.8395\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.5139 - val_loss: -9.2190\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.2637 - val_loss: -9.9763\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.6912 - val_loss: -11.1891\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.5202 - val_loss: -11.6533\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -17.5379 - val_loss: -11.6316\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.2294 - val_loss: -11.0029\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.0804 - val_loss: -10.1821\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -19.1997 - val_loss: -9.5606\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.4976 - val_loss: -9.3119\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -16.1844 - val_loss: -9.3863\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.2189 - val_loss: -9.4257\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.5979 - val_loss: -9.4984\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.1498 - val_loss: -9.5330\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -16.5541 - val_loss: -9.3173\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -15.9825 - val_loss: -9.2965\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -13.6469 - val_loss: -7.4126\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -13.5528 - val_loss: -7.6974\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.0218 - val_loss: -7.9490\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -13.4850 - val_loss: -8.0834\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -12.8764 - val_loss: -8.0614\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.8602 - val_loss: -7.9648\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.1662 - val_loss: -7.9158\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -14.9232 - val_loss: -7.8703\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -14.1848 - val_loss: -7.8983\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -14.9157 - val_loss: -7.8348\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.2117 - val_loss: -7.6714\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.4137 - val_loss: -7.4615\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.7952 - val_loss: -7.3055\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.7904 - val_loss: -7.2076\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.6175 - val_loss: -7.1954\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.6555 - val_loss: -7.2755\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -13.1697 - val_loss: -7.4364\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.2747 - val_loss: -7.6299\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -15.5184 - val_loss: -7.7544\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -14.1094 - val_loss: -7.8247\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -14.9099 - val_loss: -7.8558\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -14.6320 - val_loss: -7.7806\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.3116 - val_loss: -7.6932\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -15.3005 - val_loss: -7.5838\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.2615 - val_loss: -7.4932\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.0370 - val_loss: -7.4329\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -12.0898 - val_loss: -7.3981\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -14.2313 - val_loss: -7.3935\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -15.7477 - val_loss: -7.4003\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -15.2316 - val_loss: -7.4081\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.1253 - val_loss: -7.4108\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -14.8307 - val_loss: -7.4485\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -15.3142 - val_loss: -7.4907\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -14.7018 - val_loss: -7.5371\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.7835 - val_loss: -7.5874\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -14.8611 - val_loss: -7.6244\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -15.6269 - val_loss: -7.6517\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -15.3753 - val_loss: -7.6682\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -15.9878 - val_loss: -7.6228\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -13.2022 - val_loss: -7.5855\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -15.2735 - val_loss: -7.5495\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.4569 - val_loss: -7.5088\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -14.4039 - val_loss: -7.5016\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.5027 - val_loss: -7.5109\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -13.6404 - val_loss: -7.5131\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -14.2165 - val_loss: -7.5306\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.2419 - val_loss: -7.5711\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -14.6333 - val_loss: -7.6288\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.9159 - val_loss: -7.6937\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -14.6375 - val_loss: -7.7560\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.4599 - val_loss: -7.8611\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.7970 - val_loss: -7.8643\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -15.5815 - val_loss: -7.8211\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.0019 - val_loss: -7.7369\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -15.1918 - val_loss: -7.6553\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -14.8187 - val_loss: -7.5747\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -14.7997 - val_loss: -7.5057\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -14.5873 - val_loss: -7.4615\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.2293 - val_loss: -7.4402\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -15.0757 - val_loss: -7.4500\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -14.0041 - val_loss: -7.4958\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.2397 - val_loss: -7.5571\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.0538 - val_loss: -7.5826\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.4336 - val_loss: -7.6025\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.9028 - val_loss: -7.6309\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.3982 - val_loss: -7.6558\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -15.1607 - val_loss: -7.6793\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.7843 - val_loss: -7.6955\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -12.9907 - val_loss: -7.6912\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.0001 - val_loss: -7.6730\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -14.9970 - val_loss: -7.6524\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -15.1445 - val_loss: -7.6288\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -14.7514 - val_loss: -7.5938\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.4792 - val_loss: -7.5636\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -15.3648 - val_loss: -7.5497\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -14.6706 - val_loss: -7.5667\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.8405 - val_loss: -7.5832\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.6125 - val_loss: -7.6298\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.2554 - val_loss: -7.6576\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -15.2410 - val_loss: -7.6655\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.2655 - val_loss: -7.6643\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -16.0859 - val_loss: -7.6376\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.9709 - val_loss: -7.6279\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -15.9614 - val_loss: -7.6576\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -14.3927 - val_loss: -7.6914\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -15.2349 - val_loss: -7.7129\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.5590 - val_loss: -7.7102\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.3369 - val_loss: -7.6968\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.4454 - val_loss: -7.6328\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -15.1977 - val_loss: -7.5685\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -14.2160 - val_loss: -7.5342\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.7537 - val_loss: -7.4970\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -14.5175 - val_loss: -7.4728\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.2763 - val_loss: -7.4544\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.0971 - val_loss: -7.4586\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.3505 - val_loss: -7.4959\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -15.5928 - val_loss: -7.5469\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -13.2362 - val_loss: -7.6036\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.5997 - val_loss: -7.6550\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -15.4004 - val_loss: -7.7097\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -11.3495 - val_loss: -18.0371\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -11.2275 - val_loss: -18.0258\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.2077 - val_loss: -18.0372\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.4661 - val_loss: -18.0517\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -10.0532 - val_loss: -18.0644\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -11.2802 - val_loss: -18.0696\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -10.7742 - val_loss: -18.0694\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.4545 - val_loss: -18.0809\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -10.9917 - val_loss: -18.0893\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.3424 - val_loss: -18.1140\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -10.9846 - val_loss: -18.1511\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.6480 - val_loss: -18.1895\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.3883 - val_loss: -18.2150\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.2714 - val_loss: -18.2044\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -11.4189 - val_loss: -18.1950\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -10.6826 - val_loss: -18.1592\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -11.4644 - val_loss: -18.1240\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.1605 - val_loss: -18.1120\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -10.5587 - val_loss: -18.0889\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -11.1609 - val_loss: -18.0797\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.2871 - val_loss: -18.0881\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.2464 - val_loss: -18.0786\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.2485 - val_loss: -18.0825\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -11.0988 - val_loss: -18.0816\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -10.8456 - val_loss: -18.0527\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.3648 - val_loss: -18.0224\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.4712 - val_loss: -17.9832\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.7128 - val_loss: -17.9690\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.5704 - val_loss: -17.9443\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -10.9838 - val_loss: -17.9186\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -11.3003 - val_loss: -17.8891\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -9.0529 - val_loss: -17.8448\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -10.4262 - val_loss: -17.8525\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.7456 - val_loss: -17.8422\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.0818 - val_loss: -17.8437\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.1438 - val_loss: -17.9382\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.5687 - val_loss: -18.0833\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.5738 - val_loss: -18.2170\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.6284 - val_loss: -18.3360\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.1590 - val_loss: -18.4387\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.5686 - val_loss: -18.5136\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -10.4514 - val_loss: -18.5761\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.5162 - val_loss: -18.6103\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -11.5599 - val_loss: -18.6165\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.1622 - val_loss: -18.6330\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.3209 - val_loss: -18.6330\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -11.3369 - val_loss: -18.6352\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -10.2679 - val_loss: -18.6249\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.5354 - val_loss: -18.6013\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -11.7402 - val_loss: -18.5802\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -10.9700 - val_loss: -18.5571\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -11.2855 - val_loss: -18.5328\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -12.0275 - val_loss: -18.5207\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.4310 - val_loss: -18.4949\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.7242 - val_loss: -18.4739\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -11.7136 - val_loss: -18.4660\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -11.3163 - val_loss: -18.4666\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.4982 - val_loss: -18.4294\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.2737 - val_loss: -18.3992\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -10.9653 - val_loss: -18.3675\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.1744 - val_loss: -18.3162\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -10.4530 - val_loss: -18.3005\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -11.6737 - val_loss: -18.2789\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -9.7260 - val_loss: -18.2419\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -11.4514 - val_loss: -18.2126\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.2526 - val_loss: -18.1973\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -11.2610 - val_loss: -18.1920\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -10.3393 - val_loss: -18.1358\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.1985 - val_loss: -18.0959\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.5233 - val_loss: -18.0513\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.2321 - val_loss: -18.0150\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.5758 - val_loss: -17.9969\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -10.6453 - val_loss: -17.9527\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -11.1992 - val_loss: -17.9005\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.0854 - val_loss: -17.8175\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -11.2191 - val_loss: -17.7705\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.3839 - val_loss: -17.7944\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -11.2066 - val_loss: -17.8716\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -11.7496 - val_loss: -17.9507\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -10.7781 - val_loss: -18.0224\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.3327 - val_loss: -18.0524\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.7235 - val_loss: -18.0628\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -11.2327 - val_loss: -18.0828\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -11.0535 - val_loss: -18.0959\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -11.0541 - val_loss: -18.0949\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.9317 - val_loss: -18.1041\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.0108 - val_loss: -18.0901\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -10.2481 - val_loss: -18.0765\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.3168 - val_loss: -18.0745\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.1535 - val_loss: -18.1394\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -11.5865 - val_loss: -18.1971\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.3177 - val_loss: -18.2372\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.5154 - val_loss: -18.2744\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -11.7742 - val_loss: -18.3066\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -8.1910 - val_loss: -18.3144\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.0730 - val_loss: -18.3098\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -11.3163 - val_loss: -18.3038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.7583 - val_loss: -18.2638\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -12.0720 - val_loss: -18.2337\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -11.1719 - val_loss: -18.2053\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -9.7585 - val_loss: -2.2833\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.3528 - val_loss: -2.2836\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -12.0653 - val_loss: -2.2838\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -10.6271 - val_loss: -2.2851\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -12.0081 - val_loss: -2.2857\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.9167 - val_loss: -2.2789\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.7865 - val_loss: -2.2855\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.8591 - val_loss: -2.2853\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -10.0048 - val_loss: -2.2852\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -11.9933 - val_loss: -2.2844\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.5492 - val_loss: -2.2832\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.3799 - val_loss: -2.2825\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -11.9187 - val_loss: -2.2814\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.1048 - val_loss: -2.2812\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -11.9019 - val_loss: -2.2797\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -12.4431 - val_loss: -2.2782\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -11.7582 - val_loss: -2.2775\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -12.2292 - val_loss: -2.2762\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.9265 - val_loss: -2.2759\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.9153 - val_loss: -2.2758\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -12.2694 - val_loss: -2.2755\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.9731 - val_loss: -2.2747\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -12.9203 - val_loss: -2.2740\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.7228 - val_loss: -2.2734\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.5987 - val_loss: -2.2736\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.1364 - val_loss: -2.2748\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.9524 - val_loss: -2.2759\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.6719 - val_loss: -2.2767\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.1260 - val_loss: -2.2764\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -11.9308 - val_loss: -2.2759\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.0364 - val_loss: -2.2766\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.1124 - val_loss: -2.2775\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.9585 - val_loss: -2.2782\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.9733 - val_loss: -2.2784\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.5161 - val_loss: -2.2779\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.5634 - val_loss: -2.2773\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -11.3808 - val_loss: -2.2761\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -12.5556 - val_loss: -2.2731\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.9945 - val_loss: -2.2709\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -12.1910 - val_loss: -2.2691\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -9.7690 - val_loss: -2.2673\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.6230 - val_loss: -2.2655\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.9365 - val_loss: -2.2625\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.4942 - val_loss: -2.2604\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.8668 - val_loss: -2.2578\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.7940 - val_loss: -2.2543\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -12.3213 - val_loss: -2.2516\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.2874 - val_loss: -2.2496\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -12.1275 - val_loss: -2.2470\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -11.8263 - val_loss: -2.2452\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -11.3027 - val_loss: -2.2435\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -12.1571 - val_loss: -2.2409\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -12.0100 - val_loss: -2.2380\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -12.0781 - val_loss: -2.2363\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -11.5048 - val_loss: -2.2349\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.4953 - val_loss: -2.2349\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -11.1619 - val_loss: -2.2346\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -9.7681 - val_loss: -2.2344\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.8853 - val_loss: -2.2359\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -12.4415 - val_loss: -2.2379\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.7760 - val_loss: -2.2391\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.0115 - val_loss: -2.2384\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -11.9313 - val_loss: -2.2383\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -8.8014 - val_loss: -2.2376\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -12.6318 - val_loss: -2.2359\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.5118 - val_loss: -2.2337\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -8.5399 - val_loss: -2.2311\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.5035 - val_loss: -2.2284\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -12.2337 - val_loss: -2.2249\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -11.6251 - val_loss: -2.2223\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -12.7043 - val_loss: -2.2180\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.7750 - val_loss: -2.2144\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.1479 - val_loss: -2.2107\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -11.6079 - val_loss: -2.2088\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -8.6268 - val_loss: -2.2072\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -11.7266 - val_loss: -2.2058\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -11.9029 - val_loss: -2.2057\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.0756 - val_loss: -2.2058\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -12.5354 - val_loss: -2.2055\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.4676 - val_loss: -2.2045\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -12.0440 - val_loss: -2.2037\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -12.0134 - val_loss: -2.2031\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -12.7528 - val_loss: -2.2023\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -12.4855 - val_loss: -2.2012\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.4376 - val_loss: -2.2008\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -12.6384 - val_loss: -2.2001\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -12.3797 - val_loss: -2.1992\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -12.2484 - val_loss: -2.1983\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -10.8021 - val_loss: -2.1969\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.7685 - val_loss: -2.1962\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -10.8479 - val_loss: -2.1954\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.8242 - val_loss: -2.1942\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -12.8388 - val_loss: -2.1928\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.6825 - val_loss: -2.1920\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -12.3384 - val_loss: -2.1911\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -12.5270 - val_loss: -2.1905\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -11.5601 - val_loss: -2.1893\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -11.8774 - val_loss: -2.1886\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -12.3967 - val_loss: -2.1879\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.2346 - val_loss: -2.1867\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -4.3506 - val_loss: -6.0346\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -5.2233 - val_loss: -6.4190\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -5.1827 - val_loss: -5.0953\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -5.1258 - val_loss: -4.7209\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -5.5508 - val_loss: -5.0847\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -6.7271 - val_loss: -5.0134\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -6.4932 - val_loss: -4.4079\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -7.5058 - val_loss: -4.2579\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -7.7684 - val_loss: -4.8903\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -7.8772 - val_loss: -6.4580\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -8.8599 - val_loss: -7.8608\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -8.2787 - val_loss: -8.8617\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.9328 - val_loss: -8.2258\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -8.7979 - val_loss: -9.6413\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -9.0022 - val_loss: -8.4727\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -8.0973 - val_loss: -7.8871\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -10.6755 - val_loss: -6.8246\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -4.7110 - val_loss: -5.4808\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -9.7876 - val_loss: -5.6352\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -10.1974 - val_loss: -5.5769\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -7.7605 - val_loss: -5.8205\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -9.9158 - val_loss: -5.7330\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.7262 - val_loss: -5.3448\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -9.6857 - val_loss: -5.2069\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -8.7226 - val_loss: -5.2118\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -8.0211 - val_loss: -5.2765\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -8.9940 - val_loss: -5.3865\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -10.3238 - val_loss: -5.4254\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -10.1106 - val_loss: -5.3999\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -10.1317 - val_loss: -5.4239\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -9.8590 - val_loss: -5.4403\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -9.9528 - val_loss: -5.3864\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -9.9271 - val_loss: -5.3745\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -9.9347 - val_loss: -5.4594\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -9.5656 - val_loss: -5.3048\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.9553 - val_loss: -5.2658\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -10.3977 - val_loss: -5.3700\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -10.2055 - val_loss: -5.3160\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -10.4190 - val_loss: -5.2163\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -10.0859 - val_loss: -5.1975\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -10.6723 - val_loss: -5.3596\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -9.9610 - val_loss: -5.0846\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -9.7048 - val_loss: -5.2470\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -10.4491 - val_loss: -5.7923\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -8.6446 - val_loss: -5.7845\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -4.7937 - val_loss: -5.7806\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -4.4616 - val_loss: -5.7780\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -4.3174 - val_loss: -5.7761\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -4.3571 - val_loss: -5.7750\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -4.3299 - val_loss: -5.7747\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -4.1576 - val_loss: -5.7755\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -4.5028 - val_loss: -5.7779\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -7.4483 - val_loss: -5.7824\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -5.0412 - val_loss: -5.7926\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -9.4424 - val_loss: -4.6228\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.2942 - val_loss: -5.8662\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -8.8663 - val_loss: -6.0370\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -9.3874 - val_loss: -4.8181\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -10.2812 - val_loss: -4.4469\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -7.6203 - val_loss: -4.2800\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -4.8721 - val_loss: -4.2043\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -9.1040 - val_loss: -4.1757\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -9.4755 - val_loss: -4.1632\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -5.0412 - val_loss: -4.1574\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -7.9633 - val_loss: -4.1547\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -7.8835 - val_loss: -4.1540\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -9.1928 - val_loss: -4.1549\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -9.5552 - val_loss: -4.1573\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -8.8260 - val_loss: -4.1625\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -9.0035 - val_loss: -4.1717\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -9.6241 - val_loss: -4.1863\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.5989 - val_loss: -4.2070\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -9.7848 - val_loss: -4.2337\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -9.6292 - val_loss: -4.2654\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -9.8058 - val_loss: -4.3053\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -9.9385 - val_loss: -4.3487\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -9.0609 - val_loss: -4.4075\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -7.8846 - val_loss: -4.4649\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -8.6835 - val_loss: -4.5107\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -5.1226 - val_loss: -4.5445\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -9.4285 - val_loss: -4.5591\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -9.5571 - val_loss: -4.5567\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.8484 - val_loss: -4.5426\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -9.8695 - val_loss: -4.5244\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -9.3784 - val_loss: -4.5048\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -9.9728 - val_loss: -4.4866\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -5.2812 - val_loss: -4.4721\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -9.5965 - val_loss: -4.4613\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -10.0050 - val_loss: -4.4539\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -9.9159 - val_loss: -4.4496\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -9.9945 - val_loss: -4.4487\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -9.8567 - val_loss: -4.4508\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.9547 - val_loss: -4.4556\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -9.8065 - val_loss: -4.4645\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.7069 - val_loss: -4.4767\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -5.3380 - val_loss: -4.4896\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -9.9738 - val_loss: -4.5047\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.7580 - val_loss: -4.5200\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -9.4411 - val_loss: -4.5363\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -9.3916 - val_loss: -4.5554\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -6.8132 - val_loss: -12.0152\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -7.0252 - val_loss: -12.3277\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -6.7730 - val_loss: -12.2961\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -7.9488 - val_loss: -11.7206\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -8.8875 - val_loss: -11.5795\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -7.1341 - val_loss: -11.7130\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -7.4430 - val_loss: -11.7821\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -7.7429 - val_loss: -11.7985\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -8.4333 - val_loss: -11.7412\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.2712 - val_loss: -11.6103\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -7.4477 - val_loss: -11.6832\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -8.4009 - val_loss: -11.4176\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -8.9992 - val_loss: -11.1526\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -8.6612 - val_loss: -10.8972\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -7.6686 - val_loss: -10.5747\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.3630 - val_loss: -10.3686\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -8.5582 - val_loss: -10.1963\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -8.8669 - val_loss: -10.0808\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -9.1307 - val_loss: -10.0793\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -9.9338 - val_loss: -10.1519\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -9.1830 - val_loss: -10.4935\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.2330 - val_loss: -10.7660\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -4.9639 - val_loss: -10.9502\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -7.9668 - val_loss: -11.0772\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -8.9948 - val_loss: -11.1605\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -8.9709 - val_loss: -11.2072\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -7.5642 - val_loss: -11.2368\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.0536 - val_loss: -11.2511\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -9.0593 - val_loss: -11.2927\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -9.1585 - val_loss: -11.3380\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.1954 - val_loss: -11.3913\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -9.0663 - val_loss: -11.4530\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -9.1259 - val_loss: -11.5201\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -9.3644 - val_loss: -11.5850\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -9.0474 - val_loss: -11.6386\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -9.5072 - val_loss: -11.6733\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -7.7385 - val_loss: -11.7007\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -7.4740 - val_loss: -11.7183\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -8.5759 - val_loss: -11.7659\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -6.6868 - val_loss: -11.8081\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -9.3933 - val_loss: -11.8296\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -9.4031 - val_loss: -11.8328\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -7.8368 - val_loss: -11.8332\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -9.1125 - val_loss: -11.8283\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.7573 - val_loss: -11.8450\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -9.0662 - val_loss: -11.8771\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -8.2342 - val_loss: -11.9122\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -5.0848 - val_loss: -11.9468\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.1419 - val_loss: -12.0094\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -8.3878 - val_loss: -12.0571\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -9.0239 - val_loss: -12.1018\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -9.2484 - val_loss: -12.1275\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -9.7160 - val_loss: -12.1307\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -7.5186 - val_loss: -12.1085\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -7.9799 - val_loss: -12.1045\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -7.4031 - val_loss: -12.0816\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -10.2570 - val_loss: -11.9936\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.7010 - val_loss: -11.8943\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -8.5749 - val_loss: -11.8137\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -10.2344 - val_loss: -11.7261\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -9.5574 - val_loss: -11.6390\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -9.7376 - val_loss: -11.5659\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -9.4127 - val_loss: -11.5098\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -8.0384 - val_loss: -11.4691\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -9.3248 - val_loss: -11.4301\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -10.2249 - val_loss: -11.3989\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -9.9673 - val_loss: -11.3799\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -10.2044 - val_loss: -11.3749\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -10.2856 - val_loss: -11.3803\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -10.3763 - val_loss: -11.3890\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -9.6872 - val_loss: -11.3913\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -7.9099 - val_loss: -11.3877\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -10.3039 - val_loss: -11.3577\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -10.3840 - val_loss: -11.3139\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -10.5575 - val_loss: -11.2673\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -9.5041 - val_loss: -11.2333\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -10.5083 - val_loss: -11.2296\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -8.1526 - val_loss: -11.2666\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -10.2292 - val_loss: -11.3157\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -10.8855 - val_loss: -11.2912\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -8.1716 - val_loss: -11.2439\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -4.7901 - val_loss: -11.1983\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -10.3371 - val_loss: -11.1359\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -10.4076 - val_loss: -11.1148\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -9.3080 - val_loss: -11.0905\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -9.8908 - val_loss: -11.0858\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -10.5296 - val_loss: -11.0882\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -5.0870 - val_loss: -11.1004\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -9.5445 - val_loss: -11.1394\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -8.4397 - val_loss: -11.1896\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -10.7671 - val_loss: -11.1911\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -8.4441 - val_loss: -11.2062\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -9.7977 - val_loss: -11.1723\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -10.8022 - val_loss: -11.1297\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -10.6598 - val_loss: -11.0947\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -10.5703 - val_loss: -11.0693\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -10.3297 - val_loss: -11.0675\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -9.6943 - val_loss: -11.0515\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -8.2916 - val_loss: -11.0601\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -10.5990 - val_loss: -11.0946\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -11.6333 - val_loss: -inf\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -12.1705 - val_loss: -inf\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -4.9051 - val_loss: -inf\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.0068 - val_loss: -inf\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -5.3813 - val_loss: -inf\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.9423 - val_loss: -inf\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.5828 - val_loss: -inf\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -9.6766 - val_loss: -inf\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.4800 - val_loss: -inf\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -11.5438 - val_loss: -inf\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -5.3808 - val_loss: -inf\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -11.5606 - val_loss: -inf\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -11.6759 - val_loss: -inf\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -11.9345 - val_loss: -inf\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.1846 - val_loss: -inf\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -5.2396 - val_loss: -inf\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.3351 - val_loss: -inf\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -12.1086 - val_loss: -inf\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -8.8203 - val_loss: -inf\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -12.2894 - val_loss: -inf\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -11.8315 - val_loss: -inf\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -12.2908 - val_loss: -inf\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.1941 - val_loss: -inf\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -10.8309 - val_loss: -inf\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -8.9431 - val_loss: -inf\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.9232 - val_loss: -inf\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -8.2049 - val_loss: -inf\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -12.2649 - val_loss: -inf\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -5.4466 - val_loss: -inf\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.9506 - val_loss: -inf\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.9284 - val_loss: -inf\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -5.4586 - val_loss: -inf\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -12.7484 - val_loss: -inf\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -5.4481 - val_loss: -inf\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -5.3782 - val_loss: -inf\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -10.5377 - val_loss: -inf\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -8.8635 - val_loss: -inf\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -10.9568 - val_loss: -inf\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -11.7561 - val_loss: -inf\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -12.7826 - val_loss: -inf\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -4.9622 - val_loss: -inf\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -12.4301 - val_loss: -inf\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.5901 - val_loss: -inf\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -12.3891 - val_loss: -inf\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -10.6205 - val_loss: -inf\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -5.4412 - val_loss: -inf\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -8.7670 - val_loss: -inf\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -8.6020 - val_loss: -inf\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.4351 - val_loss: -inf\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -5.3235 - val_loss: -inf\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -5.3811 - val_loss: -inf\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.0391 - val_loss: -inf\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -12.6059 - val_loss: -inf\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.2314 - val_loss: -inf\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -11.7872 - val_loss: -inf\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.4031 - val_loss: -inf\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -12.8238 - val_loss: -inf\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -12.3186 - val_loss: -inf\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -12.6741 - val_loss: -inf\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.1276 - val_loss: -inf\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -12.0627 - val_loss: -inf\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.9692 - val_loss: -inf\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.4048 - val_loss: -inf\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -12.1767 - val_loss: -inf\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.9586 - val_loss: -inf\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -11.0441 - val_loss: -inf\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -10.3367 - val_loss: -inf\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -10.7059 - val_loss: -inf\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -12.2610 - val_loss: -inf\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.5408 - val_loss: -inf\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -5.3431 - val_loss: -inf\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -12.3555 - val_loss: -inf\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -10.5797 - val_loss: -inf\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -11.5199 - val_loss: -inf\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -12.2213 - val_loss: -inf\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -12.5238 - val_loss: -inf\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -12.3946 - val_loss: -inf\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -5.4210 - val_loss: -inf\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.2980 - val_loss: -inf\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -11.8378 - val_loss: -inf\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -5.2094 - val_loss: -inf\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -5.3832 - val_loss: -inf\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -11.6587 - val_loss: -inf\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.1329 - val_loss: -inf\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -12.3769 - val_loss: -inf\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.6428 - val_loss: -inf\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.5996 - val_loss: -inf\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -12.8232 - val_loss: -inf\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -12.4155 - val_loss: -inf\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -12.4092 - val_loss: -inf\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -8.4888 - val_loss: -inf\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -12.7516 - val_loss: -inf\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -12.6817 - val_loss: -inf\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -12.0295 - val_loss: -inf\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.2608 - val_loss: -inf\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -12.8062 - val_loss: -inf\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.7860 - val_loss: -inf\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -9.2782 - val_loss: -inf\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -5.4601 - val_loss: -inf\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.8845 - val_loss: -inf\n",
            "Testing parameters:  {'activation': 'relu', 'dropout_rate': 0.1, 'epochs': 100, 'hidden_layer_sizes': 64, 'learning_rate': 0.01, 'num_hidden_layers': 1, 'optimizer': 'sgd'}\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: -5.7704 - val_loss: -24.3326\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -5.8541 - val_loss: -24.4567\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -5.9955 - val_loss: -24.4901\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -6.0738 - val_loss: -24.5318\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -6.1688 - val_loss: -24.6239\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -6.2257 - val_loss: -24.7386\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -6.4175 - val_loss: -24.9777\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -6.3396 - val_loss: -25.2584\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -6.6194 - val_loss: -25.5135\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -6.7857 - val_loss: -26.0144\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -6.7939 - val_loss: -26.6974\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -6.9883 - val_loss: -27.3328\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -7.3299 - val_loss: -28.7386\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -7.5001 - val_loss: -31.7093\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -7.6892 - val_loss: -34.0185\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.0617 - val_loss: -35.7796\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -8.1920 - val_loss: -34.3889\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -8.4583 - val_loss: -29.1743\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -8.2300 - val_loss: -29.2774\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -8.4637 - val_loss: -20.5094\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -8.4673 - val_loss: -26.0877\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -9.0031 - val_loss: -26.1900\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -9.1285 - val_loss: -18.3731\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -8.9619 - val_loss: -29.4970\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -9.0663 - val_loss: -17.1517\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -8.9000 - val_loss: -24.9500\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -9.8175 - val_loss: -20.6567\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -10.3786 - val_loss: -18.3426\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -9.5820 - val_loss: -20.6137\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.6801 - val_loss: -16.4137\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -10.4358 - val_loss: -15.6538\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -10.8618 - val_loss: -15.8489\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -10.8028 - val_loss: -15.7078\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.4725 - val_loss: -15.3659\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.6338 - val_loss: -16.1502\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.6206 - val_loss: -14.4449\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -11.8321 - val_loss: -10.7583\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.0691 - val_loss: -13.3049\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.0447 - val_loss: -13.1581\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.1476 - val_loss: -11.2877\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -11.3151 - val_loss: -8.5596\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -10.3499 - val_loss: -13.8967\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -11.3605 - val_loss: -15.2621\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -10.9691 - val_loss: -14.3216\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.4463 - val_loss: -15.1028\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.4876 - val_loss: -15.6404\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -12.0673 - val_loss: -15.5403\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -11.9617 - val_loss: -15.6245\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -12.2547 - val_loss: -12.1966\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -13.2804 - val_loss: -10.0298\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -10.9419 - val_loss: -13.8130\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -12.4061 - val_loss: -13.5673\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -11.7863 - val_loss: -12.2688\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -12.9659 - val_loss: -14.6923\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -10.7763 - val_loss: -13.7693\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -11.4858 - val_loss: -11.7713\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -12.4266 - val_loss: -17.8499\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -11.0867 - val_loss: -13.9524\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.7225 - val_loss: -11.1580\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.0471 - val_loss: -21.3213\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.5306 - val_loss: -12.6959\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -12.3142 - val_loss: -13.3021\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -13.0233 - val_loss: -10.0363\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -12.6958 - val_loss: -13.8362\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -11.4555 - val_loss: -13.8350\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -12.2733 - val_loss: -12.9152\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -13.6728 - val_loss: -6.3476\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -10.6358 - val_loss: -13.7915\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -11.3379 - val_loss: -14.6661\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -11.3620 - val_loss: -15.2552\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -11.5329 - val_loss: -15.9119\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -12.2357 - val_loss: -15.0925\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.5492 - val_loss: -16.6725\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -11.9418 - val_loss: -15.9909\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -12.6913 - val_loss: -16.7106\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -11.9074 - val_loss: -13.9955\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -12.2924 - val_loss: -14.8726\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -12.3943 - val_loss: -10.0289\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -12.6897 - val_loss: -15.5512\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -11.7395 - val_loss: -13.6840\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.4094 - val_loss: -9.2860\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -12.6027 - val_loss: -12.2914\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -12.0488 - val_loss: -13.3620\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -13.2606 - val_loss: -7.7616\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.7708 - val_loss: -24.0823\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -10.2706 - val_loss: -17.0978\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -11.8971 - val_loss: -17.8591\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.4941 - val_loss: -15.8996\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.1052 - val_loss: -15.9368\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -13.0545 - val_loss: -14.6242\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -12.7599 - val_loss: -11.0417\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -12.5178 - val_loss: -9.4761\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -13.3625 - val_loss: -11.4068\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -12.2734 - val_loss: -10.4567\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -13.4006 - val_loss: -13.1986\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.7120 - val_loss: -7.1125\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.4804 - val_loss: -14.9896\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -12.2476 - val_loss: -17.6872\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.2327 - val_loss: -14.5232\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -12.0243 - val_loss: -14.7535\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -14.1141 - val_loss: -9.1881\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.2962 - val_loss: -10.2301\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -13.8594 - val_loss: -8.5048\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -13.3291 - val_loss: -10.9008\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -13.3039 - val_loss: -10.7205\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -14.0252 - val_loss: -10.1870\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -15.5310 - val_loss: -7.6427\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -12.1459 - val_loss: -12.5941\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.8513 - val_loss: -12.3449\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.5124 - val_loss: -11.9825\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -13.7476 - val_loss: -11.7140\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -14.0113 - val_loss: -10.8941\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -14.7368 - val_loss: -8.8187\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.9286 - val_loss: -12.0964\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -13.5363 - val_loss: -11.9298\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.2315 - val_loss: -11.8390\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -13.6750 - val_loss: -11.8665\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.8644 - val_loss: -11.3886\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.9739 - val_loss: -10.0056\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -14.8771 - val_loss: -11.0935\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.2891 - val_loss: -9.8875\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.1445 - val_loss: -9.9189\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -16.2263 - val_loss: -10.7661\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.5451 - val_loss: -7.6200\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -13.7401 - val_loss: -12.7714\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -13.6447 - val_loss: -13.0078\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -13.6351 - val_loss: -12.8866\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -12.4744 - val_loss: -12.6240\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -14.1733 - val_loss: -12.3625\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.0765 - val_loss: -12.1621\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -13.8373 - val_loss: -12.4601\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -14.4533 - val_loss: -12.3458\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.4774 - val_loss: -12.3251\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.0712 - val_loss: -12.2264\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -13.8873 - val_loss: -11.6938\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -13.5980 - val_loss: -11.9175\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.4153 - val_loss: -12.2425\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -13.7238 - val_loss: -11.8447\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -13.9405 - val_loss: -12.2572\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.8993 - val_loss: -12.1629\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -14.6001 - val_loss: -12.0081\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -14.9625 - val_loss: -11.6337\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -14.2497 - val_loss: -11.5832\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.6065 - val_loss: -10.7645\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -15.8567 - val_loss: -9.4544\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -14.8470 - val_loss: -10.1656\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.5272 - val_loss: -9.7115\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -15.8485 - val_loss: -8.3220\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -14.0194 - val_loss: -11.3444\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -14.4597 - val_loss: -11.1996\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -15.5575 - val_loss: -10.3840\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.5511 - val_loss: -10.2720\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.5342 - val_loss: -9.1246\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -15.5120 - val_loss: -10.4793\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.8021 - val_loss: -8.9635\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.6987 - val_loss: -12.8956\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -13.6554 - val_loss: -13.2707\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -13.8899 - val_loss: -13.2913\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.7455 - val_loss: -12.7962\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -14.7272 - val_loss: -12.6752\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -14.7288 - val_loss: -12.2961\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.6190 - val_loss: -10.9489\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -15.8375 - val_loss: -9.0627\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -15.3720 - val_loss: -11.2174\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -16.8894 - val_loss: -7.6619\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -13.9627 - val_loss: -13.3928\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.2074 - val_loss: -14.3597\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -14.6362 - val_loss: -14.2279\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -14.2234 - val_loss: -14.1256\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.2074 - val_loss: -14.1361\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -14.5623 - val_loss: -14.0462\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.4233 - val_loss: -14.2641\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -13.6979 - val_loss: -14.1143\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.3572 - val_loss: -13.9492\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -14.6922 - val_loss: -13.8980\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.7572 - val_loss: -13.2169\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.9584 - val_loss: -13.0117\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -15.1182 - val_loss: -12.5092\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -15.8399 - val_loss: -10.5933\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -15.2200 - val_loss: -11.4051\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -16.5851 - val_loss: -9.9887\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.2523 - val_loss: -11.2024\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.5360 - val_loss: -8.8123\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -15.8558 - val_loss: -12.9137\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -14.7491 - val_loss: -13.3199\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -15.8027 - val_loss: -12.1144\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.5425 - val_loss: -10.8622\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.4947 - val_loss: -10.3365\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.0634 - val_loss: -9.0046\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -15.6452 - val_loss: -13.3018\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -13.7511 - val_loss: -13.6230\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.9781 - val_loss: -13.3010\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.6485 - val_loss: -12.5029\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.0915 - val_loss: -11.2609\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.9970 - val_loss: -9.7586\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -15.9271 - val_loss: -12.8568\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.3225 - val_loss: -12.3579\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.7962 - val_loss: -11.2985\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -16.9063 - val_loss: -10.8050\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.3165 - val_loss: -9.0066\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -12.2468 - val_loss: -8.2025\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.3822 - val_loss: -8.4015\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.7586 - val_loss: -8.2808\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.0563 - val_loss: -8.1960\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.6211 - val_loss: -8.2307\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -15.6924 - val_loss: -7.8679\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.8775 - val_loss: -8.5600\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -14.0137 - val_loss: -8.2599\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.2072 - val_loss: -8.0710\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.4215 - val_loss: -8.8437\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -14.9143 - val_loss: -8.0407\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -14.2986 - val_loss: -8.8826\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -15.8247 - val_loss: -8.5655\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.7227 - val_loss: -8.8289\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.8829 - val_loss: -8.3707\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -14.2618 - val_loss: -9.4171\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.7511 - val_loss: -8.5883\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -15.0303 - val_loss: -8.3606\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -16.1536 - val_loss: -8.1002\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -15.4693 - val_loss: -8.8099\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -14.7901 - val_loss: -8.6809\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.3203 - val_loss: -8.6900\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -16.2503 - val_loss: -8.1046\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -15.0841 - val_loss: -8.4080\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.8230 - val_loss: -8.3222\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.3426 - val_loss: -8.8075\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -17.6416 - val_loss: -8.2208\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.6532 - val_loss: -9.3165\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.2145 - val_loss: -9.0431\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.3608 - val_loss: -9.1320\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -16.0913 - val_loss: -8.6543\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -16.9120 - val_loss: -8.4760\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.0674 - val_loss: -9.1371\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -14.0703 - val_loss: -8.6400\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.7966 - val_loss: -8.4314\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -17.4099 - val_loss: -8.6943\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -16.5111 - val_loss: -9.2821\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.5250 - val_loss: -9.0808\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.2923 - val_loss: -9.4836\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.8455 - val_loss: -8.3928\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.1995 - val_loss: -9.5052\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.4020 - val_loss: -9.5125\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.8326 - val_loss: -9.1201\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.1954 - val_loss: -9.2706\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.2093 - val_loss: -9.1534\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.5316 - val_loss: -9.0659\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.9774 - val_loss: -8.7123\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.2270 - val_loss: -9.4865\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -15.4998 - val_loss: -9.2359\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -16.4077 - val_loss: -8.8732\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.0786 - val_loss: -9.1430\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.8756 - val_loss: -9.1995\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.2934 - val_loss: -8.8472\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.1244 - val_loss: -9.4849\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -15.4636 - val_loss: -9.2166\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.6568 - val_loss: -8.5856\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -15.4752 - val_loss: -9.1594\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -14.9140 - val_loss: -9.2942\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -15.7414 - val_loss: -9.2783\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.5973 - val_loss: -8.9142\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -15.8736 - val_loss: -9.0028\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.0455 - val_loss: -9.2773\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.0520 - val_loss: -8.8971\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.7725 - val_loss: -9.1447\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.3913 - val_loss: -8.9295\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -16.3234 - val_loss: -8.9488\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.9343 - val_loss: -8.9239\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -17.2999 - val_loss: -8.8068\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.3774 - val_loss: -9.1485\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.2854 - val_loss: -8.4526\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -15.9086 - val_loss: -8.8713\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -15.3293 - val_loss: -9.1104\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.1026 - val_loss: -8.7491\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.9384 - val_loss: -9.0427\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.9903 - val_loss: -8.6798\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -15.5408 - val_loss: -9.1402\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -14.8404 - val_loss: -9.3395\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -14.5856 - val_loss: -8.9798\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -15.3737 - val_loss: -8.9398\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -15.2381 - val_loss: -8.9060\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.4692 - val_loss: -9.0063\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.4854 - val_loss: -8.9208\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -17.0378 - val_loss: -8.8272\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -17.0048 - val_loss: -8.7533\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.0553 - val_loss: -8.4325\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.0992 - val_loss: -8.3254\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -18.4933 - val_loss: -7.8594\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.8113 - val_loss: -8.2020\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.0224 - val_loss: -7.9595\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.5468 - val_loss: -8.0277\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.7454 - val_loss: -8.0069\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.7442 - val_loss: -8.2620\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -16.1687 - val_loss: -7.8098\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.3387 - val_loss: -7.4599\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.1490 - val_loss: -7.6800\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -15.8097 - val_loss: -7.6869\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -17.0687 - val_loss: -7.8160\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.8796 - val_loss: -7.6309\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.8382 - val_loss: -7.7256\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.1915 - val_loss: -7.6617\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -12.1704 - val_loss: -16.1281\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -14.4837 - val_loss: -16.1974\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.0244 - val_loss: -15.2903\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -15.2890 - val_loss: -16.4304\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -16.7206 - val_loss: -15.3479\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.6462 - val_loss: -17.3168\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.2782 - val_loss: -15.7500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -16.5378 - val_loss: -17.0817\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.4721 - val_loss: -14.9762\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -14.0310 - val_loss: -15.9141\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.3119 - val_loss: -16.4653\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.6037 - val_loss: -17.9015\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.4507 - val_loss: -15.0729\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.7640 - val_loss: -16.2308\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -14.9846 - val_loss: -13.6070\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -13.7011 - val_loss: -14.2662\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -14.4112 - val_loss: -15.4370\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -15.4997 - val_loss: -16.3758\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -17.2716 - val_loss: -16.6626\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -17.1793 - val_loss: -16.7503\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -16.0560 - val_loss: -14.6868\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.1344 - val_loss: -15.9352\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -16.6189 - val_loss: -17.0008\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.4511 - val_loss: -16.7006\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.5944 - val_loss: -15.9816\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.5802 - val_loss: -14.9613\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.0182 - val_loss: -16.1020\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -16.4712 - val_loss: -15.1010\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.0534 - val_loss: -16.5533\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.3623 - val_loss: -15.7553\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -15.4314 - val_loss: -15.5835\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.6564 - val_loss: -15.1079\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.7025 - val_loss: -15.8477\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -13.8182 - val_loss: -14.7854\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -14.2762 - val_loss: -15.3285\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -15.0832 - val_loss: -16.0468\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.0150 - val_loss: -16.0639\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.5201 - val_loss: -16.6599\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.3875 - val_loss: -16.4287\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.7762 - val_loss: -17.4289\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.2156 - val_loss: -16.1692\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -16.9200 - val_loss: -15.4737\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.3524 - val_loss: -16.1286\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.4843 - val_loss: -15.4523\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -18.2484 - val_loss: -15.9527\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.1778 - val_loss: -14.4548\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -14.1815 - val_loss: -15.1611\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.6674 - val_loss: -15.5258\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -16.5737 - val_loss: -14.8220\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -19.7765 - val_loss: -14.2556\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -23.4629 - val_loss: -17.9703\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -20.7070 - val_loss: -11.7707\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -21.3329 - val_loss: -16.6563\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -25.7210 - val_loss: -16.0435\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -26.1960 - val_loss: -12.6369\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -23.4281 - val_loss: -13.7358\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -20.7020 - val_loss: -17.7321\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -21.2588 - val_loss: -13.7398\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -23.0025 - val_loss: -15.1811\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -22.9464 - val_loss: -13.8591\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -22.3491 - val_loss: -15.6692\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.5418 - val_loss: -13.0553\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -22.0881 - val_loss: -15.9240\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -24.0979 - val_loss: -13.1696\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -25.1660 - val_loss: -15.4102\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -23.2005 - val_loss: -12.1506\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -23.3713 - val_loss: -12.0350\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -25.3887 - val_loss: -13.1399\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -26.6956 - val_loss: -15.4615\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -26.2656 - val_loss: -11.5907\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -25.1446 - val_loss: -12.1355\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -23.8267 - val_loss: -11.6234\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.4212 - val_loss: -15.2902\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -22.7770 - val_loss: -14.7309\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -23.7228 - val_loss: -13.1847\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -24.0981 - val_loss: -13.3350\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -27.3642 - val_loss: -12.4653\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -27.0178 - val_loss: -26.6237\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -20.8396 - val_loss: -12.6267\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -22.6043 - val_loss: -20.1309\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -20.1590 - val_loss: -18.8524\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -22.9358 - val_loss: -11.9510\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -20.7544 - val_loss: -15.4564\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -16.8570 - val_loss: -33.2718\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -18.9165 - val_loss: -18.9584\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -20.3679 - val_loss: -14.0987\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -20.6993 - val_loss: -13.4429\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -20.6337 - val_loss: -12.2772\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -21.3998 - val_loss: -13.2753\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -22.6877 - val_loss: -12.9702\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -23.9510 - val_loss: -13.8355\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.3245 - val_loss: -13.3867\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -25.6205 - val_loss: -15.2434\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -22.8454 - val_loss: -11.6714\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -23.9216 - val_loss: -13.8957\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -26.1508 - val_loss: -14.4058\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -26.9701 - val_loss: -14.4894\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.5594 - val_loss: -15.1955\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.3913 - val_loss: -12.2769\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.9701 - val_loss: -13.0868\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -20.1175 - val_loss: -16.2797\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -22.1965 - val_loss: -14.1376\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.6063 - val_loss: -13.3964\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.2067 - val_loss: -14.2278\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.4045 - val_loss: -16.4046\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.5063 - val_loss: -14.0948\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -25.4869 - val_loss: -14.8070\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -21.9496 - val_loss: -16.4039\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -22.8843 - val_loss: -18.4232\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -21.3786 - val_loss: -15.5612\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -28.4431 - val_loss: -13.2912\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.2855 - val_loss: -16.1523\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -27.1369 - val_loss: -11.8966\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -21.5129 - val_loss: -17.3645\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.5853 - val_loss: -21.8389\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.0498 - val_loss: -16.3440\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -26.9424 - val_loss: -13.3732\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -20.3281 - val_loss: -15.7251\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -25.8807 - val_loss: -12.2530\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -21.9538 - val_loss: -16.6155\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -24.2434 - val_loss: -14.9052\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -27.7313 - val_loss: -12.9113\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -20.9122 - val_loss: -13.4913\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -21.8749 - val_loss: -14.9693\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -23.0576 - val_loss: -15.7366\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -28.0929 - val_loss: -16.9335\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.8738 - val_loss: -15.9506\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -29.8847 - val_loss: -13.2875\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -22.2998 - val_loss: -15.4302\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -26.9036 - val_loss: -12.7022\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.8900 - val_loss: -14.0915\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -22.7876 - val_loss: -16.9649\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -31.3363 - val_loss: -16.7025\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -29.8022 - val_loss: -18.5785\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -30.0032 - val_loss: -14.9388\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -25.1678 - val_loss: -14.2530\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -19.6700 - val_loss: -18.2198\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -30.8996 - val_loss: -12.1022\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -23.0394 - val_loss: -23.0620\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -27.8616 - val_loss: -14.1584\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -23.7609 - val_loss: -13.1877\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -22.0784 - val_loss: -16.8892\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -26.9587 - val_loss: -20.4498\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -30.3287 - val_loss: -11.3938\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.3124 - val_loss: -15.1467\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -26.7602 - val_loss: -13.5740\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.3694 - val_loss: -16.0403\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -30.4359 - val_loss: -16.8986\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -32.9345 - val_loss: -17.2681\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -27.8724 - val_loss: -19.5582\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -25.8623 - val_loss: -14.0675\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -28.2232 - val_loss: -15.8333\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.6576 - val_loss: -16.1465\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -24.3331 - val_loss: -18.9644\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -30.0926 - val_loss: -16.0357\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -32.9139 - val_loss: -18.8441\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -28.6112 - val_loss: -11.5583\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -22.3166 - val_loss: -15.9211\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -34.1575 - val_loss: -16.5677\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -33.6072 - val_loss: -11.8875\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -24.5518 - val_loss: -18.3394\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -31.3874 - val_loss: -10.9169\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -20.0006 - val_loss: -16.5733\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -34.3230 - val_loss: -11.5609\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -22.7394 - val_loss: -14.3824\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.3744 - val_loss: -21.8876\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -23.5854 - val_loss: -13.0599\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.6852 - val_loss: -15.9582\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -30.0100 - val_loss: -14.0378\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -31.1456 - val_loss: -13.7301\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -23.9033 - val_loss: -15.3941\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -29.9432 - val_loss: -12.5095\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -22.2645 - val_loss: -20.2938\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -31.2240 - val_loss: -18.3630\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -32.7869 - val_loss: -17.4138\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -18.4004 - val_loss: -18.4212\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -21.2052 - val_loss: -17.8209\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -26.8770 - val_loss: -10.9735\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -19.9706 - val_loss: -17.8837\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -32.7760 - val_loss: -14.2804\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.0451 - val_loss: -16.6590\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -23.0144 - val_loss: -18.3654\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -33.4879 - val_loss: -15.3552\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -23.4554 - val_loss: -17.0492\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -31.1021 - val_loss: -13.1787\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -25.1904 - val_loss: -16.9764\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -20.9251 - val_loss: -10.8981\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -22.7166 - val_loss: -17.9026\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -33.6962 - val_loss: -10.2513\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.2435 - val_loss: -11.2784\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -22.7739 - val_loss: -12.3608\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -23.3202 - val_loss: -20.9991\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -27.4622 - val_loss: -16.6402\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -21.0278 - val_loss: -16.5491\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -34.8024 - val_loss: -16.1991\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -31.6132 - val_loss: -10.2352\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -20.2893 - val_loss: -10.6312\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -22.1129 - val_loss: -10.7675\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.9280 - val_loss: -12.0923\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -22.2606 - val_loss: -16.9175\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -20.9826 - val_loss: -11.0708\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.0896 - val_loss: -11.0769\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -15.0178 - val_loss: -11.0853\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -15.0754 - val_loss: -11.0969\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.9846 - val_loss: -11.1361\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.6741 - val_loss: -11.1744\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -15.9313 - val_loss: -11.3124\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -16.4132 - val_loss: -11.7096\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -18.4921 - val_loss: -14.5763\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -22.4889 - val_loss: -8.3994\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -16.9790 - val_loss: -12.0227\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -23.1907 - val_loss: -11.6624\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -20.3165 - val_loss: -11.3340\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.0134 - val_loss: -9.1043\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.6115 - val_loss: -11.0500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -14.8074 - val_loss: -11.0500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -14.8119 - val_loss: -11.0500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.8331 - val_loss: -11.0502\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.8309 - val_loss: -11.0504\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -14.8759 - val_loss: -11.0507\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -14.8067 - val_loss: -11.0507\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -14.8257 - val_loss: -11.0509\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -14.8121 - val_loss: -11.0510\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -14.9275 - val_loss: -11.0519\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.8099 - val_loss: -11.0520\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -14.9151 - val_loss: -11.0530\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.8340 - val_loss: -11.0535\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -14.8225 - val_loss: -11.0538\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -14.8465 - val_loss: -11.0545\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -14.8195 - val_loss: -11.0549\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -14.9197 - val_loss: -11.0571\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -14.8400 - val_loss: -11.0582\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -14.9476 - val_loss: -11.0624\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -14.8410 - val_loss: -11.0643\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -14.8739 - val_loss: -11.0677\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.0017 - val_loss: -11.0757\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.2240 - val_loss: -11.3605\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.9657 - val_loss: -12.6460\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -23.0754 - val_loss: -8.5481\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.1958 - val_loss: -11.3792\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.6961 - val_loss: -12.3692\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.6499 - val_loss: -8.3246\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -14.4900 - val_loss: -10.7107\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -24.0551 - val_loss: -12.8775\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -26.1348 - val_loss: -14.0038\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -29.4211 - val_loss: -8.3226\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -10.5839 - val_loss: -8.3266\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -11.0537 - val_loss: -8.3504\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -9.9254 - val_loss: -8.3502\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -10.6993 - val_loss: -8.3708\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -10.6927 - val_loss: -8.3933\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -10.9615 - val_loss: -8.4652\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -10.7378 - val_loss: -8.5105\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -10.8638 - val_loss: -8.6541\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -11.9214 - val_loss: -9.1032\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -12.2277 - val_loss: -10.5003\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -14.5766 - val_loss: -16.0585\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -22.7935 - val_loss: -11.8945\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -24.6320 - val_loss: -14.9664\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -28.5670 - val_loss: -8.3773\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.1994 - val_loss: -8.5396\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -16.6945 - val_loss: -9.0882\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -17.7152 - val_loss: -11.8484\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -23.8653 - val_loss: -20.7142\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -24.1545 - val_loss: -8.6319\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -17.1772 - val_loss: -12.2197\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -23.7618 - val_loss: -13.0522\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -23.3040 - val_loss: -8.4156\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.5113 - val_loss: -8.6361\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.1319 - val_loss: -9.6966\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -21.7304 - val_loss: -12.5579\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -14.6644 - val_loss: -12.3203\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -20.2639 - val_loss: -9.7076\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.0169 - val_loss: -14.4169\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -16.2346 - val_loss: -11.7448\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -28.8054 - val_loss: -13.2942\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.6312 - val_loss: -15.8909\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -26.5415 - val_loss: -8.6137\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.5160 - val_loss: -11.0422\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -26.0293 - val_loss: -15.7032\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -30.9453 - val_loss: -8.4705\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.1132 - val_loss: -8.9194\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.4340 - val_loss: -12.7417\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.9002 - val_loss: -8.6208\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -16.9556 - val_loss: -9.6819\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.0595 - val_loss: -23.0908\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.7479 - val_loss: -17.9595\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -26.6614 - val_loss: -9.2237\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -21.6021 - val_loss: -13.2422\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -24.6149 - val_loss: -9.5588\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -19.3332 - val_loss: -9.7489\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -20.4842 - val_loss: -16.6259\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -19.1444 - val_loss: -11.7582\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -23.6589 - val_loss: -18.5488\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -26.3347 - val_loss: -8.4158\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -15.4869 - val_loss: -8.5094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -16.2691 - val_loss: -9.2632\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -19.9198 - val_loss: -11.4216\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -16.8606 - val_loss: -13.1052\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -23.7177 - val_loss: -13.0458\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -21.3283 - val_loss: -12.7391\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -23.6221 - val_loss: -14.0393\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -15.5077 - val_loss: -14.7685\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.6320 - val_loss: -11.8301\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.3803 - val_loss: -14.6296\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -20.2080 - val_loss: -12.5737\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.9808 - val_loss: -15.8323\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -17.1459 - val_loss: -16.1581\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.9250 - val_loss: -12.1501\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -19.9639 - val_loss: -17.0498\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.0820 - val_loss: -15.9563\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -24.3646 - val_loss: -11.0316\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.7028 - val_loss: -16.5217\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -29.7099 - val_loss: -10.3320\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.2032 - val_loss: -13.7270\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -23.5490 - val_loss: -13.1524\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -24.3284 - val_loss: -17.8789\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -19.6515 - val_loss: -14.7583\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -24.6081 - val_loss: -16.0999\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.1427 - val_loss: -11.6728\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -19.4014 - val_loss: -17.6348\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.7729 - val_loss: -15.8668\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -22.4168 - val_loss: -11.8804\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -18.1810 - val_loss: -17.6175\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.8605 - val_loss: -15.0553\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.1327 - val_loss: -17.0730\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -27.8703 - val_loss: -10.2635\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.5040 - val_loss: -12.4282\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -25.9832 - val_loss: -10.2273\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.9353 - val_loss: -14.0394\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.8099 - val_loss: -13.2978\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -27.6506 - val_loss: -11.4003\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -17.4493 - val_loss: -14.8593\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.9590 - val_loss: -16.1377\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -22.5989 - val_loss: -14.0163\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -24.9308 - val_loss: -16.6600\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.2617 - val_loss: -15.3475\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -21.3276 - val_loss: -14.9878\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -26.2977 - val_loss: -12.6980\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -26.3819 - val_loss: -16.6336\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -13.3933 - val_loss: -15.0010\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.1183 - val_loss: -15.1689\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.8098 - val_loss: -15.9222\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.8608 - val_loss: -16.4284\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.2538 - val_loss: -15.7586\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.1135 - val_loss: -16.0637\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.4114 - val_loss: -16.6139\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -18.9051 - val_loss: -16.5059\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -20.0132 - val_loss: -15.3229\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -23.0641 - val_loss: -16.4501\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -27.9269 - val_loss: -12.9766\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.1579 - val_loss: -12.2773\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -15.5208 - val_loss: -16.1315\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -18.0021 - val_loss: -17.6044\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -22.6327 - val_loss: -10.5167\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -15.3232 - val_loss: -13.3867\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -21.7053 - val_loss: -13.9120\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -29.0877 - val_loss: -13.4691\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -11.1284 - val_loss: -14.8627\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -15.8012 - val_loss: -16.9526\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.8293 - val_loss: -16.3642\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -17.8239 - val_loss: -16.2394\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.5569 - val_loss: -17.9331\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.8536 - val_loss: -13.6278\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -15.9857 - val_loss: -15.2424\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -17.6635 - val_loss: -17.0145\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.0012 - val_loss: -16.8104\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.3252 - val_loss: -16.7472\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.2381 - val_loss: -16.7789\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.7170 - val_loss: -17.2633\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.3759 - val_loss: -16.7940\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -21.5600 - val_loss: -13.7845\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -21.4479 - val_loss: -14.6494\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.5237 - val_loss: -11.9976\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.6430 - val_loss: -14.7516\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -20.8543 - val_loss: -13.2605\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -26.0480 - val_loss: -15.5333\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -25.4978 - val_loss: -11.9672\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -23.2068 - val_loss: -17.1697\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -14.6731 - val_loss: -10.2381\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -14.5313 - val_loss: -10.7589\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.1199 - val_loss: -13.4074\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.8764 - val_loss: -17.1457\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.1706 - val_loss: -15.3160\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -30.5519 - val_loss: -11.3617\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -27.5300 - val_loss: -15.4074\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.0857 - val_loss: -14.3602\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -24.7922 - val_loss: -14.4976\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -20.1084 - val_loss: -11.9835\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.7272 - val_loss: -14.3521\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.1677 - val_loss: -14.7005\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -15.7147 - val_loss: -14.6530\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -17.6542 - val_loss: -16.0900\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -24.3710 - val_loss: -15.8541\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -23.3198 - val_loss: -11.7943\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.1498 - val_loss: -15.2969\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -23.8019 - val_loss: -11.6187\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -20.3669 - val_loss: -12.8305\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.4628 - val_loss: -13.7906\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.3975 - val_loss: -14.7454\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -14.5463 - val_loss: -11.5643\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.1843 - val_loss: -13.7069\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -15.2661 - val_loss: -11.2310\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -15.6275 - val_loss: -16.3230\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -14.2267 - val_loss: -11.9948\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -15.6855 - val_loss: -14.8623\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -16.8562 - val_loss: -12.3889\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.7668 - val_loss: -16.2232\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.5893 - val_loss: -10.7105\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -15.6804 - val_loss: -12.5991\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -20.8453 - val_loss: -14.2702\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -20.8456 - val_loss: -10.2296\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -16.4100 - val_loss: -11.6744\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -21.1298 - val_loss: -8.8180\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -19.8993 - val_loss: -9.9866\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -24.6233 - val_loss: -9.0040\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -23.2964 - val_loss: -11.5260\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -20.3110 - val_loss: -12.0868\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.6332 - val_loss: -8.6611\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -22.3984 - val_loss: -12.5380\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -20.4573 - val_loss: -8.1266\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -21.1890 - val_loss: -11.1261\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -21.8225 - val_loss: -7.5766\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -21.6836 - val_loss: -13.5133\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -19.5928 - val_loss: -16.7076\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.9189 - val_loss: -12.1046\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.0927 - val_loss: -13.1297\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -19.6646 - val_loss: -16.4590\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -18.1345 - val_loss: -11.8086\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.3981 - val_loss: -13.1803\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -20.6249 - val_loss: -14.7740\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.9294 - val_loss: -12.8613\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -20.2531 - val_loss: -15.3803\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.6878 - val_loss: -12.7043\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.8610 - val_loss: -14.1934\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.0691 - val_loss: -11.9827\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.5372 - val_loss: -14.3783\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -20.4805 - val_loss: -11.6325\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.3961 - val_loss: -12.0602\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -21.5797 - val_loss: -12.2883\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -21.8238 - val_loss: -10.2962\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -24.1406 - val_loss: -10.4679\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -21.2625 - val_loss: -10.1412\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -22.1779 - val_loss: -8.6704\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -22.0053 - val_loss: -14.9492\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.2317 - val_loss: -12.4720\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.6555 - val_loss: -14.5063\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -18.9688 - val_loss: -11.5807\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.5408 - val_loss: -13.0814\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.6510 - val_loss: -8.4018\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.2530 - val_loss: -7.6185\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -19.4083 - val_loss: -12.8906\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -20.7066 - val_loss: -13.0934\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -21.9679 - val_loss: -9.6835\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.7448 - val_loss: -8.7629\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -25.9785 - val_loss: -12.5917\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -22.1485 - val_loss: -10.8780\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -25.2611 - val_loss: -8.5392\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -25.7287 - val_loss: -13.4926\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.6391 - val_loss: -12.0709\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -18.1286 - val_loss: -12.6514\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -24.6608 - val_loss: -8.4176\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -28.4037 - val_loss: -7.2072\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -23.0130 - val_loss: -14.4343\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.5574 - val_loss: -14.7952\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.3630 - val_loss: -15.6676\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -19.3553 - val_loss: -12.3859\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -18.8245 - val_loss: -16.2547\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -19.0298 - val_loss: -11.6390\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -17.5002 - val_loss: -12.7406\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -19.1048 - val_loss: -13.4437\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -18.7316 - val_loss: -14.1015\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -23.0525 - val_loss: -14.0701\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.2034 - val_loss: -12.1218\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -20.5820 - val_loss: -14.5852\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.4247 - val_loss: -12.3024\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -19.8277 - val_loss: -13.6933\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -20.2500 - val_loss: -9.9990\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -20.1310 - val_loss: -11.3021\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -24.2839 - val_loss: -13.4788\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.3904 - val_loss: -17.4020\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.5765 - val_loss: -11.2405\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -16.5788 - val_loss: -16.5589\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -16.7233 - val_loss: -11.3650\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -16.0078 - val_loss: -14.2033\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -21.7962 - val_loss: -13.8409\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -21.0235 - val_loss: -14.4838\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -21.4574 - val_loss: -11.4050\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -19.2367 - val_loss: -11.4849\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -24.7975 - val_loss: -9.1321\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -24.5646 - val_loss: -6.9463\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.0111 - val_loss: -13.0347\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -20.0877 - val_loss: -16.0407\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -19.8292 - val_loss: -12.5106\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.4882 - val_loss: -15.8455\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.1323 - val_loss: -12.7860\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -19.1394 - val_loss: -14.5632\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -21.9782 - val_loss: -13.0631\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -20.9456 - val_loss: -14.0383\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -18.9899 - val_loss: -12.4988\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -16.7843 - val_loss: -9.7457\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -17.9131 - val_loss: -10.1316\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -17.8471 - val_loss: -9.7339\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -18.4010 - val_loss: -9.6920\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -18.1303 - val_loss: -9.6572\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.6369 - val_loss: -9.7323\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -19.5208 - val_loss: -9.6625\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -19.0292 - val_loss: -9.6505\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -18.1114 - val_loss: -9.1380\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.2432 - val_loss: -9.4547\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.2739 - val_loss: -9.7556\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.8405 - val_loss: -9.7905\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.1389 - val_loss: -9.5236\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -17.1757 - val_loss: -9.5005\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.7381 - val_loss: -9.3920\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.1260 - val_loss: -9.0752\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.0975 - val_loss: -9.4210\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -17.4410 - val_loss: -9.2878\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.8498 - val_loss: -9.4074\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.9061 - val_loss: -9.4582\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -18.2847 - val_loss: -9.5017\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.5639 - val_loss: -9.8056\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.3304 - val_loss: -9.4066\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -19.3577 - val_loss: -9.4516\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -19.7129 - val_loss: -9.6958\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -17.0019 - val_loss: -9.5136\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.2296 - val_loss: -9.5892\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.1597 - val_loss: -9.3252\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.6934 - val_loss: -9.5523\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -19.4249 - val_loss: -9.5673\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -19.4678 - val_loss: -9.5777\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -18.6400 - val_loss: -9.5565\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -19.0748 - val_loss: -9.7209\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -20.5599 - val_loss: -9.7591\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -20.0329 - val_loss: -9.2732\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.3560 - val_loss: -9.4577\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -19.1683 - val_loss: -9.3281\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -18.2395 - val_loss: -9.3328\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.3729 - val_loss: -9.4071\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -19.1014 - val_loss: -9.7531\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -19.2497 - val_loss: -9.4885\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.9421 - val_loss: -9.8067\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -20.1021 - val_loss: -9.5700\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -20.3161 - val_loss: -9.8137\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.8171 - val_loss: -9.3993\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -20.1351 - val_loss: -9.1599\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.8647 - val_loss: -9.3897\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -18.6453 - val_loss: -9.6242\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.7920 - val_loss: -9.4107\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -20.0841 - val_loss: -9.4927\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -19.2780 - val_loss: -9.5098\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -19.9329 - val_loss: -9.4787\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -21.4720 - val_loss: -9.3615\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -18.6779 - val_loss: -9.4817\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -19.2679 - val_loss: -9.6893\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -21.1355 - val_loss: -9.4032\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -20.1032 - val_loss: -9.3896\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -19.1410 - val_loss: -9.5538\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -20.2724 - val_loss: -9.2358\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -20.4395 - val_loss: -9.0502\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -16.1103 - val_loss: -9.5712\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.0850 - val_loss: -9.6692\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -20.8480 - val_loss: -9.4686\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -22.3862 - val_loss: -10.0845\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -20.7190 - val_loss: -9.2781\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.7396 - val_loss: -9.8430\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -22.9130 - val_loss: -10.1972\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -21.6947 - val_loss: -9.3859\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.2825 - val_loss: -9.1563\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.6224 - val_loss: -10.1844\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -22.7352 - val_loss: -10.0165\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -21.7804 - val_loss: -9.6620\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -21.0653 - val_loss: -8.8430\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.7271 - val_loss: -10.0361\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.0195 - val_loss: -9.3438\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -19.4988 - val_loss: -9.4092\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -19.4068 - val_loss: -9.3853\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -16.8017 - val_loss: -9.6607\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -21.3727 - val_loss: -9.7100\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -20.1787 - val_loss: -9.8356\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -22.7682 - val_loss: -10.2335\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -23.8541 - val_loss: -9.0287\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -17.0534 - val_loss: -9.1642\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.6373 - val_loss: -9.3538\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -21.7289 - val_loss: -9.7205\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -22.8635 - val_loss: -9.5639\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -21.6737 - val_loss: -9.9677\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -24.7497 - val_loss: -9.5875\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -21.1939 - val_loss: -9.6087\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -17.4106 - val_loss: -8.9902\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.3873 - val_loss: -9.6331\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.7502 - val_loss: -9.4282\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.9577 - val_loss: -9.7988\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.1534 - val_loss: -9.2334\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.2042 - val_loss: -9.9307\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -23.4086 - val_loss: -10.0712\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -21.5450 - val_loss: -10.0753\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -21.8187 - val_loss: -9.9518\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -22.5139 - val_loss: -9.7675\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -19.8310 - val_loss: -9.5603\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -13.8424 - val_loss: -22.8560\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -14.8612 - val_loss: -22.8863\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -15.7844 - val_loss: -20.5638\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -15.5201 - val_loss: -19.6276\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.6486 - val_loss: -21.9620\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.9214 - val_loss: -19.6210\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -16.6354 - val_loss: -16.3304\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -15.8713 - val_loss: -17.1716\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -15.9495 - val_loss: -19.4167\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.6972 - val_loss: -15.3970\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -16.3373 - val_loss: -22.3653\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -16.3195 - val_loss: -20.6908\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.3392 - val_loss: -17.2028\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -16.8846 - val_loss: -23.2617\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.6150 - val_loss: -16.1045\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.8366 - val_loss: -15.2810\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -17.1296 - val_loss: -17.3635\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.3171 - val_loss: -14.8803\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.3140 - val_loss: -16.6588\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.7265 - val_loss: -21.4384\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -17.1850 - val_loss: -15.9268\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.8039 - val_loss: -18.8205\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -17.9917 - val_loss: -15.2968\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.2755 - val_loss: -20.0697\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -18.2069 - val_loss: -16.1405\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -17.9244 - val_loss: -17.0027\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.4046 - val_loss: -20.9945\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -15.2999 - val_loss: -21.6964\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.8069 - val_loss: -17.5836\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -18.1886 - val_loss: -17.1350\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -17.9613 - val_loss: -18.9994\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.2133 - val_loss: -18.3689\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.8919 - val_loss: -26.0693\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.1205 - val_loss: -15.8386\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -18.3479 - val_loss: -17.5910\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.5446 - val_loss: -17.8403\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -17.4639 - val_loss: -17.7505\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.9685 - val_loss: -20.2905\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.2132 - val_loss: -17.6571\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.2262 - val_loss: -24.0027\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.5103 - val_loss: -15.3787\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.9052 - val_loss: -17.1330\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -19.0896 - val_loss: -20.8584\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.6074 - val_loss: -12.0552\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -16.8896 - val_loss: -19.3528\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.0397 - val_loss: -22.3373\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -14.2498 - val_loss: -17.2911\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.1569 - val_loss: -18.0642\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.6331 - val_loss: -15.4343\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -18.0576 - val_loss: -12.8949\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.0101 - val_loss: -16.6886\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.1794 - val_loss: -13.8078\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -18.3775 - val_loss: -19.7918\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.2118 - val_loss: -21.4308\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -18.3040 - val_loss: -15.4923\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.9674 - val_loss: -16.9302\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -18.0701 - val_loss: -17.0445\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.4722 - val_loss: -22.5163\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.3026 - val_loss: -13.3439\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.4663 - val_loss: -13.8876\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.5468 - val_loss: -14.5844\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.5252 - val_loss: -14.6932\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -19.8834 - val_loss: -16.4430\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.1732 - val_loss: -17.7466\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -18.0512 - val_loss: -15.6894\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.4048 - val_loss: -14.3659\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -18.5382 - val_loss: -17.0519\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.8140 - val_loss: -18.7358\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.9109 - val_loss: -17.8131\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -18.1490 - val_loss: -19.7131\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -20.0504 - val_loss: -15.4248\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -18.8865 - val_loss: -15.4475\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.2177 - val_loss: -15.0091\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -18.7832 - val_loss: -17.5163\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.3195 - val_loss: -17.0893\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -20.2545 - val_loss: -16.1335\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -19.7824 - val_loss: -16.4829\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -18.0260 - val_loss: -18.2772\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -18.5636 - val_loss: -17.7291\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.0086 - val_loss: -15.3531\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -20.6316 - val_loss: -16.9598\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.1214 - val_loss: -16.3557\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.2996 - val_loss: -17.0128\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -19.4009 - val_loss: -22.2345\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -18.0502 - val_loss: -16.0105\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.9151 - val_loss: -13.8187\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.3316 - val_loss: -16.3959\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.3137 - val_loss: -14.4237\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -18.0870 - val_loss: -16.8679\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -18.4448 - val_loss: -16.1877\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.9143 - val_loss: -15.4744\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -21.2857 - val_loss: -17.0934\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -18.5714 - val_loss: -17.6181\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.0616 - val_loss: -18.5100\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -20.1054 - val_loss: -18.7424\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.4620 - val_loss: -13.4398\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.8881 - val_loss: -15.9386\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -19.5975 - val_loss: -16.2832\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.9760 - val_loss: -16.7331\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -18.8365 - val_loss: -17.8287\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -17.2566 - val_loss: -11.3663\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.8741 - val_loss: -13.1740\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.6363 - val_loss: -12.6058\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -18.6010 - val_loss: -13.7217\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.1900 - val_loss: -14.5521\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.6097 - val_loss: -12.9074\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -19.0385 - val_loss: -11.3168\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.8399 - val_loss: -12.1984\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.9693 - val_loss: -14.8916\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -18.1630 - val_loss: -12.4882\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.2197 - val_loss: -10.7768\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -18.4521 - val_loss: -12.0259\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -17.7682 - val_loss: -11.5972\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -19.7385 - val_loss: -13.5066\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.8929 - val_loss: -12.3180\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -18.2949 - val_loss: -12.3526\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -18.5177 - val_loss: -12.9375\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -20.1845 - val_loss: -10.8934\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.6425 - val_loss: -14.1188\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -18.6566 - val_loss: -11.8578\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.2157 - val_loss: -13.8954\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -18.2401 - val_loss: -13.5117\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.5454 - val_loss: -11.2888\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.3126 - val_loss: -10.3473\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.6523 - val_loss: -13.2268\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.4298 - val_loss: -11.5908\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.6642 - val_loss: -13.6032\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -19.1342 - val_loss: -13.2559\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.8323 - val_loss: -12.1421\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -18.9905 - val_loss: -11.9900\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -20.1417 - val_loss: -13.5390\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -20.5848 - val_loss: -12.9383\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -18.8478 - val_loss: -10.7685\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.8773 - val_loss: -11.2158\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.2033 - val_loss: -13.9084\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.2033 - val_loss: -11.9336\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.5204 - val_loss: -12.7117\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -19.8437 - val_loss: -12.6030\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -19.9182 - val_loss: -9.8134\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.5100 - val_loss: -10.5664\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.6936 - val_loss: -13.5649\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.1342 - val_loss: -13.3134\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -19.5535 - val_loss: -12.5419\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.1016 - val_loss: -11.7848\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -19.3710 - val_loss: -12.9138\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.6110 - val_loss: -10.9697\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -19.3945 - val_loss: -12.4929\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -19.9792 - val_loss: -11.3426\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -19.4864 - val_loss: -12.0506\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.6707 - val_loss: -11.3237\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -20.6547 - val_loss: -12.1230\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -19.4950 - val_loss: -10.5619\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.3999 - val_loss: -11.1098\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -17.5391 - val_loss: -12.2530\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -20.0859 - val_loss: -11.4186\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -19.5686 - val_loss: -12.0017\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.4284 - val_loss: -11.4131\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -21.1021 - val_loss: -11.9101\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.7643 - val_loss: -13.6841\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.2318 - val_loss: -13.3813\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.5957 - val_loss: -10.6031\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -19.0135 - val_loss: -11.7025\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -20.3798 - val_loss: -12.8154\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -19.0303 - val_loss: -10.8236\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -19.2741 - val_loss: -13.0309\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -16.9141 - val_loss: -11.7077\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.8495 - val_loss: -11.0457\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.8875 - val_loss: -12.5366\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.0735 - val_loss: -12.1712\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -15.6709 - val_loss: -12.5849\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -19.6375 - val_loss: -10.2501\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.4088 - val_loss: -11.1599\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.9949 - val_loss: -12.4247\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -20.3570 - val_loss: -12.4436\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -20.0943 - val_loss: -11.8820\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -19.4375 - val_loss: -14.6368\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -19.4471 - val_loss: -10.3109\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.9941 - val_loss: -13.0979\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -20.2422 - val_loss: -12.0660\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -20.7732 - val_loss: -11.6789\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -19.0171 - val_loss: -11.7137\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -19.8172 - val_loss: -13.7743\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -20.3062 - val_loss: -13.3602\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -19.7238 - val_loss: -11.0116\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -19.9172 - val_loss: -12.2152\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.6334 - val_loss: -13.4654\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -20.1085 - val_loss: -12.4515\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.1921 - val_loss: -11.9062\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -21.1874 - val_loss: -14.0032\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.1315 - val_loss: -11.4506\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.1114 - val_loss: -12.6568\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -20.7353 - val_loss: -13.9757\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.4024 - val_loss: -11.6382\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -18.7132 - val_loss: -11.5360\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -20.4889 - val_loss: -13.5871\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.9145 - val_loss: -10.2448\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.4566 - val_loss: -11.1067\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -19.4996 - val_loss: -12.1700\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -20.9404 - val_loss: -12.7947\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.4502 - val_loss: -11.9770\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -15.1831 - val_loss: -17.8098\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -15.2148 - val_loss: -18.4502\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.3326 - val_loss: -20.1485\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.6868 - val_loss: -19.5675\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.7303 - val_loss: -15.7029\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.1947 - val_loss: -17.9267\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -16.8327 - val_loss: -16.6540\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.9809 - val_loss: -14.8345\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -15.6277 - val_loss: -20.4713\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -16.0258 - val_loss: -17.7942\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -15.0249 - val_loss: -19.0527\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.3349 - val_loss: -17.8837\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.8638 - val_loss: -16.0498\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.0531 - val_loss: -17.3197\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -14.7798 - val_loss: -19.3285\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -17.3886 - val_loss: -18.5911\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -16.1216 - val_loss: -19.6179\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -18.1042 - val_loss: -16.7505\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.5970 - val_loss: -17.4652\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.7262 - val_loss: -16.0633\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -16.2362 - val_loss: -18.3141\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.8016 - val_loss: -15.7093\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -18.0834 - val_loss: -18.3786\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -18.0155 - val_loss: -15.0005\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -16.9741 - val_loss: -18.2216\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -18.5599 - val_loss: -14.4780\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.3181 - val_loss: -17.0591\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -14.8021 - val_loss: -17.5634\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -16.8054 - val_loss: -15.9968\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -18.8841 - val_loss: -17.9065\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -18.0745 - val_loss: -15.7331\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -18.5067 - val_loss: -18.1252\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.9348 - val_loss: -15.4802\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.3514 - val_loss: -18.6877\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.8004 - val_loss: -12.8103\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -16.7721 - val_loss: -18.2972\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.9774 - val_loss: -14.0770\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.6548 - val_loss: -17.8403\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.7124 - val_loss: -16.2561\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.5784 - val_loss: -16.8122\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.5640 - val_loss: -17.1691\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -18.5225 - val_loss: -13.3456\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -15.8812 - val_loss: -13.1196\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -17.0452 - val_loss: -16.6316\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.1089 - val_loss: -17.6255\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.6042 - val_loss: -17.8951\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -18.6238 - val_loss: -12.2648\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.0887 - val_loss: -16.6247\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -16.7541 - val_loss: -16.5308\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.4644 - val_loss: -18.1168\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.6482 - val_loss: -16.4520\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.8061 - val_loss: -15.1594\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -17.9668 - val_loss: -15.1629\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.7382 - val_loss: -14.8151\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.6959 - val_loss: -14.7009\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -17.1739 - val_loss: -17.0246\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.8235 - val_loss: -17.2694\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.7986 - val_loss: -15.1338\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.7838 - val_loss: -17.6686\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.0413 - val_loss: -15.5732\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.8732 - val_loss: -17.4742\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.4558 - val_loss: -16.0419\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -19.0095 - val_loss: -14.6666\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.9137 - val_loss: -18.6238\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.1831 - val_loss: -16.6508\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.3298 - val_loss: -16.0859\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -19.2606 - val_loss: -15.4373\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -20.2034 - val_loss: -12.5892\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -18.3038 - val_loss: -16.6169\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.8433 - val_loss: -17.7948\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.9857 - val_loss: -12.2564\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.9267 - val_loss: -16.8494\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -16.9435 - val_loss: -17.9569\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -17.9639 - val_loss: -14.5831\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.9887 - val_loss: -17.7306\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.4187 - val_loss: -14.9470\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.0182 - val_loss: -16.3562\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.3352 - val_loss: -16.7472\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.9231 - val_loss: -16.8261\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.3494 - val_loss: -17.4495\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -18.4309 - val_loss: -13.7189\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.2552 - val_loss: -15.3899\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -18.6679 - val_loss: -15.8728\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.5014 - val_loss: -15.6121\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.9291 - val_loss: -15.7015\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -18.5687 - val_loss: -16.6516\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -19.2155 - val_loss: -14.8066\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.2136 - val_loss: -17.0530\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -18.5480 - val_loss: -14.7807\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.7122 - val_loss: -15.6693\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.2249 - val_loss: -17.0224\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.7202 - val_loss: -15.2976\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -17.0841 - val_loss: -16.3571\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.4860 - val_loss: -16.6912\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.1245 - val_loss: -15.2025\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -18.4844 - val_loss: -16.6085\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.0769 - val_loss: -15.9841\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.3365 - val_loss: -14.0320\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -18.7693 - val_loss: -15.5458\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -17.7632 - val_loss: -16.7888\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -17.1708 - val_loss: -8.9503\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.6737 - val_loss: -8.2198\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.9433 - val_loss: -7.6960\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.9269 - val_loss: -5.4732\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.2091 - val_loss: -8.9506\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.0545 - val_loss: -8.8094\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.4502 - val_loss: -7.0751\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.7834 - val_loss: -7.9810\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -18.2004 - val_loss: -7.1289\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -17.2055 - val_loss: -7.0555\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.5669 - val_loss: -8.6904\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.2907 - val_loss: -8.4535\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -17.1775 - val_loss: -5.5977\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.3263 - val_loss: -8.0061\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -18.4510 - val_loss: -7.0027\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -17.9708 - val_loss: -8.2817\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -18.0559 - val_loss: -7.7323\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.5817 - val_loss: -7.5925\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.0027 - val_loss: -7.6761\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.6670 - val_loss: -6.5094\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.9982 - val_loss: -6.9272\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -18.1533 - val_loss: -6.8285\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.8494 - val_loss: -8.9572\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -18.8259 - val_loss: -8.0919\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -18.1072 - val_loss: -8.3851\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.3574 - val_loss: -8.9524\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.5799 - val_loss: -8.3178\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -19.8955 - val_loss: -8.8422\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.5159 - val_loss: -6.3678\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - ETA: 0s - loss: -18.1146"
          ]
        }
      ],
      "source": [
        "best_score = np.inf\n",
        "best_params = None\n",
        "\n",
        "for params in ParameterGrid(param_grid):\n",
        "  print(\"Testing parameters: \", params)\n",
        "\n",
        "  mlp = create_MLP_model(negative_sharpe_loss,\n",
        "                         asset_num,\n",
        "                         mlp_input_shape,\n",
        "                         params)\n",
        "\n",
        "  preds, avg_score = walk_forward(n_train=n_train,\n",
        "                                      n_val=n_val,\n",
        "                                      df=df_trainval,\n",
        "                                      epochs=params['epochs'],\n",
        "                                      batch=batch,\n",
        "                                      model=mlp,\n",
        "                                      asset_num=len(x_tickers),\n",
        "                                      best_params=best_params,\n",
        "                                      best_score=best_score)\n",
        "\n",
        "  if avg_score < best_score:\n",
        "    best_score = avg_score\n",
        "    best_params = params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ICyEsyTuME"
      },
      "source": [
        "#### Train MLP on best params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "6naCDoDqcRo-",
        "outputId": "169ff097-601a-44bc-fdcb-25cdf9601bc7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_params' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bca2bedf354b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
          ]
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3oW7hicvpf",
        "outputId": "cea0d9f0-bf82-4bda-e6e1-d07145fb8bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 11ms/step - loss: -6.5111\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: -8.2369\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: -8.1571\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -7.8410\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -9.3112\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: -9.1228\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -9.5928\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -10.0036\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -10.1391\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -10.7950\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -10.7124\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -11.5681\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.3114\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: -13.8682\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.8612\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.0159\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -11.7096\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -12.3323\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: -12.8546\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.5402\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.7289\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.2091\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.9407\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.5001\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.0048\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.2182\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.6369\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.3368\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.3288\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.8912\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -12.3584\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -14.2127\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.0450\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.8900\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: -14.0240\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.1608\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.8244\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.7428\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.9487\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: -14.7079\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.1473\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: -14.7298\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.7832\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.6298\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.8971\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -12.2847\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.9143\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.5358\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.4987\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.7296\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.2845\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.8765\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.6069\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -13.9378\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.4747\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.4592\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.9329\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.9118\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -16.0088\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.8284\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.7063\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -16.2767\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -16.1402\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.0292\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.3315\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -17.2672\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.3954\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.0034\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -14.9926\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -15.1882\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.8978\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: -13.7560\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.6308\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.6777\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -13.9119\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.0300\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: -12.1672\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -14.5715\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: -16.0435\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.9375\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -13.8717\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: -15.8136\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -12.9149\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -15.4071\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -16.7068\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.9686\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -16.2886\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: -16.0362\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -16.0068\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.4387\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -14.5590\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.2559\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -16.2755\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: -13.2885\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -16.0679\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.6351\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -16.5678\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -15.3394\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -16.5445\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: -16.7729\n"
          ]
        }
      ],
      "source": [
        "# train with best params\n",
        "mlp = create_MLP_model(negative_sharpe_loss,\n",
        "                         asset_num,\n",
        "                         mlp_input_shape,\n",
        "                         best_params)\n",
        "\n",
        "mlp_history = mlp.fit(\n",
        "                      df_trainval.iloc[:, :-asset_num],\n",
        "                      df_trainval.iloc[:, -asset_num:],\n",
        "                      epochs=best_params['epochs'],\n",
        "                      batch_size=batch,\n",
        "                      verbose=1\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHR_1ZVJTzda"
      },
      "source": [
        "#### Predict out-of-sample performance on test dataset for MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnD63MMX7qIf",
        "outputId": "463f16e7-a8f2-4725-b9d5-c6be574cd1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 111ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_test_mlp = mlp.predict(df_test.iloc[:, :-asset_num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "AM72kqMhgBOi",
        "outputId": "8fee484f-4c35-4c9e-aa41-a40833a3e41b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mlp_wts"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-53470908-8eed-4d6c-9061-321f1ed61527\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-07-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53470908-8eed-4d6c-9061-321f1ed61527')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53470908-8eed-4d6c-9061-321f1ed61527 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53470908-8eed-4d6c-9061-321f1ed61527');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b94d773-a19b-4396-9053-8246e5780e4c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b94d773-a19b-4396-9053-8246e5780e4c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b94d773-a19b-4396-9053-8246e5780e4c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_317cb422-d2bc-4031-906b-739a192ad89b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('mlp_wts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_317cb422-d2bc-4031-906b-739a192ad89b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('mlp_wts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker      ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  \\\n",
              "Date                                                          ...             \n",
              "2021-07-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-08-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-09-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-10-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-11-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-12-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-01-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-02-28 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-03-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-04-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-05-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-06-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-07-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-08-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-09-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-10-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-11-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-12-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-01-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-02-28 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-03-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-04-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-05-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-06-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "\n",
              "Ticker      SPGI  SWK  SYY  TGT  TROW  WMT  WST  XOM  \n",
              "Date                                                  \n",
              "2021-07-31  0.00 0.04 0.08 0.11  0.00 0.00 0.03 0.02  \n",
              "2021-08-31  0.00 0.04 0.08 0.11  0.00 0.00 0.03 0.02  \n",
              "2021-09-30  0.00 0.04 0.06 0.12  0.00 0.00 0.03 0.01  \n",
              "2021-10-31  0.00 0.04 0.06 0.12  0.00 0.00 0.03 0.01  \n",
              "2021-11-30  0.00 0.04 0.06 0.12  0.00 0.00 0.03 0.01  \n",
              "2021-12-31  0.00 0.04 0.05 0.10  0.00 0.00 0.02 0.01  \n",
              "2022-01-31  0.00 0.03 0.04 0.10  0.00 0.00 0.02 0.01  \n",
              "2022-02-28  0.00 0.02 0.04 0.11  0.00 0.00 0.02 0.01  \n",
              "2022-03-31  0.00 0.01 0.14 0.10  0.00 0.00 0.00 0.01  \n",
              "2022-04-30  0.00 0.00 0.32 0.05  0.00 0.00 0.00 0.00  \n",
              "2022-05-31  0.00 0.00 0.29 0.06  0.00 0.00 0.00 0.00  \n",
              "2022-06-30  0.00 0.00 0.39 0.03  0.00 0.00 0.00 0.00  \n",
              "2022-07-31  0.00 0.00 0.39 0.03  0.00 0.00 0.00 0.00  \n",
              "2022-08-31  0.00 0.00 0.54 0.01  0.00 0.00 0.00 0.00  \n",
              "2022-09-30  0.00 0.00 0.68 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-10-31  0.00 0.00 0.73 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-11-30  0.00 0.00 0.71 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-12-31  0.00 0.00 0.72 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-01-31  0.00 0.00 0.69 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-02-28  0.00 0.00 0.76 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-03-31  0.00 0.00 0.68 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-04-30  0.00 0.00 0.68 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-05-31  0.00 0.00 0.73 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-06-30  0.00 0.00 0.76 0.00  0.00 0.00 0.00 0.00  \n",
              "\n",
              "[24 rows x 61 columns]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_wts = pd.DataFrame(y_pred_test_mlp, index=test_date_index, columns=dataset.Ticker[:asset_num])\n",
        "mlp_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDSC2i11ULsB",
        "outputId": "24e31c93-166c-43e4-c37f-a8a51a69a553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/WQU_Capstone/Capstone Project/models/mlp/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/WQU_Capstone/Capstone Project/models/mlp/assets\n"
          ]
        }
      ],
      "source": [
        "# # save mlp model to \"disk\" for easier access if needed\n",
        "# mlp.save(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/models/mlp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swEt8sqyUSJl"
      },
      "outputs": [],
      "source": [
        "# # load best model for next time if needed\n",
        "# loaded_mlp_model = tf.keras.models.load_model(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/models/mlp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZKFj_RZmII3"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL3YYeUjmz7Q",
        "outputId": "b89b806b-4cbf-43f0-898d-d6c8c93f6e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 30, 427)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_length = n_train + n_val\n",
        "cnn_input_shape = (batch, sequence_length, mlp_input_shape)\n",
        "cnn_input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX7JaW9bRGmc"
      },
      "outputs": [],
      "source": [
        "cnn_param_grid = {\n",
        "    # 'filters': [32, 64, 128],\n",
        "    # 'kernel_size': [3, 5, 7],\n",
        "    # 'dense_units': [64, 128, 256],\n",
        "    # 'optimizer': ['adam', 'sgd'],\n",
        "    # 'learning_rate': [0.001, 0.01, 0.1],\n",
        "    # 'activation': ['relu'],\n",
        "    # 'epochs': [50, 100]\n",
        "    'filters': [32, 64],\n",
        "    'kernel_size': [3],\n",
        "    'dense_units': [64],\n",
        "    'optimizer': ['adam'],\n",
        "    'learning_rate': [0.001],\n",
        "    'activation': ['relu'],\n",
        "    'epochs': [50]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP2qCU_8ndw6"
      },
      "outputs": [],
      "source": [
        "X_train_cnn = df_trainval.iloc[:, :-asset_num]\n",
        "y_train_cnn = df_trainval.iloc[:, -asset_num:]\n",
        "\n",
        "X_train_cnn_reshaped = np.reshape(X_train_cnn.to_numpy(), (X_train_cnn.shape[0], X_train_cnn.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u5t75gamHLj"
      },
      "outputs": [],
      "source": [
        "# Define CNN model\n",
        "def create_CNN_model(custom_loss, asset_num, input_shape, params):\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation=params['activation'], input_shape=input_shape),\n",
        "      tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(params['dense_units'], activation=params['activation']),\n",
        "      tf.keras.layers.Dense(asset_num, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=params['optimizer'], loss=custom_loss)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7If-lS0T-76",
        "outputId": "7c68ea4c-9827-4bf6-b09c-e50bc6d5e27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing parameters:  {'activation': 'relu', 'dense_units': 64, 'epochs': 50, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: -5.6351 - val_loss: -23.6739\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -6.0737 - val_loss: -22.5832\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -6.4594 - val_loss: -20.3378\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -6.8699 - val_loss: -17.4458\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -7.2706 - val_loss: -15.1379\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -7.6478 - val_loss: -13.7895\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -7.9641 - val_loss: -13.1983\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -8.1796 - val_loss: -13.5569\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -8.5163 - val_loss: -14.2733\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -8.9313 - val_loss: -14.9199\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -9.2103 - val_loss: -15.6294\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -9.3478 - val_loss: -16.0542\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -9.4447 - val_loss: -15.8203\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -9.6158 - val_loss: -15.1300\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -9.8583 - val_loss: -14.2925\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -10.1101 - val_loss: -13.6126\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -10.3506 - val_loss: -13.1966\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -10.6203 - val_loss: -12.8134\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -10.9515 - val_loss: -12.0746\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -11.3332 - val_loss: -10.7449\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -11.6292 - val_loss: -9.4235\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.6837 - val_loss: -9.4564\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.7872 - val_loss: -10.5475\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -11.9780 - val_loss: -11.0465\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -12.1840 - val_loss: -10.5125\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -12.4625 - val_loss: -9.8402\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -12.6646 - val_loss: -9.6778\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -12.8610 - val_loss: -9.9258\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -13.0322 - val_loss: -10.0803\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -13.1461 - val_loss: -9.8747\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -13.2671 - val_loss: -9.5769\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -13.3449 - val_loss: -9.6098\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -13.4626 - val_loss: -9.9799\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: -13.6536 - val_loss: -10.4528\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -13.8552 - val_loss: -10.5556\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -14.0124 - val_loss: -10.0138\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: -14.1463 - val_loss: -9.4940\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: -14.2164 - val_loss: -9.8422\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -14.3415 - val_loss: -10.4898\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -14.4859 - val_loss: -10.2663\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.7403 - val_loss: -9.7434\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.0353 - val_loss: -9.8799\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: -15.3506 - val_loss: -10.4817\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.5521 - val_loss: -10.3320\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -15.7977 - val_loss: -9.7991\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.2338 - val_loss: -10.3196\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -16.6338 - val_loss: -10.9585\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -16.9317 - val_loss: -10.1360\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -17.3397 - val_loss: -10.2890\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.7376 - val_loss: -10.6665\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -14.8909 - val_loss: -6.9738\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.8182 - val_loss: -7.5924\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -15.3186 - val_loss: -7.8311\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.6409 - val_loss: -7.8036\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -16.2736 - val_loss: -7.2204\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.2066 - val_loss: -7.1692\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -16.3530 - val_loss: -7.1246\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -16.9010 - val_loss: -7.1011\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -16.7663 - val_loss: -6.9446\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -16.7474 - val_loss: -6.6513\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.1005 - val_loss: -6.5839\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -17.0956 - val_loss: -7.1745\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.5026 - val_loss: -7.9551\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -17.4811 - val_loss: -8.4224\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.5336 - val_loss: -8.4474\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -17.7882 - val_loss: -8.0567\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.9084 - val_loss: -7.5752\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.9845 - val_loss: -7.3747\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.0884 - val_loss: -7.3743\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -18.0829 - val_loss: -7.4418\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.2561 - val_loss: -7.6392\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -18.3271 - val_loss: -7.9580\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -18.3918 - val_loss: -8.0385\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -18.4828 - val_loss: -7.7258\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -18.5751 - val_loss: -7.2259\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -18.7030 - val_loss: -6.8866\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -18.7717 - val_loss: -6.8693\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -18.9185 - val_loss: -6.8579\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -18.9748 - val_loss: -6.6080\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -19.0821 - val_loss: -6.2651\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -19.1348 - val_loss: -6.1411\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -19.2289 - val_loss: -6.1333\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -19.3188 - val_loss: -6.0744\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.4109 - val_loss: -5.9858\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.4734 - val_loss: -5.9144\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -19.5614 - val_loss: -5.8077\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -19.6452 - val_loss: -5.7154\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -19.7126 - val_loss: -5.6994\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -19.7787 - val_loss: -5.5607\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -19.8451 - val_loss: -5.3605\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.9059 - val_loss: -5.3802\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -19.9906 - val_loss: -5.4106\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -20.0622 - val_loss: -5.2734\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.1396 - val_loss: -5.2032\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.2139 - val_loss: -5.1337\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.4939 - val_loss: -5.1728\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -20.5644 - val_loss: -5.0235\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -20.6468 - val_loss: -5.0377\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.7221 - val_loss: -4.9726\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.7728 - val_loss: -5.1521\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -9.3063 - val_loss: -6.4302\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -11.1875 - val_loss: -12.0028\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -13.3938 - val_loss: -16.5653\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -14.1576 - val_loss: -18.0233\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -14.3192 - val_loss: -18.4777\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -13.9348 - val_loss: -18.7451\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -13.6110 - val_loss: -19.0669\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -14.4286 - val_loss: -19.5977\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -15.5942 - val_loss: -19.8381\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.5935 - val_loss: -19.4099\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -15.2520 - val_loss: -19.0497\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -15.8667 - val_loss: -19.2151\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -16.3487 - val_loss: -19.4231\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -16.6607 - val_loss: -18.8183\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -17.0268 - val_loss: -16.8378\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -17.5528 - val_loss: -14.7488\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -16.9099 - val_loss: -14.4134\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -17.3006 - val_loss: -14.7514\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.2228 - val_loss: -15.2107\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -18.0061 - val_loss: -15.8186\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -18.1617 - val_loss: -16.4967\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -18.3216 - val_loss: -16.0211\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.1164 - val_loss: -14.5138\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.5180 - val_loss: -12.9135\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -18.5578 - val_loss: -12.3144\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.0765 - val_loss: -12.0379\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -18.9162 - val_loss: -11.7736\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.2864 - val_loss: -11.7476\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.0227 - val_loss: -12.2658\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -19.3480 - val_loss: -12.3634\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -19.3070 - val_loss: -11.9272\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.5109 - val_loss: -11.4365\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.5234 - val_loss: -11.1369\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.5871 - val_loss: -10.8732\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.6272 - val_loss: -10.7823\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -19.6971 - val_loss: -11.1291\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -19.8852 - val_loss: -11.5811\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -19.8711 - val_loss: -11.5330\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -20.0228 - val_loss: -11.0066\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.0040 - val_loss: -10.5271\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -20.1929 - val_loss: -9.9293\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.2728 - val_loss: -9.4134\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.2728 - val_loss: -9.3569\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -20.4106 - val_loss: -9.3371\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.4078 - val_loss: -9.1745\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -20.4629 - val_loss: -9.2025\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.5727 - val_loss: -9.2984\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.5888 - val_loss: -9.3354\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.6734 - val_loss: -9.5705\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -20.7584 - val_loss: -9.7872\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.3802 - val_loss: -10.1479\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -17.5392 - val_loss: -11.8155\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -19.0223 - val_loss: -11.9644\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -18.7410 - val_loss: -11.7531\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -18.6453 - val_loss: -11.7002\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -19.1139 - val_loss: -11.8621\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -20.2810 - val_loss: -12.3363\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -20.9925 - val_loss: -13.2178\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -20.5630 - val_loss: -13.7352\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.7851 - val_loss: -12.9125\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -22.1958 - val_loss: -11.1474\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -22.6765 - val_loss: -10.2097\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -22.2572 - val_loss: -10.3014\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -23.5154 - val_loss: -10.8426\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -24.0697 - val_loss: -11.5009\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -23.6583 - val_loss: -12.2505\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -23.4693 - val_loss: -12.8120\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -23.5744 - val_loss: -12.6863\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -23.8365 - val_loss: -11.8623\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -24.1402 - val_loss: -11.1806\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -24.4300 - val_loss: -11.3310\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -24.5901 - val_loss: -12.6536\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -24.6173 - val_loss: -14.8333\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -24.6760 - val_loss: -15.9974\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -24.5768 - val_loss: -15.0956\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -24.6284 - val_loss: -13.4167\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -24.8731 - val_loss: -12.1236\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -24.8695 - val_loss: -11.5711\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -24.8345 - val_loss: -11.7251\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -24.9337 - val_loss: -12.4433\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -25.0124 - val_loss: -13.3665\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -25.0636 - val_loss: -13.7479\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.2168 - val_loss: -13.0603\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -25.3265 - val_loss: -12.2146\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.1686 - val_loss: -12.3646\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -25.1647 - val_loss: -13.3966\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: -25.3724 - val_loss: -14.0555\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.4213 - val_loss: -13.5747\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.4056 - val_loss: -12.6096\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -25.4235 - val_loss: -11.9901\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -25.4256 - val_loss: -12.0625\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -25.4596 - val_loss: -12.8240\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -25.5667 - val_loss: -13.8767\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -25.6222 - val_loss: -14.2815\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -25.6134 - val_loss: -13.5926\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -25.6554 - val_loss: -12.7569\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -25.7132 - val_loss: -12.6061\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.7745 - val_loss: -12.9619\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: -25.8268 - val_loss: -13.2400\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -25.8946 - val_loss: -13.1666\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -19.6258 - val_loss: -15.2177\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -25.3545 - val_loss: -13.2305\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -22.8874 - val_loss: -14.3656\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -24.1544 - val_loss: -18.3008\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -25.2395 - val_loss: -19.8518\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -23.9312 - val_loss: -19.5482\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -25.3417 - val_loss: -17.1882\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -27.3409 - val_loss: -15.6801\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -27.2731 - val_loss: -15.9902\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -26.2053 - val_loss: -16.3168\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -26.3499 - val_loss: -16.2349\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -27.9663 - val_loss: -16.1464\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -28.4566 - val_loss: -16.7095\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -28.5075 - val_loss: -17.2155\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -28.4960 - val_loss: -16.6855\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -28.7278 - val_loss: -15.2080\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -29.4602 - val_loss: -13.7355\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -29.7508 - val_loss: -12.8532\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -29.5993 - val_loss: -12.4087\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -29.1444 - val_loss: -12.3177\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -29.4666 - val_loss: -12.5541\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -29.9790 - val_loss: -13.1150\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -30.3966 - val_loss: -13.7284\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -30.3488 - val_loss: -13.9828\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -30.1806 - val_loss: -14.4727\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -30.3897 - val_loss: -14.6726\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -30.4597 - val_loss: -14.6110\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -30.5848 - val_loss: -14.4227\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -30.7015 - val_loss: -14.3097\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -30.8183 - val_loss: -14.2721\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -30.8866 - val_loss: -14.2434\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -30.9571 - val_loss: -14.3468\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -31.0431 - val_loss: -14.6251\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -31.1776 - val_loss: -14.8615\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -31.3106 - val_loss: -14.9463\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -31.4418 - val_loss: -14.9493\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -31.5987 - val_loss: -14.8469\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -31.7488 - val_loss: -14.6326\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -31.8369 - val_loss: -14.5627\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -31.8590 - val_loss: -14.7967\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -31.9198 - val_loss: -15.2133\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -32.0013 - val_loss: -15.6277\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -32.0398 - val_loss: -15.9213\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -32.0410 - val_loss: -15.9591\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -32.0760 - val_loss: -15.6987\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -32.1495 - val_loss: -15.3929\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -32.2162 - val_loss: -15.2460\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -32.2777 - val_loss: -15.2519\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -32.3203 - val_loss: -15.3875\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -32.3546 - val_loss: -15.5658\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -24.7458 - val_loss: -13.7504\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -26.6180 - val_loss: -13.1188\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -26.9219 - val_loss: -12.8430\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -26.1598 - val_loss: -12.8882\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -26.3809 - val_loss: -13.0093\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -27.2869 - val_loss: -13.2945\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -28.2707 - val_loss: -13.9744\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -27.9788 - val_loss: -14.0692\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -28.1477 - val_loss: -13.4760\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -29.3911 - val_loss: -13.1662\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -29.5997 - val_loss: -13.1261\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -29.4962 - val_loss: -13.2268\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -30.1065 - val_loss: -13.4211\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -30.8349 - val_loss: -13.6105\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -30.6077 - val_loss: -13.6021\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -31.1375 - val_loss: -13.1978\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -31.9187 - val_loss: -12.8288\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -32.0739 - val_loss: -12.6788\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -32.4723 - val_loss: -12.7250\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -33.1994 - val_loss: -12.7349\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -33.5109 - val_loss: -12.5569\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -34.0888 - val_loss: -12.5866\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -34.9608 - val_loss: -12.5919\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -35.2897 - val_loss: -12.4671\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -36.1872 - val_loss: -12.3830\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -36.8320 - val_loss: -12.4194\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -37.3559 - val_loss: -12.3060\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -37.7062 - val_loss: -12.1677\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -37.9168 - val_loss: -12.0827\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -38.6251 - val_loss: -12.0222\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -39.0668 - val_loss: -11.8856\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -39.3759 - val_loss: -11.8672\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -39.6406 - val_loss: -11.8012\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -39.9414 - val_loss: -11.6223\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -40.4758 - val_loss: -11.7041\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -40.4224 - val_loss: -11.5920\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -40.7368 - val_loss: -11.3776\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -40.9937 - val_loss: -11.4527\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -41.3948 - val_loss: -11.4455\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -41.5805 - val_loss: -11.3348\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -42.0223 - val_loss: -11.4432\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -42.2192 - val_loss: -11.3754\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -42.4894 - val_loss: -11.2067\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -42.9202 - val_loss: -11.2542\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -43.1390 - val_loss: -11.1083\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -43.6590 - val_loss: -11.0412\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -44.0825 - val_loss: -10.8959\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -44.5348 - val_loss: -10.6647\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -44.5168 - val_loss: -10.7726\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -44.9935 - val_loss: -10.5046\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -19.8610 - val_loss: -10.6179\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.0659 - val_loss: -10.9985\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -20.7934 - val_loss: -11.7237\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -21.4255 - val_loss: -12.5830\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -21.5569 - val_loss: -13.1496\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -21.8648 - val_loss: -13.2151\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -22.8738 - val_loss: -12.8523\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -24.1945 - val_loss: -12.5574\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -25.0670 - val_loss: -12.9428\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -26.4817 - val_loss: -13.8599\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -28.0954 - val_loss: -13.7005\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -29.3239 - val_loss: -12.2562\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -31.4033 - val_loss: -11.9229\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -32.2081 - val_loss: -12.2134\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -32.1320 - val_loss: -11.5289\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -33.7389 - val_loss: -11.7929\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -35.3014 - val_loss: -12.8183\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -34.9226 - val_loss: -12.3797\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -36.5461 - val_loss: -12.9595\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -37.5365 - val_loss: -13.6035\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -37.4290 - val_loss: -12.2682\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -39.4833 - val_loss: -12.0088\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -40.6518 - val_loss: -11.9439\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -40.5957 - val_loss: -11.2290\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -39.8553 - val_loss: -11.8974\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -41.8858 - val_loss: -11.6687\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -42.9004 - val_loss: -11.4160\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -42.7783 - val_loss: -11.8074\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -42.7986 - val_loss: -11.0602\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -43.8646 - val_loss: -11.3624\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: -45.2577 - val_loss: -11.1139\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -46.2513 - val_loss: -11.4373\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -47.0933 - val_loss: -10.9102\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -45.1648 - val_loss: -11.6606\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -44.6140 - val_loss: -11.0262\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: -49.2785 - val_loss: -10.6908\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -48.2333 - val_loss: -11.1370\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -44.4757 - val_loss: -10.7905\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -46.0856 - val_loss: -10.7417\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -48.9955 - val_loss: -11.6218\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -41.8276 - val_loss: -11.3510\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -48.8751 - val_loss: -10.5877\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -41.4915 - val_loss: -10.7550\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -43.1377 - val_loss: -11.1689\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -48.3970 - val_loss: -11.0149\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -45.9255 - val_loss: -10.5339\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -45.2381 - val_loss: -10.6685\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -50.0655 - val_loss: -11.3268\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -45.3444 - val_loss: -11.2761\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -45.1021 - val_loss: -10.6954\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -20.9064 - val_loss: -12.2714\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -19.8218 - val_loss: -12.8734\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -18.9285 - val_loss: -13.1317\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -18.6292 - val_loss: -13.0917\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -19.0326 - val_loss: -12.7530\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -20.1988 - val_loss: -12.0851\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -22.0395 - val_loss: -11.1352\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -23.8347 - val_loss: -10.2146\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -24.4073 - val_loss: -9.7011\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -23.9776 - val_loss: -9.5600\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -23.6818 - val_loss: -9.6522\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -24.2165 - val_loss: -9.9351\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -25.8875 - val_loss: -10.4224\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -28.2593 - val_loss: -11.0270\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -28.9913 - val_loss: -11.3864\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -27.9482 - val_loss: -11.2820\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -28.5383 - val_loss: -10.7761\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -30.5891 - val_loss: -10.1498\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -30.9218 - val_loss: -9.7057\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -30.6344 - val_loss: -9.4747\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -31.8054 - val_loss: -9.4214\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -32.6603 - val_loss: -9.4758\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -32.3052 - val_loss: -9.4744\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -32.5318 - val_loss: -9.3689\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -33.5937 - val_loss: -9.2247\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -34.1430 - val_loss: -9.1597\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -33.9453 - val_loss: -9.1799\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -34.3456 - val_loss: -9.2213\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -35.0498 - val_loss: -9.1901\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -35.4107 - val_loss: -9.0149\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -35.7417 - val_loss: -8.7728\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -36.1777 - val_loss: -8.6289\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -36.7915 - val_loss: -8.6476\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -37.3896 - val_loss: -8.7597\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -37.8950 - val_loss: -8.8575\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -38.7944 - val_loss: -8.8186\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: -39.4850 - val_loss: -8.6528\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -40.2165 - val_loss: -8.4788\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -41.4123 - val_loss: -8.3209\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -42.1411 - val_loss: -8.2261\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -43.3779 - val_loss: -8.2825\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -44.7761 - val_loss: -8.4084\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -45.7743 - val_loss: -8.2616\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -47.5397 - val_loss: -8.0509\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -48.8960 - val_loss: -8.0308\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -49.6024 - val_loss: -7.9890\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -49.7310 - val_loss: -8.3553\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -50.0382 - val_loss: -8.0110\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -51.8727 - val_loss: -8.1200\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -54.3325 - val_loss: -7.8976\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -14.2723 - val_loss: -9.9700\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -14.0925 - val_loss: -9.9411\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -14.2318 - val_loss: -9.9213\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -14.7600 - val_loss: -9.9002\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -15.6801 - val_loss: -9.8832\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -16.9047 - val_loss: -9.8598\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.1934 - val_loss: -9.8053\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -19.0413 - val_loss: -9.7141\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -19.2025 - val_loss: -9.6227\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -19.0643 - val_loss: -9.5605\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -19.0976 - val_loss: -9.4973\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -19.5050 - val_loss: -9.5017\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -20.3893 - val_loss: -9.5663\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.5937 - val_loss: -9.6789\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -22.4987 - val_loss: -9.7916\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -22.8283 - val_loss: -9.8456\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -23.3738 - val_loss: -9.8236\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -24.2941 - val_loss: -9.7470\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -24.7378 - val_loss: -9.6621\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -24.5637 - val_loss: -9.6250\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -24.5688 - val_loss: -9.6594\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -25.3649 - val_loss: -9.7112\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -26.2591 - val_loss: -9.7419\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -26.4845 - val_loss: -9.7368\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -26.2654 - val_loss: -9.7035\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -26.4627 - val_loss: -9.6654\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -26.8895 - val_loss: -9.6443\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -27.0899 - val_loss: -9.6462\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -27.3476 - val_loss: -9.6455\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -27.8587 - val_loss: -9.6292\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -28.2214 - val_loss: -9.6029\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -28.1898 - val_loss: -9.5739\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -28.2201 - val_loss: -9.5587\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -28.4469 - val_loss: -9.5655\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -28.6533 - val_loss: -9.5732\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -28.8388 - val_loss: -9.5726\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -29.0935 - val_loss: -9.5668\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -29.2370 - val_loss: -9.5630\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -29.2214 - val_loss: -9.5545\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -29.4131 - val_loss: -9.5406\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -29.6507 - val_loss: -9.5219\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -29.8160 - val_loss: -9.4933\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: -30.0414 - val_loss: -9.4535\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -30.1224 - val_loss: -9.4214\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -30.2121 - val_loss: -9.4111\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -30.4031 - val_loss: -9.4193\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: -30.5573 - val_loss: -9.4318\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -30.7155 - val_loss: -9.4384\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -30.8386 - val_loss: -9.4366\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -30.8988 - val_loss: -9.4251\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -16.3287 - val_loss: -20.0642\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.3811 - val_loss: -20.1580\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.4672 - val_loss: -20.3155\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -16.5755 - val_loss: -20.4920\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.6990 - val_loss: -20.6474\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.8374 - val_loss: -20.7782\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.9882 - val_loss: -20.8647\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -17.1574 - val_loss: -20.9169\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.3396 - val_loss: -20.9493\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.5264 - val_loss: -20.9699\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.7106 - val_loss: -20.9788\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.8911 - val_loss: -20.9720\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.0716 - val_loss: -20.9415\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.2562 - val_loss: -20.8807\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.4429 - val_loss: -20.7888\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -18.6250 - val_loss: -20.6691\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -18.7974 - val_loss: -20.5491\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.9605 - val_loss: -20.4442\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -19.1198 - val_loss: -20.3608\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -19.2776 - val_loss: -20.2978\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -19.4315 - val_loss: -20.2382\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -19.5766 - val_loss: -20.1653\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -19.7117 - val_loss: -20.0699\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -19.8407 - val_loss: -19.9507\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -19.9669 - val_loss: -19.8168\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.0900 - val_loss: -19.6838\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.2061 - val_loss: -19.5689\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -20.3129 - val_loss: -19.4867\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.4126 - val_loss: -19.4421\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.5088 - val_loss: -19.4304\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -20.5998 - val_loss: -19.4407\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.6853 - val_loss: -19.4591\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -20.7672 - val_loss: -19.4752\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -20.8461 - val_loss: -19.4848\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.9218 - val_loss: -19.4903\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -20.9936 - val_loss: -19.4965\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -21.0609 - val_loss: -19.5090\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -21.1250 - val_loss: -19.5294\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -21.1874 - val_loss: -19.5546\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.2485 - val_loss: -19.5775\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -21.3072 - val_loss: -19.5969\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.3630 - val_loss: -19.6144\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -21.4164 - val_loss: -19.6242\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -21.4671 - val_loss: -19.6323\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.5163 - val_loss: -19.6472\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -21.5636 - val_loss: -19.6701\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.6099 - val_loss: -19.7078\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -21.6556 - val_loss: -19.7562\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: -21.7002 - val_loss: -19.8075\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.7422 - val_loss: -19.8538\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -19.1458 - val_loss: -10.4355\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -19.2163 - val_loss: -10.2903\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -19.3048 - val_loss: -10.1390\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -19.3854 - val_loss: -10.0015\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -19.4485 - val_loss: -9.8902\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -19.4927 - val_loss: -9.8081\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -19.5293 - val_loss: -9.7558\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -19.5740 - val_loss: -9.7314\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -19.6410 - val_loss: -9.7325\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.7348 - val_loss: -9.7563\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -19.8494 - val_loss: -9.8002\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -19.9808 - val_loss: -9.8628\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -20.1263 - val_loss: -9.9385\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -20.2841 - val_loss: -10.0149\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -20.4514 - val_loss: -10.0828\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.6225 - val_loss: -10.1327\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -20.7684 - val_loss: -10.1572\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -20.8649 - val_loss: -10.1509\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -20.9338 - val_loss: -10.1091\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -21.0105 - val_loss: -10.0482\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -21.0907 - val_loss: -9.9793\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -21.1487 - val_loss: -9.9080\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -21.1870 - val_loss: -9.8323\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -21.2175 - val_loss: -9.7473\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -21.2425 - val_loss: -9.6535\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -21.2705 - val_loss: -9.5585\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -21.3030 - val_loss: -9.4779\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -21.3236 - val_loss: -9.4208\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.3336 - val_loss: -9.3893\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -21.3557 - val_loss: -9.3796\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.3985 - val_loss: -9.3839\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -21.4482 - val_loss: -9.3905\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -21.4940 - val_loss: -9.3944\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -21.5388 - val_loss: -9.3959\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.5790 - val_loss: -9.3978\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.6164 - val_loss: -9.4020\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -21.6548 - val_loss: -9.4067\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -21.6898 - val_loss: -9.4080\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -21.7205 - val_loss: -9.4029\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -21.7554 - val_loss: -9.3922\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -21.7965 - val_loss: -9.3806\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -21.8370 - val_loss: -9.3718\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -21.8770 - val_loss: -9.3666\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -21.9206 - val_loss: -9.3626\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -21.9678 - val_loss: -9.3566\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -22.0202 - val_loss: -9.3473\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -22.0802 - val_loss: -9.3364\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -22.1452 - val_loss: -9.3270\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -22.2142 - val_loss: -9.3211\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -22.2900 - val_loss: -9.3177\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -14.3637 - val_loss: -11.1723\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -14.4108 - val_loss: -11.2004\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -14.4806 - val_loss: -11.2510\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -14.5725 - val_loss: -11.3332\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -14.6924 - val_loss: -11.4645\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -14.8557 - val_loss: -11.6788\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -15.0873 - val_loss: -12.0413\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -15.4183 - val_loss: -12.6623\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -15.8592 - val_loss: -13.6204\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -16.2964 - val_loss: -14.5686\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -16.4189 - val_loss: -14.8755\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -16.2073 - val_loss: -14.9293\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.1050 - val_loss: -15.1780\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -16.3221 - val_loss: -15.3608\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -16.7538 - val_loss: -14.9381\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.0850 - val_loss: -14.1399\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -17.0993 - val_loss: -13.5975\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.9857 - val_loss: -13.4867\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.9918 - val_loss: -13.7299\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -17.1667 - val_loss: -14.1942\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -17.4285 - val_loss: -14.6616\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.6430 - val_loss: -14.8721\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.7117 - val_loss: -14.7722\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -17.6904 - val_loss: -14.5319\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.6913 - val_loss: -14.2783\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: -17.7630 - val_loss: -14.0415\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.8570 - val_loss: -13.8728\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.9202 - val_loss: -13.8493\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -17.9504 - val_loss: -13.9916\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.9584 - val_loss: -14.2180\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.9653 - val_loss: -14.3772\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.0144 - val_loss: -14.3708\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.0998 - val_loss: -14.2432\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -18.1583 - val_loss: -14.0935\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.1679 - val_loss: -13.9899\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -18.1702 - val_loss: -13.9527\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -18.2031 - val_loss: -13.9722\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.2634 - val_loss: -14.0126\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.3179 - val_loss: -14.0162\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -18.3441 - val_loss: -13.9309\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.3581 - val_loss: -13.7579\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.3871 - val_loss: -13.5635\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.4309 - val_loss: -13.4243\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.4705 - val_loss: -13.3694\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.5044 - val_loss: -13.3842\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -18.5392 - val_loss: -13.4131\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -18.5706 - val_loss: -13.3932\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.5982 - val_loss: -13.2918\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -18.6328 - val_loss: -13.1202\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -18.6740 - val_loss: -12.9306\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -16.5501 - val_loss: -7.2638\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.6296 - val_loss: -7.3217\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -16.7674 - val_loss: -7.4215\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -16.8699 - val_loss: -7.5455\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -16.9299 - val_loss: -7.6648\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.0018 - val_loss: -7.7544\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -17.1232 - val_loss: -7.7970\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.2792 - val_loss: -7.8008\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: -17.4467 - val_loss: -7.7794\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.5854 - val_loss: -7.7553\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -17.6575 - val_loss: -7.7449\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.6299 - val_loss: -7.7638\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -17.5985 - val_loss: -7.8168\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -17.5997 - val_loss: -7.8988\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -17.5784 - val_loss: -7.9980\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.5865 - val_loss: -8.0954\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.6155 - val_loss: -8.1756\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -17.6668 - val_loss: -8.2291\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -17.7420 - val_loss: -8.2486\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -17.8262 - val_loss: -8.2390\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -17.8797 - val_loss: -8.2112\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -17.9306 - val_loss: -8.1846\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -18.0026 - val_loss: -8.1731\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -18.0350 - val_loss: -8.1817\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -18.0544 - val_loss: -8.2027\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -18.0595 - val_loss: -8.2215\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -18.0698 - val_loss: -8.2305\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -18.1098 - val_loss: -8.2327\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -18.1343 - val_loss: -8.2405\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -18.1658 - val_loss: -8.2712\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -18.1917 - val_loss: -8.3309\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -18.2367 - val_loss: -8.4070\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -18.2995 - val_loss: -8.4626\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -18.3053 - val_loss: -8.4794\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.3544 - val_loss: -8.4663\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -18.4115 - val_loss: -8.4553\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -18.4257 - val_loss: -8.4722\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -18.4587 - val_loss: -8.5181\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -18.5234 - val_loss: -8.5705\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -18.5300 - val_loss: -8.6091\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -18.5477 - val_loss: -8.6341\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -18.6008 - val_loss: -8.6498\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -18.6651 - val_loss: -8.6665\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -18.6831 - val_loss: -8.6920\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -18.7096 - val_loss: -8.7213\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -18.7551 - val_loss: -8.7470\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.7848 - val_loss: -8.7766\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.8119 - val_loss: -8.8037\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -18.8512 - val_loss: -8.8110\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -18.8695 - val_loss: -8.8041\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -13.9677 - val_loss: -8.2784\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -14.2115 - val_loss: -8.2383\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -14.5510 - val_loss: -8.1852\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -14.7875 - val_loss: -8.1618\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -14.8167 - val_loss: -8.1599\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -14.6935 - val_loss: -8.1439\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -14.6698 - val_loss: -8.1021\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -14.8646 - val_loss: -8.0674\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -15.1017 - val_loss: -8.0875\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.2034 - val_loss: -8.1590\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -15.2194 - val_loss: -8.2370\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -15.2038 - val_loss: -8.2879\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -15.2257 - val_loss: -8.3061\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -15.3324 - val_loss: -8.2904\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.4847 - val_loss: -8.2409\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -15.6115 - val_loss: -8.1802\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.6525 - val_loss: -8.1583\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -15.6707 - val_loss: -8.2015\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -15.7751 - val_loss: -8.2773\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.9058 - val_loss: -8.3354\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -15.9765 - val_loss: -8.3582\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -16.0294 - val_loss: -8.3551\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -16.0889 - val_loss: -8.3403\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -16.1434 - val_loss: -8.3280\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -16.2019 - val_loss: -8.3320\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.2823 - val_loss: -8.3493\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -16.3557 - val_loss: -8.3657\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.3885 - val_loss: -8.3698\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.4306 - val_loss: -8.3632\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -16.5012 - val_loss: -8.3582\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.5539 - val_loss: -8.3648\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -16.5966 - val_loss: -8.3825\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.6419 - val_loss: -8.4005\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -16.6719 - val_loss: -8.4105\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.6965 - val_loss: -8.4105\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.7378 - val_loss: -8.4034\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.7807 - val_loss: -8.3963\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -16.8041 - val_loss: -8.3994\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -16.8222 - val_loss: -8.4113\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -16.8516 - val_loss: -8.4238\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -16.8806 - val_loss: -8.4316\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -16.8946 - val_loss: -8.4315\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.9138 - val_loss: -8.4287\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -16.9331 - val_loss: -8.4279\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -16.9492 - val_loss: -8.4308\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -16.9620 - val_loss: -8.4369\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.9759 - val_loss: -8.4422\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -16.9820 - val_loss: -8.4441\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -16.9929 - val_loss: -8.4428\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.0144 - val_loss: -8.4410\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.5906 - val_loss: -12.1537\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.5884 - val_loss: -12.1519\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.5938 - val_loss: -12.1547\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.6033 - val_loss: -12.1634\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.6116 - val_loss: -12.1781\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.6173 - val_loss: -12.1991\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.6222 - val_loss: -12.2263\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.6291 - val_loss: -12.2593\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.6395 - val_loss: -12.2978\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.6524 - val_loss: -12.3415\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.6659 - val_loss: -12.3897\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.6775 - val_loss: -12.4368\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.6844 - val_loss: -12.4813\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.6918 - val_loss: -12.5221\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.7008 - val_loss: -12.5581\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -11.7115 - val_loss: -12.5890\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.7228 - val_loss: -12.6144\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.7340 - val_loss: -12.6338\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.7424 - val_loss: -12.6532\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.7500 - val_loss: -12.6716\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.7597 - val_loss: -12.6883\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.7711 - val_loss: -12.7015\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.7829 - val_loss: -12.7106\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.7951 - val_loss: -12.7147\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -11.8075 - val_loss: -12.7128\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.8188 - val_loss: -12.6973\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.8318 - val_loss: -12.6673\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.8479 - val_loss: -12.6220\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.8655 - val_loss: -12.5668\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.8836 - val_loss: -12.4982\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.9036 - val_loss: -12.4105\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.9261 - val_loss: -12.2989\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.9513 - val_loss: -12.1581\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -11.9789 - val_loss: -11.9846\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -12.0072 - val_loss: -11.7755\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -12.0338 - val_loss: -11.5321\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.0562 - val_loss: -11.2643\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.0709 - val_loss: -10.9973\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -12.0764 - val_loss: -10.7518\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.0750 - val_loss: -10.5510\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -12.0697 - val_loss: -10.4138\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -12.0686 - val_loss: -10.3466\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.0747 - val_loss: -10.3427\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -12.0874 - val_loss: -10.3853\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -12.1049 - val_loss: -10.4539\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -12.1245 - val_loss: -10.5290\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: -12.1426 - val_loss: -10.5981\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -12.1558 - val_loss: -10.6510\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -12.1630 - val_loss: -10.6840\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -12.1660 - val_loss: -10.6953\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.3496 - val_loss: -2.3891\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.4063 - val_loss: -2.3803\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.4718 - val_loss: -2.3719\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.5240 - val_loss: -2.3650\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -11.5598 - val_loss: -2.3604\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -11.5845 - val_loss: -2.3584\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -11.6026 - val_loss: -2.3590\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -11.6199 - val_loss: -2.3617\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.6392 - val_loss: -2.3663\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -11.6619 - val_loss: -2.3723\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -11.6875 - val_loss: -2.3791\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.7157 - val_loss: -2.3863\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.7459 - val_loss: -2.3934\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.7773 - val_loss: -2.3998\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.8070 - val_loss: -2.4082\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.8322 - val_loss: -2.4159\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -11.8561 - val_loss: -2.4215\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.8798 - val_loss: -2.4247\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.9034 - val_loss: -2.4255\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.9273 - val_loss: -2.4242\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -11.9504 - val_loss: -2.4214\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -11.9699 - val_loss: -2.4178\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -11.9751 - val_loss: -2.4140\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -11.9801 - val_loss: -2.4107\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -11.9938 - val_loss: -2.4077\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -12.0120 - val_loss: -2.4050\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.0348 - val_loss: -2.4023\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -12.0613 - val_loss: -2.3993\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.0900 - val_loss: -2.3952\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.1186 - val_loss: -2.3899\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -12.1463 - val_loss: -2.3830\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -12.1728 - val_loss: -2.3745\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.1999 - val_loss: -2.3646\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -12.2287 - val_loss: -2.3535\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -12.2579 - val_loss: -2.3418\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -12.2822 - val_loss: -2.3300\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.3021 - val_loss: -2.3185\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.3203 - val_loss: -2.3076\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -12.3366 - val_loss: -2.2973\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.3528 - val_loss: -2.2874\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -12.3689 - val_loss: -2.2778\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -12.3857 - val_loss: -2.2684\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -12.4034 - val_loss: -2.2591\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -12.4218 - val_loss: -2.2497\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.4402 - val_loss: -2.2404\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -12.4553 - val_loss: -2.2315\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: -12.4674 - val_loss: -2.2232\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -12.4799 - val_loss: -2.2154\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -12.4930 - val_loss: -2.2082\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -12.5066 - val_loss: -2.2017\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -4.3525 - val_loss: -6.4828\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -4.3849 - val_loss: -6.4151\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -4.4597 - val_loss: -6.3137\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -4.5840 - val_loss: -6.1777\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -4.7685 - val_loss: -6.0095\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -5.0183 - val_loss: -5.8188\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -5.3147 - val_loss: -5.6221\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -5.6062 - val_loss: -5.4382\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -5.8398 - val_loss: -5.2801\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.0019 - val_loss: -5.1519\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -6.1101 - val_loss: -5.0514\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -6.1852 - val_loss: -4.9741\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.2398 - val_loss: -4.9152\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -6.2788 - val_loss: -4.8706\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.3088 - val_loss: -4.8365\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3309 - val_loss: -4.8103\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.3465 - val_loss: -4.7912\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3572 - val_loss: -4.7774\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -6.3643 - val_loss: -4.7664\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.3688 - val_loss: -4.7580\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3718 - val_loss: -4.7514\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3738 - val_loss: -4.7461\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -6.3754 - val_loss: -4.7418\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -6.3769 - val_loss: -4.7383\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -6.3785 - val_loss: -4.7356\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -6.3805 - val_loss: -4.7333\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -6.3829 - val_loss: -4.7316\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -6.3858 - val_loss: -4.7302\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3894 - val_loss: -4.7292\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -6.3935 - val_loss: -4.7285\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.3982 - val_loss: -4.7281\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.4034 - val_loss: -4.7280\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -6.4091 - val_loss: -4.7281\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.4152 - val_loss: -4.7283\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -6.4217 - val_loss: -4.7288\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -6.4285 - val_loss: -4.7294\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -6.4354 - val_loss: -4.7302\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -6.4422 - val_loss: -4.7311\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.4491 - val_loss: -4.7322\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.4557 - val_loss: -4.7334\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.4621 - val_loss: -4.7348\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -6.4683 - val_loss: -4.7363\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.4743 - val_loss: -4.7379\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -6.4800 - val_loss: -4.7396\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -6.4856 - val_loss: -4.7415\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.4911 - val_loss: -4.7435\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.4967 - val_loss: -4.7456\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -6.5024 - val_loss: -4.7478\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.5084 - val_loss: -4.7502\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -6.5147 - val_loss: -4.7527\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -5.4855 - val_loss: -4.7762\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -5.5088 - val_loss: -4.8521\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -5.5353 - val_loss: -5.0040\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -5.5687 - val_loss: -5.3038\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -5.6271 - val_loss: -5.9083\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -5.7144 - val_loss: -6.9608\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -5.7468 - val_loss: -7.0306\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -5.8352 - val_loss: -6.6866\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -5.9337 - val_loss: -6.4416\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -5.9911 - val_loss: -6.4564\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -6.0436 - val_loss: -6.7176\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -6.1019 - val_loss: -7.1436\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -6.1381 - val_loss: -7.4528\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.1464 - val_loss: -7.3819\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.1625 - val_loss: -7.0500\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -6.1823 - val_loss: -6.6933\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.1883 - val_loss: -6.4570\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -6.1854 - val_loss: -6.3726\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -6.1856 - val_loss: -6.4145\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.1909 - val_loss: -6.5326\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.1959 - val_loss: -6.6560\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.1977 - val_loss: -6.7105\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.2002 - val_loss: -6.6618\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -6.2074 - val_loss: -6.5371\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -6.2172 - val_loss: -6.3939\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -6.2253 - val_loss: -6.2990\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.2306 - val_loss: -6.2860\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -6.2368 - val_loss: -6.3583\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.2451 - val_loss: -6.4887\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.2523 - val_loss: -6.6235\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -6.2561 - val_loss: -6.6912\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.2596 - val_loss: -6.6733\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -6.2650 - val_loss: -6.6046\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.2702 - val_loss: -6.5432\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: -6.2736 - val_loss: -6.5381\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.2772 - val_loss: -6.6023\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.2827 - val_loss: -6.7167\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: -6.2886 - val_loss: -6.8322\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.2936 - val_loss: -6.8994\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 67ms/step - loss: -6.2991 - val_loss: -6.9032\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3059 - val_loss: -6.8707\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -6.3130 - val_loss: -6.8484\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -6.3195 - val_loss: -6.8721\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.3264 - val_loss: -6.9512\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -6.3343 - val_loss: -7.0689\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.3424 - val_loss: -7.1916\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: -6.3504 - val_loss: -7.2875\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -6.3587 - val_loss: -7.3459\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -6.3680 - val_loss: -7.3814\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.3778 - val_loss: -7.4264\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -6.3620 - val_loss: -inf\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -6.4930 - val_loss: -inf\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -6.5857 - val_loss: -inf\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -6.6056 - val_loss: -inf\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -6.6466 - val_loss: -inf\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -6.7400 - val_loss: -inf\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -6.8394 - val_loss: -inf\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -6.8890 - val_loss: -inf\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -6.8909 - val_loss: -inf\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: -6.8926 - val_loss: -inf\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: -6.9111 - val_loss: -inf\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -6.9301 - val_loss: -inf\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -6.9453 - val_loss: -inf\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -6.9708 - val_loss: -inf\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -7.0127 - val_loss: -inf\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -7.0617 - val_loss: -inf\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -7.1061 - val_loss: -inf\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -7.1420 - val_loss: -inf\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -7.1711 - val_loss: -inf\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -7.1919 - val_loss: -inf\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -7.2021 - val_loss: -inf\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -7.2064 - val_loss: -inf\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -7.2135 - val_loss: -inf\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -7.2255 - val_loss: -inf\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: -7.2399 - val_loss: -inf\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -7.2542 - val_loss: -inf\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -7.2695 - val_loss: -inf\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -7.2869 - val_loss: -inf\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -7.3038 - val_loss: -inf\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -7.3169 - val_loss: -inf\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -7.3265 - val_loss: -inf\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -7.3348 - val_loss: -inf\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -7.3428 - val_loss: -inf\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -7.3505 - val_loss: -inf\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -7.3578 - val_loss: -inf\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -7.3653 - val_loss: -inf\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -7.3741 - val_loss: -inf\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -7.3836 - val_loss: -inf\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -7.3936 - val_loss: -inf\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -7.4031 - val_loss: -inf\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -7.4115 - val_loss: -inf\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -7.4192 - val_loss: -inf\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: -7.4268 - val_loss: -inf\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -7.4335 - val_loss: -inf\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -7.4395 - val_loss: -inf\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -7.4455 - val_loss: -inf\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -7.4521 - val_loss: -inf\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -7.4587 - val_loss: -inf\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -7.4651 - val_loss: -inf\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -7.4712 - val_loss: -inf\n",
            "Testing parameters:  {'activation': 'relu', 'dense_units': 64, 'epochs': 50, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: -5.6362 - val_loss: -21.7802\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -6.0528 - val_loss: -19.6768\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -6.4489 - val_loss: -17.7629\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -6.8449 - val_loss: -16.2007\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -7.2409 - val_loss: -15.3536\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -7.6474 - val_loss: -15.6436\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.1071 - val_loss: -17.0666\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.5595 - val_loss: -18.8467\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.8187 - val_loss: -17.9812\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.9769 - val_loss: -14.1309\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -9.2048 - val_loss: -10.6912\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -9.3888 - val_loss: -10.2477\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.6608 - val_loss: -11.5143\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -9.9594 - val_loss: -12.7890\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -10.0737 - val_loss: -12.2982\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -10.2484 - val_loss: -10.6958\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -10.6208 - val_loss: -9.4730\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -10.9487 - val_loss: -9.3063\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.2854 - val_loss: -9.8949\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -11.6872 - val_loss: -10.6955\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -12.0751 - val_loss: -11.3905\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -12.4308 - val_loss: -11.7239\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -12.7686 - val_loss: -11.5443\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -13.0725 - val_loss: -10.8744\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -13.2085 - val_loss: -10.3292\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -13.2277 - val_loss: -10.6780\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -13.5215 - val_loss: -11.4676\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.8984 - val_loss: -11.9573\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -14.1270 - val_loss: -11.7462\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -14.3433 - val_loss: -10.7159\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -14.6591 - val_loss: -9.5539\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -14.8397 - val_loss: -9.4958\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.0555 - val_loss: -10.3831\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.3696 - val_loss: -11.0723\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.4782 - val_loss: -10.8835\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -15.6634 - val_loss: -9.8987\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.8814 - val_loss: -8.9363\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -15.8703 - val_loss: -9.1695\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.0590 - val_loss: -10.0917\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.2683 - val_loss: -10.5198\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.3836 - val_loss: -10.1144\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.5570 - val_loss: -9.5251\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.6202 - val_loss: -9.6690\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.7489 - val_loss: -10.1470\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.8539 - val_loss: -10.0296\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.0621 - val_loss: -9.4857\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.3317 - val_loss: -9.4051\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.5064 - val_loss: -9.5387\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.5863 - val_loss: -9.2944\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.9515 - val_loss: -9.2297\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -15.2092 - val_loss: -9.7290\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.5538 - val_loss: -10.9275\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.0754 - val_loss: -11.2508\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -15.9083 - val_loss: -11.2331\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.2553 - val_loss: -10.6465\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.6606 - val_loss: -9.1108\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.8554 - val_loss: -7.5702\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.8489 - val_loss: -7.1426\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -16.7911 - val_loss: -7.5859\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.8292 - val_loss: -8.2286\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.8554 - val_loss: -8.7995\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -16.9964 - val_loss: -9.2126\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -17.0489 - val_loss: -9.2858\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.9520 - val_loss: -8.9769\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.0591 - val_loss: -8.6262\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -17.0678 - val_loss: -8.4342\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.1087 - val_loss: -8.3640\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.2682 - val_loss: -8.3610\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.2322 - val_loss: -8.2711\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.1718 - val_loss: -8.1060\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.2575 - val_loss: -8.0765\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.2712 - val_loss: -8.2711\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -17.2466 - val_loss: -8.5726\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.3081 - val_loss: -8.8427\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -17.3445 - val_loss: -8.9364\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.3131 - val_loss: -8.8221\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.3174 - val_loss: -8.6556\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.3488 - val_loss: -8.5734\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -17.3691 - val_loss: -8.5767\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.4015 - val_loss: -8.6058\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.4223 - val_loss: -8.5856\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.4099 - val_loss: -8.4734\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.4256 - val_loss: -8.3291\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.4572 - val_loss: -8.2576\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.4649 - val_loss: -8.3151\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.4809 - val_loss: -8.4980\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -17.5115 - val_loss: -8.7274\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.5165 - val_loss: -8.8547\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -17.5219 - val_loss: -8.8068\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.5455 - val_loss: -8.6538\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -17.5605 - val_loss: -8.4911\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.5850 - val_loss: -8.3830\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.5961 - val_loss: -8.3672\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.6035 - val_loss: -8.4367\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.6294 - val_loss: -8.5421\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -17.6419 - val_loss: -8.6264\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -17.6594 - val_loss: -8.6556\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -17.6824 - val_loss: -8.6334\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -17.6948 - val_loss: -8.6078\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -17.7136 - val_loss: -8.6218\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -12.3821 - val_loss: -7.3280\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -13.4562 - val_loss: -8.3150\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -14.2684 - val_loss: -8.7059\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.2978 - val_loss: -9.1298\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.4806 - val_loss: -9.7700\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -14.5203 - val_loss: -10.2402\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -14.5711 - val_loss: -10.6279\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -14.8004 - val_loss: -11.4217\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -14.8652 - val_loss: -13.1671\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -15.0251 - val_loss: -15.1784\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -15.0789 - val_loss: -16.4258\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -15.0819 - val_loss: -16.8950\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.2780 - val_loss: -16.8470\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.6030 - val_loss: -16.4341\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -15.6427 - val_loss: -15.6988\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.4503 - val_loss: -14.6960\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -15.7725 - val_loss: -13.7835\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -15.9006 - val_loss: -13.1817\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -15.7264 - val_loss: -12.9767\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -15.7290 - val_loss: -13.2368\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.8168 - val_loss: -14.2661\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -15.8904 - val_loss: -16.0650\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -16.0841 - val_loss: -17.8011\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.1194 - val_loss: -18.9504\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -16.0110 - val_loss: -19.5413\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -15.9886 - val_loss: -19.7047\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.0880 - val_loss: -19.5450\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.1564 - val_loss: -19.1499\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.1350 - val_loss: -18.6721\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.1202 - val_loss: -18.2914\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -16.1237 - val_loss: -18.1629\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -16.1226 - val_loss: -18.3335\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.1661 - val_loss: -18.8317\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.1910 - val_loss: -19.4243\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.1734 - val_loss: -19.9311\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.1854 - val_loss: -20.2430\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.2137 - val_loss: -20.3682\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -16.2244 - val_loss: -20.3474\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -16.2326 - val_loss: -20.1788\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.2375 - val_loss: -19.8620\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.2442 - val_loss: -19.4459\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.2786 - val_loss: -18.9241\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -16.3054 - val_loss: -18.4015\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -16.3101 - val_loss: -18.0164\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -16.3144 - val_loss: -17.8095\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.3286 - val_loss: -17.7770\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -16.3509 - val_loss: -17.7813\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.3722 - val_loss: -17.7871\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -16.3834 - val_loss: -17.7605\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -16.3909 - val_loss: -17.7389\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -18.4045 - val_loss: -12.9581\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -19.8373 - val_loss: -12.8471\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -19.8554 - val_loss: -12.3207\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -19.7114 - val_loss: -11.9093\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -20.0439 - val_loss: -11.5924\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -20.8600 - val_loss: -11.3246\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -19.2070 - val_loss: -11.7288\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.9532 - val_loss: -12.1226\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -20.5127 - val_loss: -12.1696\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -20.2624 - val_loss: -11.7919\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.4955 - val_loss: -11.0043\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -20.8693 - val_loss: -10.2662\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.7647 - val_loss: -10.3338\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.1403 - val_loss: -10.5781\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.3445 - val_loss: -10.7358\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.3176 - val_loss: -10.8741\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -21.2210 - val_loss: -11.0186\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.2564 - val_loss: -11.1228\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -21.4174 - val_loss: -11.0882\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -21.5092 - val_loss: -10.8649\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.5707 - val_loss: -10.5777\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -21.5872 - val_loss: -10.4752\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.6195 - val_loss: -10.5103\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -21.6235 - val_loss: -10.5623\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -21.6335 - val_loss: -10.6410\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -21.7166 - val_loss: -10.7699\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -21.6925 - val_loss: -10.9570\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -21.7508 - val_loss: -11.1580\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.8073 - val_loss: -11.2560\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -21.7512 - val_loss: -11.1899\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -21.7647 - val_loss: -11.0274\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -21.8542 - val_loss: -10.8845\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -21.8876 - val_loss: -10.8276\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -21.8493 - val_loss: -10.8618\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -21.8649 - val_loss: -10.9737\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.9162 - val_loss: -11.1391\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -21.9483 - val_loss: -11.2968\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -21.9607 - val_loss: -11.3858\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -21.9630 - val_loss: -11.4064\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -21.9815 - val_loss: -11.3839\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -22.0246 - val_loss: -11.3241\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -22.0521 - val_loss: -11.2530\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -22.0543 - val_loss: -11.2068\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -22.0771 - val_loss: -11.2027\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -22.1161 - val_loss: -11.2499\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -22.1329 - val_loss: -11.3650\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -22.1529 - val_loss: -11.5146\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -22.1879 - val_loss: -11.6135\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -22.2174 - val_loss: -11.6243\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -22.2523 - val_loss: -11.5793\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -17.4376 - val_loss: -18.4469\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -18.3238 - val_loss: -18.0200\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -20.3777 - val_loss: -15.4260\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -19.8633 - val_loss: -15.8426\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -21.0149 - val_loss: -18.7864\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -22.9273 - val_loss: -19.6151\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -22.6017 - val_loss: -18.7645\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -24.4227 - val_loss: -15.9987\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -24.4695 - val_loss: -15.1730\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -24.8089 - val_loss: -16.4556\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -26.0652 - val_loss: -18.5866\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -25.1124 - val_loss: -18.5276\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -25.8656 - val_loss: -16.4933\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -26.4864 - val_loss: -14.1457\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -26.0501 - val_loss: -13.0160\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -25.8956 - val_loss: -13.3409\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -26.5912 - val_loss: -14.6241\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -27.2780 - val_loss: -15.9004\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -27.0510 - val_loss: -16.3805\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -27.2493 - val_loss: -16.1876\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -27.8871 - val_loss: -15.9310\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -28.1846 - val_loss: -15.9999\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -28.5006 - val_loss: -16.1011\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -28.9095 - val_loss: -15.7003\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -29.3673 - val_loss: -14.8583\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -29.9436 - val_loss: -14.3856\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -30.5233 - val_loss: -14.7550\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -31.2186 - val_loss: -15.5812\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -31.8258 - val_loss: -16.0163\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -32.2355 - val_loss: -15.7620\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -32.6566 - val_loss: -15.3263\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -33.0066 - val_loss: -15.2041\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -33.3777 - val_loss: -15.2595\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -33.5610 - val_loss: -15.2612\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -33.8335 - val_loss: -15.6853\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -34.0506 - val_loss: -16.5272\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -33.9234 - val_loss: -17.3509\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -33.5507 - val_loss: -15.5614\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -34.1114 - val_loss: -15.7476\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -34.3016 - val_loss: -17.4404\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -33.8681 - val_loss: -16.7917\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -34.6769 - val_loss: -16.4728\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -34.5018 - val_loss: -17.2948\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -34.6522 - val_loss: -16.5336\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -35.0631 - val_loss: -15.8400\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -34.8453 - val_loss: -17.0628\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -35.0722 - val_loss: -16.8476\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -35.3401 - val_loss: -16.1062\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -35.2212 - val_loss: -16.5507\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -35.3419 - val_loss: -15.9849\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -25.0078 - val_loss: -10.2759\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -26.1547 - val_loss: -10.4530\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -26.4631 - val_loss: -10.3778\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -26.6990 - val_loss: -10.3088\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -26.5902 - val_loss: -10.4456\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -26.9597 - val_loss: -10.6735\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -27.6746 - val_loss: -10.7191\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -27.9807 - val_loss: -10.4929\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -28.6027 - val_loss: -10.1379\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -28.7622 - val_loss: -9.9374\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -29.7300 - val_loss: -9.7017\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -30.2758 - val_loss: -9.3537\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -30.6882 - val_loss: -9.5249\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -31.6190 - val_loss: -9.9862\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -32.2519 - val_loss: -10.1093\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -32.7538 - val_loss: -9.7697\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -33.6499 - val_loss: -9.5241\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -34.1644 - val_loss: -9.7951\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -34.5835 - val_loss: -9.8524\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -35.0091 - val_loss: -10.3995\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -35.3677 - val_loss: -10.2868\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -35.9384 - val_loss: -10.2182\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -36.0276 - val_loss: -10.5105\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -35.9921 - val_loss: -10.4671\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -35.6019 - val_loss: -10.8517\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -35.9738 - val_loss: -10.8516\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -36.6408 - val_loss: -11.0309\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -36.8296 - val_loss: -11.2402\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -36.7165 - val_loss: -11.2387\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -36.9702 - val_loss: -11.1930\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -37.5092 - val_loss: -11.1198\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -37.6805 - val_loss: -11.0824\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -37.7191 - val_loss: -11.1903\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -37.9629 - val_loss: -11.1565\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -38.3089 - val_loss: -11.0862\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -38.4017 - val_loss: -11.1688\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -38.4509 - val_loss: -11.2539\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -38.7380 - val_loss: -11.3756\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -38.9917 - val_loss: -11.4211\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -39.1154 - val_loss: -11.4242\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -39.1966 - val_loss: -11.4904\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -39.3973 - val_loss: -11.5334\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -39.6465 - val_loss: -11.5301\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -39.7847 - val_loss: -11.5012\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -39.8237 - val_loss: -11.4887\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -39.8735 - val_loss: -11.5305\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -39.9855 - val_loss: -11.5504\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -40.1570 - val_loss: -11.5504\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -40.3251 - val_loss: -11.5601\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -40.5101 - val_loss: -11.5546\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -20.5411 - val_loss: -10.5317\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -21.6869 - val_loss: -10.7899\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -22.9565 - val_loss: -10.7744\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -23.8671 - val_loss: -10.5532\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -24.4574 - val_loss: -10.4210\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -24.8782 - val_loss: -10.5387\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -25.3095 - val_loss: -10.7064\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -25.5561 - val_loss: -10.6911\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -25.8350 - val_loss: -10.5054\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -25.9398 - val_loss: -10.5678\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -26.1329 - val_loss: -10.6628\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -26.1953 - val_loss: -10.5721\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -26.3462 - val_loss: -10.4078\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -26.3761 - val_loss: -10.4556\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -26.5331 - val_loss: -10.4400\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -26.6626 - val_loss: -10.3577\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -26.8523 - val_loss: -10.4477\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -27.2680 - val_loss: -10.5717\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -27.9870 - val_loss: -10.8037\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -29.6385 - val_loss: -11.2841\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -29.1983 - val_loss: -11.1171\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -31.6547 - val_loss: -11.2554\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -33.3476 - val_loss: -11.5391\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -34.0801 - val_loss: -11.3219\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -36.4638 - val_loss: -11.3079\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -37.9626 - val_loss: -11.2277\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -39.6096 - val_loss: -11.0881\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -41.1264 - val_loss: -10.9036\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -39.3045 - val_loss: -11.5370\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -41.4688 - val_loss: -11.0750\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -45.7332 - val_loss: -10.3438\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -36.4186 - val_loss: -10.7244\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -45.0556 - val_loss: -11.5437\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -35.3813 - val_loss: -11.3996\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -39.3565 - val_loss: -10.4825\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -42.1582 - val_loss: -10.5539\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -42.5667 - val_loss: -11.0090\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -46.8682 - val_loss: -11.0069\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -46.2457 - val_loss: -10.7513\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -45.2268 - val_loss: -10.7226\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -50.7454 - val_loss: -10.9987\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -45.7159 - val_loss: -10.8385\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -51.6913 - val_loss: -10.5919\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -47.7073 - val_loss: -10.8914\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -49.9892 - val_loss: -11.0672\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -50.8517 - val_loss: -10.8129\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -51.6329 - val_loss: -10.6931\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -50.5135 - val_loss: -10.8540\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: -54.8185 - val_loss: -10.9655\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -51.6618 - val_loss: -10.8997\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -20.8771 - val_loss: -10.9774\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -20.8652 - val_loss: -11.2217\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -20.8315 - val_loss: -11.3405\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -20.9247 - val_loss: -11.3123\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -21.2407 - val_loss: -11.1461\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -21.8090 - val_loss: -10.8780\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -22.5953 - val_loss: -10.5663\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -23.5093 - val_loss: -10.2811\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -24.4374 - val_loss: -10.0728\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -25.3088 - val_loss: -9.9659\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -26.1497 - val_loss: -9.9565\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -27.1316 - val_loss: -10.0260\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -28.4746 - val_loss: -10.1594\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -30.3857 - val_loss: -10.3448\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -32.8776 - val_loss: -10.5416\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -35.4095 - val_loss: -10.6420\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -37.6295 - val_loss: -10.5693\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -40.5394 - val_loss: -10.3650\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -44.9470 - val_loss: -10.2540\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -48.2227 - val_loss: -10.3361\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -53.2233 - val_loss: -10.5339\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -56.1163 - val_loss: -10.3834\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -61.2769 - val_loss: -10.5736\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -63.9233 - val_loss: -10.5572\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -59.5199 - val_loss: -11.1185\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -51.7638 - val_loss: -10.7854\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -69.3259 - val_loss: -10.3048\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -70.5215 - val_loss: -12.7486\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -34.8811 - val_loss: -13.2160\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -28.0700 - val_loss: -13.0340\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -27.6602 - val_loss: -12.5858\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -28.9858 - val_loss: -12.0388\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -31.8436 - val_loss: -11.4102\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -37.2346 - val_loss: -10.4107\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -45.0155 - val_loss: -9.3404\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -45.1299 - val_loss: -9.5475\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -56.5594 - val_loss: -11.2398\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -52.7112 - val_loss: -11.1541\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -51.0157 - val_loss: -10.1443\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -71.5430 - val_loss: -9.0414\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -53.8482 - val_loss: -9.1682\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -49.8217 - val_loss: -9.9449\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -62.0916 - val_loss: -10.2264\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -71.4321 - val_loss: -9.5559\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -61.5446 - val_loss: -9.0755\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -66.6255 - val_loss: -9.2325\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -78.4869 - val_loss: -9.8418\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -67.8974 - val_loss: -9.6554\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -79.4574 - val_loss: -8.9489\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -74.3835 - val_loss: -8.9449\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -17.2179 - val_loss: -10.6617\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -17.6296 - val_loss: -10.7059\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.3148 - val_loss: -10.7588\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -19.2467 - val_loss: -10.8120\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -20.3594 - val_loss: -10.8598\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -21.4979 - val_loss: -10.8971\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -22.6413 - val_loss: -10.9158\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -23.8243 - val_loss: -10.9185\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -25.1288 - val_loss: -10.9088\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -26.5890 - val_loss: -10.8893\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -28.1725 - val_loss: -10.8719\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -29.8471 - val_loss: -10.8739\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -31.8056 - val_loss: -10.8983\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -34.3887 - val_loss: -10.9499\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -37.6653 - val_loss: -11.0329\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -41.3634 - val_loss: -11.1197\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -44.5316 - val_loss: -11.1851\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -45.9144 - val_loss: -11.2249\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -46.5125 - val_loss: -11.2425\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -48.7793 - val_loss: -11.2386\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -52.8833 - val_loss: -11.2095\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -55.7320 - val_loss: -11.1564\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -57.8893 - val_loss: -11.1136\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -61.2374 - val_loss: -11.1677\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -61.4952 - val_loss: -11.2100\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -63.8019 - val_loss: -11.1537\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -66.3813 - val_loss: -10.9694\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -68.6175 - val_loss: -10.6759\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -72.5768 - val_loss: -10.4478\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -75.0813 - val_loss: -10.4930\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -81.4180 - val_loss: -10.5683\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -80.7169 - val_loss: -10.3322\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -80.6031 - val_loss: -10.3337\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -86.0524 - val_loss: -10.2430\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -87.6265 - val_loss: -10.0094\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -85.7705 - val_loss: -10.1425\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -84.6977 - val_loss: -9.9802\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -86.1424 - val_loss: -9.9362\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -90.6175 - val_loss: -9.7646\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -94.6432 - val_loss: -9.7974\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -93.2457 - val_loss: -9.4451\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -90.4052 - val_loss: -9.9007\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -83.2207 - val_loss: -9.5597\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -95.6575 - val_loss: -9.4264\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -96.4560 - val_loss: -9.7216\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -95.3077 - val_loss: -9.4105\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -94.1963 - val_loss: -9.6917\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -89.2036 - val_loss: -9.4246\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -95.6502 - val_loss: -9.3456\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -99.3125 - val_loss: -9.5557\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -17.9655 - val_loss: -21.3877\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -18.6359 - val_loss: -21.0377\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -19.3905 - val_loss: -20.5096\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -20.1702 - val_loss: -19.8500\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -20.8904 - val_loss: -19.1360\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -21.4704 - val_loss: -18.4437\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -21.8756 - val_loss: -17.8213\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -22.1316 - val_loss: -17.2875\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -22.3024 - val_loss: -16.8409\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -22.4398 - val_loss: -16.4908\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -22.5741 - val_loss: -16.2320\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -22.6888 - val_loss: -16.0140\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -22.8452 - val_loss: -15.8276\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -23.0307 - val_loss: -15.7345\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -23.2418 - val_loss: -15.7243\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -23.4936 - val_loss: -15.7357\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -23.7560 - val_loss: -15.7608\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -23.9696 - val_loss: -15.7944\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -24.1803 - val_loss: -15.8394\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -24.4108 - val_loss: -15.8972\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -24.6619 - val_loss: -15.9687\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -24.9362 - val_loss: -16.0532\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -25.2304 - val_loss: -16.1485\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -25.5423 - val_loss: -16.2531\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -25.8460 - val_loss: -16.3839\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -26.1335 - val_loss: -16.5034\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -26.4219 - val_loss: -16.6039\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -26.7068 - val_loss: -16.6791\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -26.9847 - val_loss: -16.7230\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -27.2540 - val_loss: -16.7313\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -27.5152 - val_loss: -16.7019\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -27.7713 - val_loss: -16.6349\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -28.0269 - val_loss: -16.5332\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -28.2880 - val_loss: -16.4012\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -28.5596 - val_loss: -16.2582\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -28.8440 - val_loss: -16.1120\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -29.1005 - val_loss: -15.9610\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -29.3643 - val_loss: -15.8117\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -29.6382 - val_loss: -15.6698\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -29.9147 - val_loss: -15.5405\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -30.1861 - val_loss: -15.4284\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -30.4465 - val_loss: -15.3360\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -30.6995 - val_loss: -15.2660\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -30.9558 - val_loss: -15.2172\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -31.2052 - val_loss: -15.1980\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -31.4722 - val_loss: -15.2024\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -31.7519 - val_loss: -15.2200\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -32.0165 - val_loss: -15.2510\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -32.3019 - val_loss: -15.2749\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -32.5922 - val_loss: -15.2851\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -22.1268 - val_loss: -16.4951\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -22.4907 - val_loss: -16.4840\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -22.8771 - val_loss: -16.4927\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -23.3025 - val_loss: -16.5272\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -23.8453 - val_loss: -16.5775\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -24.5317 - val_loss: -16.6297\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -25.3182 - val_loss: -16.6726\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -26.1231 - val_loss: -16.7005\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -26.8802 - val_loss: -16.7122\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -27.6014 - val_loss: -16.7098\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -28.2264 - val_loss: -16.6926\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -28.6995 - val_loss: -16.6619\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -29.1079 - val_loss: -16.6172\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -29.5734 - val_loss: -16.5561\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -30.1521 - val_loss: -16.4723\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -30.8373 - val_loss: -16.3604\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -31.5303 - val_loss: -16.2231\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -32.0342 - val_loss: -16.0845\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -32.2367 - val_loss: -15.9886\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -32.3248 - val_loss: -15.9677\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 71ms/step - loss: -32.5624 - val_loss: -16.0144\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -32.9534 - val_loss: -16.0888\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -33.4720 - val_loss: -16.1556\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -34.0542 - val_loss: -16.1943\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -34.5521 - val_loss: -16.2048\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -34.8667 - val_loss: -16.1949\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -35.1747 - val_loss: -16.1477\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -35.4697 - val_loss: -16.0953\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -35.6259 - val_loss: -16.0407\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -35.7842 - val_loss: -15.9809\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -36.1348 - val_loss: -15.9103\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -36.5070 - val_loss: -15.8526\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -36.7718 - val_loss: -15.8017\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -37.2572 - val_loss: -15.7250\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -37.4743 - val_loss: -15.6431\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -37.7272 - val_loss: -15.5740\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -38.0028 - val_loss: -15.4804\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -38.1460 - val_loss: -15.3518\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -38.3850 - val_loss: -15.2571\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: -38.4449 - val_loss: -15.2715\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -38.7092 - val_loss: -15.3349\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -38.9655 - val_loss: -15.3793\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -39.2079 - val_loss: -15.3880\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -39.3854 - val_loss: -15.3829\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -39.5809 - val_loss: -15.3707\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -39.8064 - val_loss: -15.3390\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -39.9095 - val_loss: -15.3013\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -40.0557 - val_loss: -15.3068\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -40.1710 - val_loss: -15.3575\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -40.2973 - val_loss: -15.3907\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -17.3987 - val_loss: -16.6302\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -17.4723 - val_loss: -16.6760\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.6280 - val_loss: -16.7751\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -17.8627 - val_loss: -16.9271\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -18.1834 - val_loss: -17.1291\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -18.6012 - val_loss: -17.3674\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -19.1227 - val_loss: -17.5977\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -19.7252 - val_loss: -17.7100\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -20.3370 - val_loss: -17.5599\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -20.8797 - val_loss: -17.1250\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -21.4167 - val_loss: -16.5467\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -22.0389 - val_loss: -15.9310\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -22.6442 - val_loss: -15.2707\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -23.0534 - val_loss: -14.5067\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -23.2409 - val_loss: -13.6290\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -23.3148 - val_loss: -12.7347\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -23.3498 - val_loss: -11.9907\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -23.3667 - val_loss: -11.5361\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -23.4078 - val_loss: -11.4268\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -23.5328 - val_loss: -11.6483\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -23.7561 - val_loss: -12.1318\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -24.0274 - val_loss: -12.7607\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -24.2691 - val_loss: -13.3899\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -24.4544 - val_loss: -13.8658\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -24.5872 - val_loss: -14.0906\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -24.7252 - val_loss: -14.0641\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -24.8687 - val_loss: -13.8764\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -25.0273 - val_loss: -13.6114\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -25.2008 - val_loss: -13.3308\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -25.4146 - val_loss: -13.0477\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -25.6365 - val_loss: -12.7525\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -25.8163 - val_loss: -12.4238\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -25.9490 - val_loss: -12.0498\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -26.0696 - val_loss: -11.6408\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -26.2143 - val_loss: -11.2075\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -26.4064 - val_loss: -10.7688\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -26.6294 - val_loss: -10.3413\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -26.8640 - val_loss: -9.9389\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -27.1068 - val_loss: -9.5644\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -27.3627 - val_loss: -9.3072\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -27.6286 - val_loss: -9.0816\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -27.8912 - val_loss: -8.8614\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -28.1486 - val_loss: -8.6475\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -28.4080 - val_loss: -8.4400\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -28.6867 - val_loss: -8.2543\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -28.9817 - val_loss: -8.0925\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -29.2865 - val_loss: -7.9476\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -29.5914 - val_loss: -7.8107\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -29.9118 - val_loss: -7.6846\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -30.2391 - val_loss: -7.5756\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -11.6165 - val_loss: -10.0589\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.6278 - val_loss: -10.1466\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.8131 - val_loss: -10.2608\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -12.1700 - val_loss: -10.4080\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.7154 - val_loss: -10.5883\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -13.4710 - val_loss: -10.7704\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -14.3557 - val_loss: -10.8692\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.2914 - val_loss: -10.7792\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -16.1333 - val_loss: -10.4902\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -16.8187 - val_loss: -10.0941\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -17.5355 - val_loss: -9.6705\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -18.1414 - val_loss: -9.2743\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -18.6389 - val_loss: -8.8848\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -19.0638 - val_loss: -8.5124\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -19.3279 - val_loss: -8.2056\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -19.3847 - val_loss: -7.9731\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -19.2877 - val_loss: -7.8095\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -19.1866 - val_loss: -7.7046\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -19.1581 - val_loss: -7.6454\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -19.2191 - val_loss: -7.6266\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -19.3528 - val_loss: -7.6364\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -19.5378 - val_loss: -7.6652\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -19.7456 - val_loss: -7.7037\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -19.9329 - val_loss: -7.7425\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -20.0813 - val_loss: -7.7740\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -20.1947 - val_loss: -7.7911\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -20.2892 - val_loss: -7.7940\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -20.3856 - val_loss: -7.7824\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -20.4969 - val_loss: -7.7621\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -20.6267 - val_loss: -7.7378\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -20.7725 - val_loss: -7.7103\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -20.9296 - val_loss: -7.6838\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -21.0917 - val_loss: -7.6630\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -21.2560 - val_loss: -7.6531\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -21.4196 - val_loss: -7.6581\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -21.5805 - val_loss: -7.6813\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.7349 - val_loss: -7.7246\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -21.8810 - val_loss: -7.7900\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -22.0061 - val_loss: -7.8730\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -22.0987 - val_loss: -7.9622\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -22.1472 - val_loss: -8.0429\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -22.1697 - val_loss: -8.0942\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -22.1946 - val_loss: -8.1022\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -22.2580 - val_loss: -8.0672\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -22.3589 - val_loss: -8.0021\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -22.4822 - val_loss: -7.9266\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -22.6015 - val_loss: -7.8571\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -22.6928 - val_loss: -7.8034\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -22.7660 - val_loss: -7.7704\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -22.8416 - val_loss: -7.7587\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -13.2589 - val_loss: -5.8550\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -13.2998 - val_loss: -5.8537\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -13.3952 - val_loss: -5.8407\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -13.5407 - val_loss: -5.8154\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -13.7314 - val_loss: -5.7768\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -13.9593 - val_loss: -5.7229\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -14.2099 - val_loss: -5.6528\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -14.4542 - val_loss: -5.5677\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -14.6456 - val_loss: -5.4746\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -14.7354 - val_loss: -5.3890\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -14.7232 - val_loss: -5.3316\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -14.6920 - val_loss: -5.3186\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -14.7486 - val_loss: -5.3522\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -14.9273 - val_loss: -5.4213\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -15.1707 - val_loss: -5.5082\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -15.3942 - val_loss: -5.5946\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -15.5464 - val_loss: -5.6670\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -15.6372 - val_loss: -5.7160\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -15.7053 - val_loss: -5.7412\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -15.7873 - val_loss: -5.7404\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -15.9048 - val_loss: -5.7064\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -16.0658 - val_loss: -5.6513\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -16.2334 - val_loss: -5.5709\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -16.3760 - val_loss: -5.4721\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -16.4547 - val_loss: -5.3874\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -16.4839 - val_loss: -5.3438\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -16.5449 - val_loss: -5.3496\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -16.6891 - val_loss: -5.3851\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -16.9021 - val_loss: -5.4397\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -17.1201 - val_loss: -5.4895\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -17.3154 - val_loss: -5.5112\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.5076 - val_loss: -5.5095\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -17.7151 - val_loss: -5.4837\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -17.8924 - val_loss: -5.4369\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -17.9729 - val_loss: -5.3734\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -18.0329 - val_loss: -5.3126\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -18.1631 - val_loss: -5.2603\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -18.2945 - val_loss: -5.2375\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.4195 - val_loss: -5.2477\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -18.5871 - val_loss: -5.2769\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -18.7815 - val_loss: -5.3056\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -18.9059 - val_loss: -5.3240\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -18.9830 - val_loss: -5.3116\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -19.0973 - val_loss: -5.2637\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.2474 - val_loss: -5.1884\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -19.4003 - val_loss: -5.1045\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -19.5164 - val_loss: -5.0361\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -19.6058 - val_loss: -5.0024\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -19.7134 - val_loss: -5.0044\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -19.8472 - val_loss: -5.0225\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -9.0882 - val_loss: -14.3004\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.2276 - val_loss: -14.8559\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -9.4210 - val_loss: -15.5612\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -9.6174 - val_loss: -16.3447\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -9.7796 - val_loss: -17.1526\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -9.9039 - val_loss: -17.9775\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -10.0264 - val_loss: -18.8081\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -10.1386 - val_loss: -19.6253\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -10.2176 - val_loss: -20.3878\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -10.2746 - val_loss: -21.0770\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -10.3218 - val_loss: -21.7236\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -10.3652 - val_loss: -22.2953\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -10.3764 - val_loss: -22.7540\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -10.3795 - val_loss: -23.1449\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -10.3898 - val_loss: -23.4684\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -10.3957 - val_loss: -23.7226\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -10.3997 - val_loss: -23.9149\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -10.4035 - val_loss: -24.0502\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -10.4081 - val_loss: -24.1346\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -10.4149 - val_loss: -24.1730\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -10.4242 - val_loss: -24.1711\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -10.4356 - val_loss: -24.1338\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -10.4490 - val_loss: -24.0642\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -10.4638 - val_loss: -23.9663\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -10.4791 - val_loss: -23.8436\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -10.4946 - val_loss: -23.7001\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -10.5097 - val_loss: -23.5405\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -10.5236 - val_loss: -23.3696\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -10.5365 - val_loss: -23.1911\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -10.5488 - val_loss: -23.0097\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -10.5605 - val_loss: -22.8280\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -10.5717 - val_loss: -22.6490\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -10.5826 - val_loss: -22.4756\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -10.5935 - val_loss: -22.3112\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -10.6044 - val_loss: -22.1581\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -10.6155 - val_loss: -22.0163\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -10.6267 - val_loss: -21.8889\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -10.6381 - val_loss: -21.7728\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -10.6496 - val_loss: -21.6674\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -10.6609 - val_loss: -21.5726\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -10.6719 - val_loss: -21.4848\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -10.6824 - val_loss: -21.4022\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -10.6924 - val_loss: -21.3236\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -10.7017 - val_loss: -21.2460\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -10.7105 - val_loss: -21.1654\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -10.7189 - val_loss: -21.0825\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -10.7270 - val_loss: -20.9957\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -10.7348 - val_loss: -20.9054\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -10.7425 - val_loss: -20.8111\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -10.7502 - val_loss: -20.7132\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -10.8189 - val_loss: -2.2425\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -10.8273 - val_loss: -2.2423\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -10.8426 - val_loss: -2.2436\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -10.8630 - val_loss: -2.2462\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -10.8862 - val_loss: -2.2500\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -10.9110 - val_loss: -2.2549\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -10.9364 - val_loss: -2.2609\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -10.9619 - val_loss: -2.2678\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -10.9874 - val_loss: -2.2756\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -11.0129 - val_loss: -2.2842\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -11.0382 - val_loss: -2.2935\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -11.0631 - val_loss: -2.3033\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.0869 - val_loss: -2.3136\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -11.1086 - val_loss: -2.3240\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -11.1275 - val_loss: -2.3342\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -11.1423 - val_loss: -2.3440\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -11.1529 - val_loss: -2.3529\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -11.1593 - val_loss: -2.3606\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -11.1621 - val_loss: -2.3666\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -11.1626 - val_loss: -2.3706\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -11.1621 - val_loss: -2.3725\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -11.1624 - val_loss: -2.3721\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -11.1644 - val_loss: -2.3696\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.1688 - val_loss: -2.3650\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -11.1755 - val_loss: -2.3588\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -11.1839 - val_loss: -2.3514\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.1929 - val_loss: -2.3431\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: -11.2016 - val_loss: -2.3343\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -11.2093 - val_loss: -2.3255\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -11.2156 - val_loss: -2.3169\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -11.2207 - val_loss: -2.3087\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -11.2248 - val_loss: -2.3011\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.2281 - val_loss: -2.2942\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.2311 - val_loss: -2.2881\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -11.2339 - val_loss: -2.2827\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -11.2369 - val_loss: -2.2781\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -11.2401 - val_loss: -2.2742\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -11.2434 - val_loss: -2.2709\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -11.2468 - val_loss: -2.2683\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -11.2502 - val_loss: -2.2662\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -11.2536 - val_loss: -2.2645\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: -11.2569 - val_loss: -2.2632\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -11.2601 - val_loss: -2.2622\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: -11.2632 - val_loss: -2.2614\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -11.2661 - val_loss: -2.2607\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.2689 - val_loss: -2.2601\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: -11.2716 - val_loss: -2.2595\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -11.2742 - val_loss: -2.2588\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -11.2767 - val_loss: -2.2579\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: -11.2791 - val_loss: -2.2569\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -4.4381 - val_loss: -5.9453\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -4.4457 - val_loss: -5.9338\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -4.4615 - val_loss: -5.9163\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: -4.4851 - val_loss: -5.8934\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -4.5170 - val_loss: -5.8656\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -4.5576 - val_loss: -5.8334\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -4.6079 - val_loss: -5.7972\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -4.6689 - val_loss: -5.7575\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -4.7419 - val_loss: -5.7148\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -4.8280 - val_loss: -5.6698\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -4.9281 - val_loss: -5.6232\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -5.0420 - val_loss: -5.5756\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -5.1679 - val_loss: -5.5281\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -5.3014 - val_loss: -5.4817\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -5.4353 - val_loss: -5.4377\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -5.5609 - val_loss: -5.3975\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -5.6701 - val_loss: -5.3626\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -5.7593 - val_loss: -5.3345\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -5.8309 - val_loss: -5.3147\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -5.8925 - val_loss: -5.3043\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -5.9543 - val_loss: -5.3042\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -6.0268 - val_loss: -5.3154\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -6.1203 - val_loss: -5.3391\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -6.2454 - val_loss: -5.3770\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -6.4160 - val_loss: -5.4312\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -6.6534 - val_loss: -5.5036\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -6.9933 - val_loss: -5.5932\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -7.4897 - val_loss: -5.6865\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 95ms/step - loss: -8.1771 - val_loss: -5.7399\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -8.8725 - val_loss: -5.7001\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -9.0698 - val_loss: -5.6329\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -8.8881 - val_loss: -5.6461\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -8.8412 - val_loss: -5.7543\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -9.0140 - val_loss: -5.9116\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -9.3429 - val_loss: -6.0307\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -9.7116 - val_loss: -6.0538\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -9.9319 - val_loss: -6.0059\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -9.8758 - val_loss: -5.9578\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -9.7104 - val_loss: -5.9474\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -9.6713 - val_loss: -5.9759\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -9.8027 - val_loss: -6.0296\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -10.0083 - val_loss: -6.0883\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.1575 - val_loss: -6.1326\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -10.1936 - val_loss: -6.1556\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -10.1763 - val_loss: -6.1631\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -10.1778 - val_loss: -6.1646\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -10.1913 - val_loss: -6.1652\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -10.1684 - val_loss: -6.1632\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -10.1624 - val_loss: -6.1606\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -10.1966 - val_loss: -6.1617\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -8.3169 - val_loss: -11.3214\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -8.3217 - val_loss: -11.4238\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: -8.3334 - val_loss: -11.5984\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -8.3545 - val_loss: -11.8111\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.3785 - val_loss: -12.0255\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -8.3964 - val_loss: -12.2090\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -8.4054 - val_loss: -12.3376\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -8.4124 - val_loss: -12.4014\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.4271 - val_loss: -12.4051\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -8.4514 - val_loss: -12.3646\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.4792 - val_loss: -12.2969\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: -8.5049 - val_loss: -12.2225\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -8.5278 - val_loss: -12.1565\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -8.5512 - val_loss: -12.1097\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -8.5778 - val_loss: -12.0864\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.6067 - val_loss: -12.0840\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -8.6352 - val_loss: -12.0924\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.6616 - val_loss: -12.0980\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.6876 - val_loss: -12.0897\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -8.7164 - val_loss: -12.0653\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -8.7489 - val_loss: -12.0306\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -8.7827 - val_loss: -11.9941\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -8.8156 - val_loss: -11.9633\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -8.8478 - val_loss: -11.9420\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -8.8811 - val_loss: -11.9276\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -8.9163 - val_loss: -11.9158\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: -8.9533 - val_loss: -11.8999\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -8.9912 - val_loss: -11.8732\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: -9.0299 - val_loss: -11.8295\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: -9.0700 - val_loss: -11.7659\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: -9.1122 - val_loss: -11.6839\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.1564 - val_loss: -11.5906\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -9.2010 - val_loss: -11.4956\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: -9.2449 - val_loss: -11.4079\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: -9.2878 - val_loss: -11.3374\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -9.3295 - val_loss: -11.2862\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -9.3696 - val_loss: -11.2531\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -9.4069 - val_loss: -11.2358\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: -9.4404 - val_loss: -11.2274\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.4704 - val_loss: -11.2200\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -9.4977 - val_loss: -11.2134\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -9.5223 - val_loss: -11.2102\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -9.5437 - val_loss: -11.2126\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -9.5619 - val_loss: -11.2202\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: -9.5776 - val_loss: -11.2307\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -9.5914 - val_loss: -11.2400\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -9.6036 - val_loss: -11.2439\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: -9.6149 - val_loss: -11.2391\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -9.6256 - val_loss: -11.2245\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: -9.6364 - val_loss: -11.2009\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -11.2889 - val_loss: -inf\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 96ms/step - loss: -11.3894 - val_loss: -inf\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: -11.5466 - val_loss: -inf\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.7410 - val_loss: -inf\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.9538 - val_loss: -inf\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.1662 - val_loss: -inf\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.3541 - val_loss: -inf\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 93ms/step - loss: -12.4920 - val_loss: -inf\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -12.5679 - val_loss: -inf\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -12.5927 - val_loss: -inf\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -12.5896 - val_loss: -inf\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -12.5850 - val_loss: -inf\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -12.6052 - val_loss: -inf\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -12.6639 - val_loss: -inf\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -12.7535 - val_loss: -inf\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: -12.8551 - val_loss: -inf\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 101ms/step - loss: -12.9495 - val_loss: -inf\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -13.0272 - val_loss: -inf\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -13.0860 - val_loss: -inf\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.1342 - val_loss: -inf\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 94ms/step - loss: -13.1816 - val_loss: -inf\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -13.2376 - val_loss: -inf\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -13.3099 - val_loss: -inf\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.4024 - val_loss: -inf\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -13.5147 - val_loss: -inf\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: -13.6452 - val_loss: -inf\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 99ms/step - loss: -13.8126 - val_loss: -inf\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -14.0156 - val_loss: -inf\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -14.2399 - val_loss: -inf\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.4791 - val_loss: -inf\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -14.7498 - val_loss: -inf\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -15.0852 - val_loss: -inf\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.4787 - val_loss: -inf\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -15.9019 - val_loss: -inf\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -16.4016 - val_loss: -inf\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -16.9193 - val_loss: -inf\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -17.4153 - val_loss: -inf\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -17.8985 - val_loss: -inf\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -18.3320 - val_loss: -inf\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -18.8028 - val_loss: -inf\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 100ms/step - loss: -19.2580 - val_loss: -inf\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: -19.7339 - val_loss: -inf\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: -20.1862 - val_loss: -inf\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -20.5691 - val_loss: -inf\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -20.9282 - val_loss: -inf\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -21.2774 - val_loss: -inf\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: -21.6506 - val_loss: -inf\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -22.0886 - val_loss: -inf\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -22.5895 - val_loss: -inf\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -23.0899 - val_loss: -inf\n"
          ]
        }
      ],
      "source": [
        "best_score = np.inf\n",
        "best_params = None\n",
        "\n",
        "for params in ParameterGrid(cnn_param_grid):\n",
        "  print(\"Testing parameters: \", params)\n",
        "\n",
        "  cnn = create_CNN_model(negative_sharpe_loss,\n",
        "                         asset_num,\n",
        "                         X_train_cnn_reshaped.shape[1:],\n",
        "                         params)\n",
        "\n",
        "  preds, avg_score = walk_forward(n_train=n_train,\n",
        "                                      n_val=n_val,\n",
        "                                      df=df_trainval,\n",
        "                                      epochs=params['epochs'],\n",
        "                                      batch=batch,\n",
        "                                      model=cnn,\n",
        "                                      asset_num=len(x_tickers),\n",
        "                                      best_params=best_params,\n",
        "                                      best_score=best_score,\n",
        "                                      hpo=True)\n",
        "\n",
        "  if avg_score < best_score:\n",
        "    best_score = avg_score\n",
        "    best_params = params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaFdXQBGp2uU",
        "outputId": "cc9d220d-b474-4232-894f-a886f02e51ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'dense_units': 64,\n",
              " 'epochs': 50,\n",
              " 'filters': 32,\n",
              " 'kernel_size': 3,\n",
              " 'learning_rate': 0.001,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0aCMjFep2o9",
        "outputId": "44a26952-7977-4244-af2a-bb3791d856a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 1s 17ms/step - loss: -6.4504\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -7.5323\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 16ms/step - loss: -8.6761\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -9.0171\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -9.6694\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -9.3792\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -10.0049\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -10.5559\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -10.4819\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -10.6506\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -10.7278\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -11.9086\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -11.7624\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -12.2022\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.1577\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.3001\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -12.3608\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.2668\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.4039\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.3646\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -13.0077\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -13.5455\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.4958\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -12.9853\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -13.4457\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -13.5219\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -14.0269\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: -14.1024\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -13.7738\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -14.6589\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -14.4177\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -14.8028\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -14.3672\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -14.7150\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -15.0074\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -15.4687\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -15.6769\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -15.1839\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: -16.2455\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -16.1286\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -16.0571\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: -15.9128\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 19ms/step - loss: -16.5332\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -17.0179\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -16.3346\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -16.8348\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -16.7619\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 18ms/step - loss: -17.4413\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -17.6994\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 17ms/step - loss: -18.8589\n"
          ]
        }
      ],
      "source": [
        "# train with best params\n",
        "cnn = create_CNN_model(negative_sharpe_loss,\n",
        "                        asset_num,\n",
        "                        X_train_cnn_reshaped.shape[1:],\n",
        "                        best_params)\n",
        "\n",
        "cnn_history = cnn.fit(\n",
        "                      df_trainval.iloc[:, :-asset_num],\n",
        "                      df_trainval.iloc[:, -asset_num:],\n",
        "                      epochs=best_params['epochs'],\n",
        "                      batch_size=batch,\n",
        "                      verbose=1\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRdIq-qcp2iE",
        "outputId": "012c06db-6dea-4132-9ef9-3900d9f1a343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 106ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_test_cnn = cnn.predict(df_test.iloc[:, :-asset_num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "qvF-1cugqXZp",
        "outputId": "fda96637-4206-465e-ff52-003f71ec4a01"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cnn_wts"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7d2704eb-1925-4fff-b987-62c85f449a7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-07-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d2704eb-1925-4fff-b987-62c85f449a7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d2704eb-1925-4fff-b987-62c85f449a7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d2704eb-1925-4fff-b987-62c85f449a7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a9efa54-44fe-4c89-889d-a33acedaf9ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a9efa54-44fe-4c89-889d-a33acedaf9ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a9efa54-44fe-4c89-889d-a33acedaf9ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a0412652-79e4-4d7e-84c6-11fc941ce855\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cnn_wts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a0412652-79e4-4d7e-84c6-11fc941ce855 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cnn_wts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker      ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  \\\n",
              "Date                                                          ...             \n",
              "2021-07-31 0.00 0.00 0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-08-31 0.00 0.00 0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-09-30 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-10-31 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-11-30 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-12-31 0.00 0.00 0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-01-31 0.00 0.00 0.00 0.00 0.03 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-02-28 0.00 0.00 0.00 0.00 0.03 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-03-31 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-04-30 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-05-31 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-06-30 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-07-31 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-08-31 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-09-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-10-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-11-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-12-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-01-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-02-28 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-03-31 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-04-30 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-05-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-06-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "\n",
              "Ticker      SPGI  SWK  SYY  TGT  TROW  WMT  WST  XOM  \n",
              "Date                                                  \n",
              "2021-07-31  0.00 0.00 0.00 0.10  0.00 0.00 0.02 0.13  \n",
              "2021-08-31  0.00 0.00 0.00 0.10  0.00 0.00 0.01 0.13  \n",
              "2021-09-30  0.00 0.00 0.00 0.12  0.00 0.00 0.02 0.08  \n",
              "2021-10-31  0.00 0.00 0.00 0.11  0.00 0.00 0.01 0.07  \n",
              "2021-11-30  0.00 0.00 0.00 0.11  0.00 0.00 0.01 0.06  \n",
              "2021-12-31  0.00 0.00 0.00 0.08  0.00 0.00 0.01 0.07  \n",
              "2022-01-31  0.00 0.00 0.00 0.09  0.00 0.00 0.01 0.04  \n",
              "2022-02-28  0.00 0.00 0.00 0.10  0.00 0.00 0.00 0.03  \n",
              "2022-03-31  0.00 0.00 0.00 0.13  0.00 0.00 0.00 0.01  \n",
              "2022-04-30  0.00 0.00 0.00 0.17  0.00 0.00 0.00 0.01  \n",
              "2022-05-31  0.00 0.00 0.00 0.16  0.00 0.00 0.00 0.01  \n",
              "2022-06-30  0.00 0.00 0.00 0.23  0.00 0.00 0.00 0.00  \n",
              "2022-07-31  0.00 0.00 0.00 0.23  0.00 0.00 0.00 0.00  \n",
              "2022-08-31  0.00 0.00 0.00 0.24  0.00 0.00 0.00 0.00  \n",
              "2022-09-30  0.00 0.00 0.00 0.25  0.00 0.00 0.00 0.00  \n",
              "2022-10-31  0.00 0.00 0.00 0.24  0.00 0.00 0.00 0.00  \n",
              "2022-11-30  0.00 0.00 0.00 0.24  0.00 0.00 0.00 0.00  \n",
              "2022-12-31  0.00 0.00 0.00 0.24  0.00 0.00 0.00 0.00  \n",
              "2023-01-31  0.00 0.00 0.00 0.25  0.00 0.00 0.00 0.00  \n",
              "2023-02-28  0.00 0.00 0.00 0.24  0.00 0.00 0.00 0.00  \n",
              "2023-03-31  0.00 0.00 0.00 0.23  0.00 0.00 0.00 0.00  \n",
              "2023-04-30  0.00 0.00 0.00 0.23  0.00 0.00 0.00 0.00  \n",
              "2023-05-31  0.00 0.00 0.00 0.23  0.00 0.00 0.00 0.00  \n",
              "2023-06-30  0.00 0.00 0.00 0.21  0.00 0.00 0.00 0.00  \n",
              "\n",
              "[24 rows x 61 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_wts = pd.DataFrame(y_pred_test_cnn, index=test_date_index, columns=dataset.Ticker[:asset_num])\n",
        "cnn_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiBbbQsrWUy5",
        "outputId": "4e88d1d8-3d69-49e7-a838-b12c1db4ce6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/WQU_Capstone/Capstone Project/models/cnn/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/WQU_Capstone/Capstone Project/models/cnn/assets\n"
          ]
        }
      ],
      "source": [
        "# save cnn model to \"disk\" for easier access if needed\n",
        "cnn.save(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/models/cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLUAbZIlXmYI"
      },
      "outputs": [],
      "source": [
        "# # load best model for next time if needed\n",
        "# loaded_cnn_model = tf.keras.models.load_model(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/models/cnn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nc-vZVdmM-f"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L-P5uyNu7Pn"
      },
      "outputs": [],
      "source": [
        "rnn_param_grid = {\n",
        "    'input_layer_size': [64, 128],\n",
        "    'optimizer': ['adam'],\n",
        "    'epochs': [50],\n",
        "    'learning_rate': [0.01]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeSus_R1mHH-"
      },
      "outputs": [],
      "source": [
        "# Define RNN model\n",
        "def create_RNN_model(custom_loss, asset_num, input_shape, params):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.SimpleRNN(params['input_layer_size'], input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(asset_num, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer_instance = tf.keras.optimizers.get(params['optimizer'])\n",
        "    optimizer_instance.learning_rate = params['learning_rate']\n",
        "    model.compile(optimizer=optimizer_instance, loss=custom_loss)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcxcY41VvrPG",
        "outputId": "3795f623-dd14-4577-87e9-6eb9a811f0eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing parameters:  {'epochs': 50, 'input_layer_size': 64, 'learning_rate': 0.01, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -5.6173 - val_loss: -22.5765\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -6.3402 - val_loss: -18.6527\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -7.2170 - val_loss: -15.7773\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -8.3129 - val_loss: -13.1210\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -9.3626 - val_loss: -11.2741\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -10.5393 - val_loss: -10.3676\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.8225 - val_loss: -9.9711\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.7284 - val_loss: -11.2986\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -13.4992 - val_loss: -12.2382\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -13.9478 - val_loss: -12.1105\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -14.3748 - val_loss: -10.8331\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -14.8184 - val_loss: -9.7522\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -15.0998 - val_loss: -9.7550\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.1350 - val_loss: -9.3733\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.3344 - val_loss: -9.8255\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -15.4125 - val_loss: -10.3615\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.4241 - val_loss: -10.0511\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.5342 - val_loss: -10.2314\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.5469 - val_loss: -10.6097\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -15.5043 - val_loss: -10.5533\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.5055 - val_loss: -10.2442\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.5066 - val_loss: -10.1340\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.5408 - val_loss: -9.9896\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.5551 - val_loss: -9.8711\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.5657 - val_loss: -10.3587\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.5969 - val_loss: -10.8828\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.5966 - val_loss: -11.2372\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -15.5826 - val_loss: -11.6895\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -15.5734 - val_loss: -11.6806\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.5929 - val_loss: -11.3663\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.6051 - val_loss: -10.9366\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.6141 - val_loss: -10.5852\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.6132 - val_loss: -10.2885\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.6016 - val_loss: -10.0936\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.6008 - val_loss: -10.2036\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.6049 - val_loss: -10.3852\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -15.6129 - val_loss: -10.5738\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -15.6185 - val_loss: -10.8406\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.6166 - val_loss: -10.9681\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.6213 - val_loss: -10.9213\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.6303 - val_loss: -10.9190\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.6245 - val_loss: -10.9129\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.6185 - val_loss: -10.8072\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.6261 - val_loss: -10.7680\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.6289 - val_loss: -10.7571\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.6276 - val_loss: -10.6858\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -15.6256 - val_loss: -10.6187\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.6233 - val_loss: -10.5731\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.6258 - val_loss: -10.5241\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.6279 - val_loss: -10.5321\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -14.5707 - val_loss: -8.6571\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -15.3799 - val_loss: -8.2299\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -15.3700 - val_loss: -7.9000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -14.9656 - val_loss: -7.7601\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: -15.0531 - val_loss: -7.5925\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -15.6583 - val_loss: -7.3692\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.5829 - val_loss: -7.5784\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.2563 - val_loss: -8.0172\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.4422 - val_loss: -7.9007\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.7509 - val_loss: -7.6249\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -15.6757 - val_loss: -7.4855\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -15.5304 - val_loss: -7.4626\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.5337 - val_loss: -7.5372\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -15.6578 - val_loss: -7.8203\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.7736 - val_loss: -8.2967\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -15.6824 - val_loss: -8.3066\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -15.6385 - val_loss: -7.7656\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -15.7974 - val_loss: -7.3177\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -15.7662 - val_loss: -7.2147\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -15.6912 - val_loss: -7.3684\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -15.7126 - val_loss: -7.6728\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -15.7984 - val_loss: -8.0131\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -15.8159 - val_loss: -8.1890\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -15.7575 - val_loss: -8.0748\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -15.7557 - val_loss: -7.8339\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -15.7893 - val_loss: -7.6880\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -15.7943 - val_loss: -7.6975\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -15.7953 - val_loss: -7.7799\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -15.8051 - val_loss: -7.8080\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -15.8098 - val_loss: -7.7515\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -15.8071 - val_loss: -7.7119\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -15.7989 - val_loss: -7.7648\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -15.8180 - val_loss: -7.8275\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -15.8251 - val_loss: -7.8302\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -15.8112 - val_loss: -7.8028\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -15.8151 - val_loss: -7.7750\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -15.8267 - val_loss: -7.7699\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.8228 - val_loss: -7.8155\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.8214 - val_loss: -7.8680\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.8261 - val_loss: -7.8365\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.8294 - val_loss: -7.7230\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.8289 - val_loss: -7.6315\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -15.8240 - val_loss: -7.6471\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.8290 - val_loss: -7.7634\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.8358 - val_loss: -7.8883\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -15.8302 - val_loss: -7.9178\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.8274 - val_loss: -7.8371\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.8338 - val_loss: -7.7312\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -15.8353 - val_loss: -7.6866\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.8320 - val_loss: -7.7170\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -11.1433 - val_loss: -6.7747\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.8345 - val_loss: -7.2085\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -11.9712 - val_loss: -7.4241\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.5475 - val_loss: -7.4564\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.6151 - val_loss: -7.3580\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.0094 - val_loss: -7.1596\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.0390 - val_loss: -7.0153\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -11.7877 - val_loss: -7.0406\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -11.8500 - val_loss: -7.2205\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.1571 - val_loss: -7.4297\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.1541 - val_loss: -7.5299\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -11.9528 - val_loss: -7.5136\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.0327 - val_loss: -7.3893\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.1687 - val_loss: -7.2428\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.0667 - val_loss: -7.2155\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.0766 - val_loss: -7.2954\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.2105 - val_loss: -7.3886\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.2163 - val_loss: -7.4283\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -12.1416 - val_loss: -7.4035\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -12.1413 - val_loss: -7.3335\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.1665 - val_loss: -7.2693\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.1437 - val_loss: -7.2670\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.1528 - val_loss: -7.3263\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -12.2072 - val_loss: -7.3965\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -12.2271 - val_loss: -7.4311\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -12.2228 - val_loss: -7.4171\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.2239 - val_loss: -7.3746\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.2074 - val_loss: -7.3456\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.1934 - val_loss: -7.3516\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.2098 - val_loss: -7.3745\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.2282 - val_loss: -7.3865\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -12.2373 - val_loss: -7.3763\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.2437 - val_loss: -7.3529\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.2395 - val_loss: -7.3368\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -12.2284 - val_loss: -7.3423\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.2264 - val_loss: -7.3644\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -12.2331 - val_loss: -7.3853\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.2409 - val_loss: -7.3903\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -12.2511 - val_loss: -7.3780\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -12.2598 - val_loss: -7.3602\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.2604 - val_loss: -7.3532\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -12.2596 - val_loss: -7.3645\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.2670 - val_loss: -7.3872\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.2832 - val_loss: -7.4078\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.3102 - val_loss: -7.4198\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.3609 - val_loss: -7.4350\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -12.4688 - val_loss: -7.4927\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -12.7135 - val_loss: -7.6286\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -12.7161 - val_loss: -7.6481\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -12.8565 - val_loss: -7.6333\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: -10.6886 - val_loss: -7.5102\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -10.8132 - val_loss: -7.2762\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -11.1369 - val_loss: -7.3487\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -11.3474 - val_loss: -7.2901\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -11.2459 - val_loss: -6.6142\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -11.2266 - val_loss: -6.7543\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -11.3156 - val_loss: -7.7067\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -11.4161 - val_loss: -8.3689\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -11.3224 - val_loss: -7.9202\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -11.3514 - val_loss: -7.1663\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -11.2679 - val_loss: -7.0937\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -11.2861 - val_loss: -7.6486\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -11.4500 - val_loss: -8.1827\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -11.3611 - val_loss: -7.8425\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.4314 - val_loss: -7.1514\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.4574 - val_loss: -6.9917\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -11.3980 - val_loss: -7.4166\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -11.5210 - val_loss: -8.0863\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -11.5131 - val_loss: -8.3579\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -11.5492 - val_loss: -8.2334\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -11.6196 - val_loss: -8.1339\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -11.5942 - val_loss: -8.2998\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.5785 - val_loss: -8.6867\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -11.5884 - val_loss: -9.0417\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -11.5796 - val_loss: -9.0681\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.5811 - val_loss: -8.7209\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -11.6129 - val_loss: -8.2609\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.6206 - val_loss: -8.0145\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -11.6096 - val_loss: -8.1020\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.6247 - val_loss: -8.3547\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -11.6272 - val_loss: -8.4567\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.6426 - val_loss: -8.3757\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -11.6970 - val_loss: -8.5089\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -11.8212 - val_loss: -9.6724\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -12.2414 - val_loss: -14.5645\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -13.0805 - val_loss: -26.0825\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -12.9317 - val_loss: -26.0496\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.7889 - val_loss: -29.0198\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -13.2639 - val_loss: -31.0993\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.1247 - val_loss: -29.3175\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -13.2895 - val_loss: -28.0752\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.6065 - val_loss: -26.1058\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -13.4483 - val_loss: -22.0998\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -13.4822 - val_loss: -17.1412\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -13.5014 - val_loss: -15.4801\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -13.5203 - val_loss: -17.4111\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -13.6218 - val_loss: -22.2232\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -13.6635 - val_loss: -28.0708\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -13.6756 - val_loss: -30.6559\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -13.6071 - val_loss: -31.1870\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -13.8843 - val_loss: -14.6184\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -13.8839 - val_loss: -15.0249\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -13.9060 - val_loss: -15.6711\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -13.9654 - val_loss: -16.8020\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.0193 - val_loss: -18.7482\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -14.0722 - val_loss: -20.8149\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -14.0837 - val_loss: -21.3427\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.1034 - val_loss: -20.5139\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -14.1118 - val_loss: -19.9543\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.0932 - val_loss: -20.2323\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.0858 - val_loss: -20.6960\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.0869 - val_loss: -20.5547\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1053 - val_loss: -19.8334\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -14.1151 - val_loss: -19.2062\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.1170 - val_loss: -18.8184\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -14.1151 - val_loss: -18.2502\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.1029 - val_loss: -17.5363\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.0991 - val_loss: -17.2639\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -14.0980 - val_loss: -17.7694\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -14.1099 - val_loss: -18.7692\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1187 - val_loss: -19.4672\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.1221 - val_loss: -19.5572\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.1232 - val_loss: -19.5831\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.1193 - val_loss: -19.8877\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -14.1212 - val_loss: -20.1373\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.1233 - val_loss: -19.9231\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -14.1297 - val_loss: -19.4420\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.1368 - val_loss: -19.1733\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.1416 - val_loss: -19.1904\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: -14.1443 - val_loss: -19.1615\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.1432 - val_loss: -18.9272\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1435 - val_loss: -18.7635\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.1430 - val_loss: -18.9231\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -14.1443 - val_loss: -19.2691\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -14.1452 - val_loss: -19.4659\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -14.1450 - val_loss: -19.4465\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -14.1445 - val_loss: -19.4533\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -14.1428 - val_loss: -19.6349\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -14.1427 - val_loss: -19.8427\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -14.1433 - val_loss: -19.8480\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -14.1449 - val_loss: -19.6638\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -14.1468 - val_loss: -19.5002\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -14.1481 - val_loss: -19.4411\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -14.1491 - val_loss: -19.3597\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -14.1489 - val_loss: -19.1741\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -14.1487 - val_loss: -19.0209\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -14.1483 - val_loss: -19.0632\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -14.1484 - val_loss: -19.2567\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -14.1486 - val_loss: -19.4102\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -14.1487 - val_loss: -19.4460\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -14.8270 - val_loss: -12.0122\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -14.9002 - val_loss: -11.9722\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -15.0188 - val_loss: -11.2836\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.9820 - val_loss: -11.4868\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -15.0363 - val_loss: -12.6113\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.0047 - val_loss: -12.8184\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -15.0940 - val_loss: -11.9939\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.0194 - val_loss: -12.0529\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -15.1385 - val_loss: -12.1441\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -15.0567 - val_loss: -11.5306\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.1229 - val_loss: -11.3244\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.0736 - val_loss: -11.9106\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.1367 - val_loss: -12.8184\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.0771 - val_loss: -12.2740\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -15.1614 - val_loss: -11.5633\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -15.1044 - val_loss: -11.6797\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -15.1350 - val_loss: -12.3627\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.1247 - val_loss: -12.4812\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -15.1532 - val_loss: -12.0577\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -15.1239 - val_loss: -11.9801\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 105ms/step - loss: -15.1566 - val_loss: -11.9907\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.1317 - val_loss: -11.8002\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.1506 - val_loss: -11.7583\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -15.1454 - val_loss: -12.1371\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -15.1578 - val_loss: -12.5808\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.1414 - val_loss: -12.2851\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -15.1595 - val_loss: -11.8353\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.1475 - val_loss: -11.8613\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.1584 - val_loss: -12.1776\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.1550 - val_loss: -12.2025\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.1608 - val_loss: -11.9917\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.1524 - val_loss: -11.9831\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.1610 - val_loss: -12.0770\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -15.1569 - val_loss: -12.0095\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -15.1623 - val_loss: -11.9528\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.1590 - val_loss: -12.1387\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -15.1622 - val_loss: -12.3479\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.1580 - val_loss: -12.1867\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -15.1638 - val_loss: -11.9278\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -15.1609 - val_loss: -11.9314\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -15.1637 - val_loss: -12.0943\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -15.1613 - val_loss: -12.1140\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.1638 - val_loss: -12.0340\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -15.1616 - val_loss: -12.0623\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -15.1649 - val_loss: -12.1160\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.1627 - val_loss: -12.0583\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -15.1644 - val_loss: -12.0240\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -15.1630 - val_loss: -12.1292\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -15.1648 - val_loss: -12.2022\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -15.1634 - val_loss: -12.0786\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -13.4956 - val_loss: -9.3530\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.0576 - val_loss: -9.4636\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 104ms/step - loss: -14.0809 - val_loss: -9.4603\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -13.9701 - val_loss: -9.4573\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -14.0049 - val_loss: -9.4662\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -13.7778 - val_loss: -9.4375\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -13.9112 - val_loss: -9.4272\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -13.8430 - val_loss: -9.4518\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -13.8598 - val_loss: -9.4472\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -13.9104 - val_loss: -9.4281\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -13.8463 - val_loss: -9.4442\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -13.9303 - val_loss: -9.4619\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -13.8579 - val_loss: -9.4531\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -13.9495 - val_loss: -9.4584\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -13.9448 - val_loss: -9.4880\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.0043 - val_loss: -9.5051\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -14.0634 - val_loss: -9.5186\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -14.0947 - val_loss: -9.5451\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.1655 - val_loss: -9.5473\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -14.1132 - val_loss: -9.5367\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.0628 - val_loss: -9.5423\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.0717 - val_loss: -9.5455\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -14.1651 - val_loss: -9.5362\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.1661 - val_loss: -9.5202\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.1562 - val_loss: -9.5072\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1328 - val_loss: -9.5033\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -14.1275 - val_loss: -9.4987\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1333 - val_loss: -9.4932\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.1420 - val_loss: -9.4917\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -14.1659 - val_loss: -9.4856\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.1757 - val_loss: -9.4730\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -14.1864 - val_loss: -9.4568\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.1698 - val_loss: -9.4416\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.1596 - val_loss: -9.4395\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.1541 - val_loss: -9.4544\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -14.1716 - val_loss: -9.4710\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.1810 - val_loss: -9.4829\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.1872 - val_loss: -9.4908\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -14.1810 - val_loss: -9.4954\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -14.1772 - val_loss: -9.4990\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -14.1746 - val_loss: -9.5034\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -14.1763 - val_loss: -9.5069\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1823 - val_loss: -9.5099\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.1860 - val_loss: -9.5121\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.1895 - val_loss: -9.5123\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.1855 - val_loss: -9.5125\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.1828 - val_loss: -9.5130\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.1810 - val_loss: -9.5133\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -14.1851 - val_loss: -9.5136\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.1880 - val_loss: -9.5133\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -14.4886 - val_loss: -8.2680\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.5013 - val_loss: -8.6583\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.5630 - val_loss: -9.0203\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -14.5516 - val_loss: -8.5043\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -14.5840 - val_loss: -8.6084\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 107ms/step - loss: -14.6078 - val_loss: -8.9828\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -14.6020 - val_loss: -8.5599\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.6365 - val_loss: -8.4807\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.6470 - val_loss: -8.8098\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.6455 - val_loss: -8.4834\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -14.6654 - val_loss: -8.3194\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.6567 - val_loss: -8.6802\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -14.6607 - val_loss: -8.5401\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -14.6830 - val_loss: -8.3889\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -14.6826 - val_loss: -8.7937\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.6943 - val_loss: -8.7013\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -14.7111 - val_loss: -8.5177\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -14.7111 - val_loss: -8.8862\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -14.7298 - val_loss: -8.7622\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.7601 - val_loss: -8.5906\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -14.7804 - val_loss: -8.9559\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -14.8193 - val_loss: -8.8535\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -14.8750 - val_loss: -8.8291\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.9244 - val_loss: -9.3719\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -14.9739 - val_loss: -9.4157\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -14.9837 - val_loss: -9.6250\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -14.9391 - val_loss: -10.0220\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -14.9650 - val_loss: -9.8182\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -15.0128 - val_loss: -9.5632\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -15.0096 - val_loss: -9.7539\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -14.9923 - val_loss: -9.6373\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -14.9821 - val_loss: -9.5437\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -14.9790 - val_loss: -9.8685\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -14.9885 - val_loss: -9.7823\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -15.0008 - val_loss: -9.8744\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -14.9947 - val_loss: -10.1538\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -14.9813 - val_loss: -9.9387\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -14.9863 - val_loss: -9.9053\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -14.9986 - val_loss: -9.9150\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -15.0017 - val_loss: -9.4079\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -14.9716 - val_loss: -10.7204\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -14.7615 - val_loss: -9.4152\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -14.9691 - val_loss: -9.1743\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -14.8973 - val_loss: -10.5632\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -14.8749 - val_loss: -10.2436\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -14.9728 - val_loss: -9.1745\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -14.8374 - val_loss: -9.9265\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -15.0079 - val_loss: -10.4123\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -14.9060 - val_loss: -9.4807\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -15.0126 - val_loss: -9.0826\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -12.1006 - val_loss: -9.9905\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.6572 - val_loss: -9.6549\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.4555 - val_loss: -9.6145\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -12.5908 - val_loss: -9.5145\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.6107 - val_loss: -9.4392\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -12.4763 - val_loss: -9.7451\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -12.8918 - val_loss: -9.8861\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: -12.8619 - val_loss: -9.9791\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: -12.7430 - val_loss: -10.0605\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -12.6658 - val_loss: -10.0369\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -12.6874 - val_loss: -9.9414\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.7810 - val_loss: -9.8695\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -12.9090 - val_loss: -9.7738\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -12.9700 - val_loss: -9.6075\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -12.8171 - val_loss: -9.6080\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -12.8651 - val_loss: -9.6641\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.9118 - val_loss: -9.7335\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.9169 - val_loss: -9.8842\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -12.9575 - val_loss: -9.9837\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -12.8692 - val_loss: -9.9302\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.9343 - val_loss: -9.7923\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.9723 - val_loss: -9.7001\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -12.9424 - val_loss: -9.6708\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -12.9437 - val_loss: -9.6775\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -12.9317 - val_loss: -9.7484\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.9680 - val_loss: -9.8234\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -12.9886 - val_loss: -9.8576\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -12.9613 - val_loss: -9.8786\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -12.9472 - val_loss: -9.8855\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -12.9612 - val_loss: -9.8513\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -12.9832 - val_loss: -9.7823\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -12.9883 - val_loss: -9.7217\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -12.9740 - val_loss: -9.7019\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -12.9668 - val_loss: -9.7254\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -12.9776 - val_loss: -9.7817\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -12.9925 - val_loss: -9.8431\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -12.9865 - val_loss: -9.8698\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: -12.9777 - val_loss: -9.8484\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -12.9833 - val_loss: -9.8092\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.9874 - val_loss: -9.7814\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.9934 - val_loss: -9.7626\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -12.9896 - val_loss: -9.7550\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.9851 - val_loss: -9.7639\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -12.9934 - val_loss: -9.7814\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.9955 - val_loss: -9.8089\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -12.9960 - val_loss: -9.8360\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -12.9954 - val_loss: -9.8377\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -12.9962 - val_loss: -9.8100\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -13.0037 - val_loss: -9.7771\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -13.0058 - val_loss: -9.7617\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -11.2326 - val_loss: -19.8205\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -11.2414 - val_loss: -20.5744\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.2338 - val_loss: -20.5350\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -11.2429 - val_loss: -20.0595\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.2453 - val_loss: -19.8657\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.2453 - val_loss: -20.1170\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -11.2574 - val_loss: -20.3789\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.2528 - val_loss: -19.7242\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -11.2648 - val_loss: -19.1340\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.2616 - val_loss: -19.1614\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.2677 - val_loss: -19.5616\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -11.2667 - val_loss: -19.4941\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.2723 - val_loss: -19.2067\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.2741 - val_loss: -19.3929\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: -11.2797 - val_loss: -19.9331\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.2836 - val_loss: -19.9586\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.2894 - val_loss: -19.5258\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -11.2944 - val_loss: -19.6063\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.2989 - val_loss: -19.8587\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -11.2963 - val_loss: -19.3760\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -11.2991 - val_loss: -19.6100\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.3058 - val_loss: -19.9963\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 111ms/step - loss: -11.3048 - val_loss: -19.4683\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.3091 - val_loss: -19.7025\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 109ms/step - loss: -11.3171 - val_loss: -19.9904\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -11.3163 - val_loss: -19.2411\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.3183 - val_loss: -19.5147\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.3290 - val_loss: -19.3314\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -11.3323 - val_loss: -18.6422\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.3300 - val_loss: -18.7839\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 108ms/step - loss: -11.3345 - val_loss: -18.4099\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -11.3410 - val_loss: -18.4516\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.3456 - val_loss: -18.7632\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -11.3468 - val_loss: -18.6022\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.3443 - val_loss: -19.1333\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -11.3470 - val_loss: -18.6292\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -11.3490 - val_loss: -18.7059\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.3662 - val_loss: -18.4056\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.3742 - val_loss: -18.2099\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -11.3732 - val_loss: -18.4086\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 460ms/step - loss: -11.3810 - val_loss: -18.4970\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -11.3917 - val_loss: -18.5876\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -11.3945 - val_loss: -18.7720\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.4007 - val_loss: -18.5015\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.4135 - val_loss: -18.2152\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -11.4259 - val_loss: -17.9171\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.4358 - val_loss: -17.6538\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -11.4507 - val_loss: -17.4471\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.4756 - val_loss: -17.1699\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.5364 - val_loss: -16.3597\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 947ms/step - loss: -10.8630 - val_loss: -12.2180\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -11.1597 - val_loss: -11.2996\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -11.1953 - val_loss: -11.7175\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -11.2356 - val_loss: -11.7010\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -11.1717 - val_loss: -11.2108\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -11.3273 - val_loss: -11.1950\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -11.2860 - val_loss: -11.2376\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -11.2765 - val_loss: -11.1557\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -11.3418 - val_loss: -11.3881\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -11.4676 - val_loss: -11.4945\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -11.5624 - val_loss: -11.4062\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -11.5795 - val_loss: -11.0782\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.6178 - val_loss: -10.8775\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.4442 - val_loss: -11.7782\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.4132 - val_loss: -11.7141\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.4431 - val_loss: -11.6613\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.4646 - val_loss: -11.5085\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.4286 - val_loss: -11.5957\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -11.4590 - val_loss: -11.5703\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -11.5063 - val_loss: -11.4622\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -11.5317 - val_loss: -11.2332\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.5719 - val_loss: -10.9079\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.6002 - val_loss: -11.0322\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.6223 - val_loss: -10.9103\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.6334 - val_loss: -10.6705\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -11.6519 - val_loss: -10.6239\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.6753 - val_loss: -10.6928\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -11.7123 - val_loss: -10.7061\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -11.6752 - val_loss: -10.8792\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -11.6816 - val_loss: -10.3593\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.7347 - val_loss: -10.2272\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -11.7280 - val_loss: -10.6038\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -11.7502 - val_loss: -10.4831\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.6885 - val_loss: -11.3001\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -11.3990 - val_loss: -10.3364\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.5285 - val_loss: -10.0454\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -11.4043 - val_loss: -9.9319\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.5256 - val_loss: -10.2125\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -11.6913 - val_loss: -10.6951\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.5215 - val_loss: -10.6207\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.6480 - val_loss: -10.3137\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -11.5609 - val_loss: -10.9866\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.4843 - val_loss: -11.0951\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.4073 - val_loss: -10.9502\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -11.3969 - val_loss: -10.8026\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -11.4153 - val_loss: -10.8113\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.4509 - val_loss: -10.9304\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.5001 - val_loss: -11.0539\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.5710 - val_loss: -11.1446\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.6270 - val_loss: -11.2833\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -10.8943 - val_loss: -16.1874\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -10.9496 - val_loss: -16.9565\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -11.0572 - val_loss: -17.4998\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -11.1744 - val_loss: -17.9705\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -11.1916 - val_loss: -17.7631\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -11.1249 - val_loss: -16.5557\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -11.1077 - val_loss: -15.3318\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -11.0963 - val_loss: -15.1538\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -11.1117 - val_loss: -15.8079\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -11.1661 - val_loss: -16.6325\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: -11.2151 - val_loss: -17.4485\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 355ms/step - loss: -11.2334 - val_loss: -18.0218\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: -11.2098 - val_loss: -18.1224\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 411ms/step - loss: -11.1863 - val_loss: -17.7491\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 493ms/step - loss: -11.2012 - val_loss: -17.0598\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 377ms/step - loss: -11.2180 - val_loss: -16.4970\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -11.2176 - val_loss: -16.3659\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 491ms/step - loss: -11.2168 - val_loss: -16.6688\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 452ms/step - loss: -11.2206 - val_loss: -17.2080\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 1s 695ms/step - loss: -11.2199 - val_loss: -17.6921\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 1s 719ms/step - loss: -11.2147 - val_loss: -17.9193\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 1s 659ms/step - loss: -11.2174 - val_loss: -17.8598\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 1s 600ms/step - loss: -11.2274 - val_loss: -17.5871\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 434ms/step - loss: -11.2326 - val_loss: -17.2372\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: -11.2288 - val_loss: -16.9639\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 435ms/step - loss: -11.2224 - val_loss: -16.8722\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 398ms/step - loss: -11.2205 - val_loss: -16.9841\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 494ms/step - loss: -11.2251 - val_loss: -17.2401\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 424ms/step - loss: -11.2316 - val_loss: -17.5228\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 357ms/step - loss: -11.2339 - val_loss: -17.7078\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 307ms/step - loss: -11.2309 - val_loss: -17.7214\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -11.2279 - val_loss: -17.5656\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 371ms/step - loss: -11.2290 - val_loss: -17.3184\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 578ms/step - loss: -11.2316 - val_loss: -17.1051\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 1s 515ms/step - loss: -11.2327 - val_loss: -17.0297\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 459ms/step - loss: -11.2326 - val_loss: -17.1183\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 334ms/step - loss: -11.2329 - val_loss: -17.3117\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 431ms/step - loss: -11.2328 - val_loss: -17.5033\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -11.2321 - val_loss: -17.6017\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -11.2323 - val_loss: -17.5760\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -11.2339 - val_loss: -17.4560\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: -11.2351 - val_loss: -17.3084\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: -11.2348 - val_loss: -17.2017\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.2337 - val_loss: -17.1766\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -11.2335 - val_loss: -17.2355\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -11.2344 - val_loss: -17.3459\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -11.2355 - val_loss: -17.4553\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -11.2358 - val_loss: -17.5139\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -11.2353 - val_loss: -17.4976\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -11.2351 - val_loss: -17.4190\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 357ms/step - loss: -12.0457 - val_loss: -7.9804\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -12.4756 - val_loss: -6.2298\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -12.4761 - val_loss: -5.2728\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -12.3022 - val_loss: -5.6656\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -12.5420 - val_loss: -6.9064\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -12.4411 - val_loss: -7.4219\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -12.3136 - val_loss: -6.8752\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -12.6065 - val_loss: -6.0307\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.5776 - val_loss: -5.8934\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -12.3952 - val_loss: -6.4221\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -12.6446 - val_loss: -7.1892\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -12.5835 - val_loss: -7.2913\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -12.4870 - val_loss: -6.5986\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -12.6413 - val_loss: -5.8469\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -12.5999 - val_loss: -5.8537\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -12.5594 - val_loss: -6.5510\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -12.6705 - val_loss: -7.3106\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.6142 - val_loss: -7.4504\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -12.5781 - val_loss: -6.8997\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -12.6718 - val_loss: -6.1775\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.6497 - val_loss: -5.9282\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -12.6120 - val_loss: -6.2903\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 112ms/step - loss: -12.6790 - val_loss: -6.8403\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 114ms/step - loss: -12.6497 - val_loss: -7.0065\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -12.6411 - val_loss: -6.7192\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -12.6870 - val_loss: -6.3597\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -12.6560 - val_loss: -6.2793\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.6607 - val_loss: -6.5000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -12.6935 - val_loss: -6.7334\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -12.6667 - val_loss: -6.6906\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -12.6718 - val_loss: -6.4367\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -12.6961 - val_loss: -6.2861\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -12.6803 - val_loss: -6.4129\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -12.6872 - val_loss: -6.6943\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.7007 - val_loss: -6.8454\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.6897 - val_loss: -6.7043\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -12.7021 - val_loss: -6.4085\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -12.7117 - val_loss: -6.2517\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -12.7043 - val_loss: -6.3695\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.7199 - val_loss: -6.6240\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 113ms/step - loss: -12.7295 - val_loss: -6.7581\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -12.7310 - val_loss: -6.6609\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.7503 - val_loss: -6.4531\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -12.7673 - val_loss: -6.3336\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -12.7867 - val_loss: -6.3774\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -12.8257 - val_loss: -6.4794\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -12.8738 - val_loss: -6.4752\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -12.9462 - val_loss: -6.3149\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -13.0435 - val_loss: -6.0900\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -13.0718 - val_loss: -5.9885\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -9.5933 - val_loss: -5.5359\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -11.0691 - val_loss: -6.0474\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -11.6073 - val_loss: -6.2572\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -11.5969 - val_loss: -6.3197\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -11.7226 - val_loss: -6.3191\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -11.3008 - val_loss: -6.3722\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 400ms/step - loss: -11.5947 - val_loss: -6.4119\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 408ms/step - loss: -11.4514 - val_loss: -6.4224\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 405ms/step - loss: -11.3590 - val_loss: -6.4140\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: -11.5194 - val_loss: -6.3828\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -11.4789 - val_loss: -6.3785\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 336ms/step - loss: -11.4275 - val_loss: -6.4114\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: -11.5498 - val_loss: -6.4260\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: -11.4376 - val_loss: -6.4233\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: -11.4756 - val_loss: -6.4043\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: -11.5520 - val_loss: -6.3846\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 366ms/step - loss: -11.4475 - val_loss: -6.4007\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -11.5409 - val_loss: -6.4199\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 352ms/step - loss: -11.5134 - val_loss: -6.4236\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: -11.4832 - val_loss: -6.4134\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: -11.5454 - val_loss: -6.3951\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -11.5129 - val_loss: -6.3957\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -11.5153 - val_loss: -6.4126\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -11.5474 - val_loss: -6.4208\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -11.5100 - val_loss: -6.4168\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: -11.5337 - val_loss: -6.4035\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -11.5445 - val_loss: -6.3965\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -11.5181 - val_loss: -6.4067\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -11.5497 - val_loss: -6.4168\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -11.5338 - val_loss: -6.4172\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -11.5319 - val_loss: -6.4088\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -11.5506 - val_loss: -6.4001\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -11.5330 - val_loss: -6.4037\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -11.5441 - val_loss: -6.4129\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -11.5465 - val_loss: -6.4161\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.5368 - val_loss: -6.4116\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.5488 - val_loss: -6.4038\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.5443 - val_loss: -6.4031\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -11.5423 - val_loss: -6.4098\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -11.5503 - val_loss: -6.4144\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 115ms/step - loss: -11.5429 - val_loss: -6.4126\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -11.5470 - val_loss: -6.4068\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -11.5492 - val_loss: -6.4039\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.5443 - val_loss: -6.4078\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -11.5500 - val_loss: -6.4125\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -11.5474 - val_loss: -6.4127\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -11.5469 - val_loss: -6.4087\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -11.5504 - val_loss: -6.4052\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -11.5470 - val_loss: -6.4068\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -11.5492 - val_loss: -6.4108\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: -9.4474 - val_loss: -26.4744\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -9.4639 - val_loss: -24.3059\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: -9.4784 - val_loss: -22.0680\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -9.4640 - val_loss: -21.6775\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -9.4587 - val_loss: -23.2835\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 288ms/step - loss: -9.4752 - val_loss: -25.3530\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -9.4755 - val_loss: -26.3981\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -9.4650 - val_loss: -26.2222\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -9.4675 - val_loss: -24.9709\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 116ms/step - loss: -9.4773 - val_loss: -23.2850\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -9.4752 - val_loss: -22.4544\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -9.4685 - val_loss: -23.0775\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -9.4739 - val_loss: -24.5078\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -9.4783 - val_loss: -25.6031\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -9.4738 - val_loss: -25.8100\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -9.4720 - val_loss: -25.1482\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -9.4766 - val_loss: -23.9941\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 120ms/step - loss: -9.4780 - val_loss: -23.1524\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -9.4744 - val_loss: -23.2427\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -9.4749 - val_loss: -24.1034\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -9.4782 - val_loss: -25.0139\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -9.4772 - val_loss: -25.3922\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -9.4753 - val_loss: -25.1043\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -9.4768 - val_loss: -24.3586\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -9.4784 - val_loss: -23.6600\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -9.4770 - val_loss: -23.5112\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -9.4764 - val_loss: -23.9722\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -9.4779 - val_loss: -24.6401\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -9.4782 - val_loss: -25.0438\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -9.4770 - val_loss: -24.9747\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -9.4773 - val_loss: -24.5179\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -9.4783 - val_loss: -23.9906\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -9.4780 - val_loss: -23.7654\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -9.4774 - val_loss: -23.9792\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -9.4780 - val_loss: -24.4317\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -9.4784 - val_loss: -24.7861\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -9.4779 - val_loss: -24.8286\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -9.4778 - val_loss: -24.5652\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -9.4783 - val_loss: -24.1893\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -9.4783 - val_loss: -23.9665\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -9.4779 - val_loss: -24.0415\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -9.4781 - val_loss: -24.3311\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -9.4784 - val_loss: -24.6112\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -9.4782 - val_loss: -24.6987\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -9.4781 - val_loss: -24.5577\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -9.4783 - val_loss: -24.3003\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -9.4784 - val_loss: -24.1106\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -9.4782 - val_loss: -24.1158\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -9.4782 - val_loss: -24.2928\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -9.4784 - val_loss: -24.5006\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 370ms/step - loss: -10.2438 - val_loss: -2.4253\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -10.3189 - val_loss: -2.3718\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -10.2550 - val_loss: -2.3705\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -10.2523 - val_loss: -2.4161\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -10.3144 - val_loss: -2.4806\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -10.2883 - val_loss: -2.4927\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -10.2684 - val_loss: -2.4410\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -10.3203 - val_loss: -2.3940\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -10.2925 - val_loss: -2.3863\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -10.2813 - val_loss: -2.4173\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -10.3152 - val_loss: -2.4646\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -10.3073 - val_loss: -2.4790\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -10.2905 - val_loss: -2.4457\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.3192 - val_loss: -2.4083\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -10.3085 - val_loss: -2.3990\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -10.2989 - val_loss: -2.4206\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -10.3170 - val_loss: -2.4552\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -10.3147 - val_loss: -2.4678\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -10.3042 - val_loss: -2.4457\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -10.3192 - val_loss: -2.4173\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -10.3152 - val_loss: -2.4087\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -10.3089 - val_loss: -2.4240\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -10.3185 - val_loss: -2.4493\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -10.3178 - val_loss: -2.4592\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -10.3119 - val_loss: -2.4441\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -10.3197 - val_loss: -2.4230\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -10.3181 - val_loss: -2.4159\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -10.3144 - val_loss: -2.4271\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -10.3196 - val_loss: -2.4456\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -10.3193 - val_loss: -2.4529\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -10.3161 - val_loss: -2.4422\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -10.3201 - val_loss: -2.4266\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -10.3195 - val_loss: -2.4213\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -10.3174 - val_loss: -2.4296\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: -10.3202 - val_loss: -2.4431\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -10.3200 - val_loss: -2.4483\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: -10.3183 - val_loss: -2.4404\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -10.3205 - val_loss: -2.4290\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: -10.3201 - val_loss: -2.4252\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -10.3190 - val_loss: -2.4315\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -10.3205 - val_loss: -2.4414\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: -10.3203 - val_loss: -2.4448\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.3195 - val_loss: -2.4389\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -10.3207 - val_loss: -2.4306\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -10.3204 - val_loss: -2.4281\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -10.3199 - val_loss: -2.4330\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -10.3207 - val_loss: -2.4402\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 117ms/step - loss: -10.3205 - val_loss: -2.4423\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -10.3202 - val_loss: -2.4377\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -10.3208 - val_loss: -2.4317\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -4.6411 - val_loss: -4.4254\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -4.6768 - val_loss: -4.5227\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -4.7462 - val_loss: -4.6640\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -4.8207 - val_loss: -4.8102\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 119ms/step - loss: -4.8472 - val_loss: -4.9092\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -4.8088 - val_loss: -4.9523\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -4.7583 - val_loss: -4.9606\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -4.7433 - val_loss: -4.9438\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -4.7715 - val_loss: -4.8952\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -4.8193 - val_loss: -4.8115\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -4.8474 - val_loss: -4.7149\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 118ms/step - loss: -4.8376 - val_loss: -4.6398\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -4.8109 - val_loss: -4.6057\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -4.7948 - val_loss: -4.6158\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -4.7999 - val_loss: -4.6638\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -4.8213 - val_loss: -4.7355\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -4.8431 - val_loss: -4.8089\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -4.8489 - val_loss: -4.8638\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -4.8377 - val_loss: -4.8922\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -4.8246 - val_loss: -4.8959\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -4.8236 - val_loss: -4.8778\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -4.8358 - val_loss: -4.8415\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -4.8511 - val_loss: -4.7975\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -4.8604 - val_loss: -4.7672\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -4.8664 - val_loss: -4.7697\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -4.8724 - val_loss: -4.7753\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -4.8666 - val_loss: -4.7722\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -4.8615 - val_loss: -4.7706\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -4.8605 - val_loss: -4.7731\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -4.8636 - val_loss: -4.7772\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -4.8726 - val_loss: -4.7735\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -4.8891 - val_loss: -4.7608\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -4.8951 - val_loss: -4.7842\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -4.9002 - val_loss: -4.8405\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -4.9134 - val_loss: -4.8922\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -4.9125 - val_loss: -4.9030\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -4.9198 - val_loss: -4.8774\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -4.9375 - val_loss: -4.8638\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -4.9531 - val_loss: -4.9136\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -4.9815 - val_loss: -4.8955\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -5.0100 - val_loss: -4.8405\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -5.0277 - val_loss: -4.8888\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -5.0525 - val_loss: -4.8626\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -5.0807 - val_loss: -4.9125\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -5.1328 - val_loss: -4.9487\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -5.1551 - val_loss: -4.8752\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -5.1573 - val_loss: -4.9465\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -5.2093 - val_loss: -4.9729\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -5.2726 - val_loss: -4.8534\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -5.2561 - val_loss: -5.0375\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -4.7473 - val_loss: -14.1365\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -4.7259 - val_loss: -13.5030\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -4.8392 - val_loss: -12.5163\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -4.8086 - val_loss: -13.4626\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -4.8930 - val_loss: -13.7604\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -4.9054 - val_loss: -12.4175\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -5.0054 - val_loss: -11.7262\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -5.0428 - val_loss: -12.9877\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -5.0750 - val_loss: -12.7859\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: -5.0849 - val_loss: -11.4516\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: -5.1002 - val_loss: -11.6421\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -5.1794 - val_loss: -12.5993\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -5.1902 - val_loss: -11.2984\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -5.2552 - val_loss: -11.3149\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -5.2556 - val_loss: -12.1807\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -5.2743 - val_loss: -12.1251\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -5.2963 - val_loss: -11.3185\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -5.3305 - val_loss: -11.0723\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -5.3534 - val_loss: -11.3727\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -5.3771 - val_loss: -11.2388\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -5.3973 - val_loss: -10.6904\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -5.4173 - val_loss: -10.6041\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -5.4350 - val_loss: -10.8163\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -5.4594 - val_loss: -10.7308\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -5.4920 - val_loss: -10.4531\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -5.5309 - val_loss: -10.5168\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -5.5576 - val_loss: -10.7363\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -5.5770 - val_loss: -10.4111\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -5.5786 - val_loss: -12.6569\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -5.4283 - val_loss: -10.4512\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -5.3922 - val_loss: -11.6001\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -5.3595 - val_loss: -11.6611\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -5.3716 - val_loss: -10.5608\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -5.4528 - val_loss: -9.8584\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -5.4552 - val_loss: -9.8539\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -5.4398 - val_loss: -10.2201\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -5.4358 - val_loss: -10.3082\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -5.4608 - val_loss: -10.1397\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -5.4855 - val_loss: -10.0092\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -5.4928 - val_loss: -10.0991\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -5.5095 - val_loss: -10.2552\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -5.5136 - val_loss: -10.1897\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -5.5264 - val_loss: -10.0187\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -5.5418 - val_loss: -9.9814\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -5.5543 - val_loss: -10.0753\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -5.5651 - val_loss: -10.1046\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -5.5772 - val_loss: -10.0467\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -5.6006 - val_loss: -10.1860\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -5.6199 - val_loss: -10.4955\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -5.6351 - val_loss: -10.4529\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 382ms/step - loss: -6.0202 - val_loss: -inf\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: -6.0730 - val_loss: -inf\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -6.1675 - val_loss: -inf\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -6.3485 - val_loss: -inf\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -6.7352 - val_loss: -inf\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -6.4170 - val_loss: -inf\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -6.4749 - val_loss: -inf\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -6.6673 - val_loss: -inf\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -6.7055 - val_loss: -inf\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -6.7068 - val_loss: -inf\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 346ms/step - loss: -6.6538 - val_loss: -inf\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 406ms/step - loss: -6.7443 - val_loss: -inf\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 379ms/step - loss: -6.7599 - val_loss: -inf\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 348ms/step - loss: -6.8053 - val_loss: -inf\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: -6.8292 - val_loss: -inf\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: -6.8550 - val_loss: -inf\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -6.8805 - val_loss: -inf\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -6.9208 - val_loss: -inf\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -6.9731 - val_loss: -inf\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: -7.0250 - val_loss: -inf\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -7.1574 - val_loss: -inf\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -7.9308 - val_loss: -inf\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -10.0348 - val_loss: -inf\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -9.0862 - val_loss: -inf\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 259ms/step - loss: -9.6729 - val_loss: -inf\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -9.0504 - val_loss: -inf\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -10.9734 - val_loss: -inf\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 474ms/step - loss: -11.2614 - val_loss: -inf\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 587ms/step - loss: -10.7303 - val_loss: -inf\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 364ms/step - loss: -11.9284 - val_loss: -inf\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 1s 509ms/step - loss: -11.3678 - val_loss: -inf\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 484ms/step - loss: -11.6039 - val_loss: -inf\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 371ms/step - loss: -11.9698 - val_loss: -inf\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 501ms/step - loss: -10.8127 - val_loss: -inf\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 1s 548ms/step - loss: -11.1209 - val_loss: -inf\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 1s 554ms/step - loss: -8.2346 - val_loss: -inf\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 1s 553ms/step - loss: -10.5704 - val_loss: -inf\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -10.1472 - val_loss: -inf\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -9.8954 - val_loss: -inf\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -10.7205 - val_loss: -inf\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -11.7852 - val_loss: -inf\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -11.8163 - val_loss: -inf\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -12.9087 - val_loss: -inf\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -12.0268 - val_loss: -inf\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -12.9858 - val_loss: -inf\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -13.4495 - val_loss: -inf\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -13.6552 - val_loss: -inf\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -10.5829 - val_loss: -inf\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -9.1931 - val_loss: -inf\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 122ms/step - loss: -9.0664 - val_loss: -inf\n",
            "Testing parameters:  {'epochs': 50, 'input_layer_size': 128, 'learning_rate': 0.01, 'optimizer': 'adam'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -5.5133 - val_loss: -18.3701\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -6.7474 - val_loss: -10.3806\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -8.3252 - val_loss: -10.2159\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -10.8639 - val_loss: -9.7416\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -12.9291 - val_loss: -12.3387\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -13.5491 - val_loss: -11.7502\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -14.4059 - val_loss: -10.2498\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -15.0641 - val_loss: -8.5033\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -14.3714 - val_loss: -5.6491\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -11.3448 - val_loss: -7.1570\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -10.5789 - val_loss: -7.4716\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -13.6911 - val_loss: -7.8185\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -14.0001 - val_loss: -11.4023\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -14.8298 - val_loss: -12.3943\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -14.4304 - val_loss: -11.7594\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -14.0205 - val_loss: -11.7436\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -14.1730 - val_loss: -11.8305\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -14.7856 - val_loss: -11.2190\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -15.0105 - val_loss: -11.1937\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -14.7129 - val_loss: -9.7655\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -14.8594 - val_loss: -9.0795\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -14.6802 - val_loss: -8.9745\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -14.5698 - val_loss: -9.1021\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -14.7008 - val_loss: -9.7364\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -14.9090 - val_loss: -10.8864\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -14.9519 - val_loss: -11.5143\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -15.1672 - val_loss: -11.9027\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -15.3549 - val_loss: -12.4005\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -15.2717 - val_loss: -12.7584\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -15.1865 - val_loss: -12.7058\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -15.2390 - val_loss: -11.7948\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -15.4126 - val_loss: -10.6517\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -15.5193 - val_loss: -9.8711\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -15.4927 - val_loss: -9.4180\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 259ms/step - loss: -15.4401 - val_loss: -9.1741\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -15.4482 - val_loss: -9.2199\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -15.4706 - val_loss: -9.5722\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -15.4946 - val_loss: -10.0264\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -15.5204 - val_loss: -10.4893\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: -15.5365 - val_loss: -10.9562\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -15.5170 - val_loss: -11.2783\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -15.4922 - val_loss: -11.2774\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -15.4941 - val_loss: -10.9284\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -15.5265 - val_loss: -10.3689\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -15.5530 - val_loss: -9.8906\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -15.5479 - val_loss: -9.6990\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -15.5361 - val_loss: -9.6726\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -15.5159 - val_loss: -9.6783\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -15.5228 - val_loss: -9.8076\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -15.5420 - val_loss: -10.1499\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -14.2324 - val_loss: -8.6949\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -15.2276 - val_loss: -8.4117\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -14.9230 - val_loss: -8.5584\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -14.6800 - val_loss: -9.0476\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -14.4216 - val_loss: -9.0694\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -14.9913 - val_loss: -8.5767\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -15.4054 - val_loss: -7.5610\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -15.1228 - val_loss: -7.2591\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -14.7963 - val_loss: -7.9136\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -15.3003 - val_loss: -8.5967\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -15.2751 - val_loss: -8.9233\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -15.2482 - val_loss: -8.9377\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -15.1447 - val_loss: -8.5589\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -15.2853 - val_loss: -7.9389\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -15.4864 - val_loss: -7.6662\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -15.3169 - val_loss: -8.0461\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -15.3486 - val_loss: -8.4470\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -15.3184 - val_loss: -8.2996\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -15.4142 - val_loss: -8.1428\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -15.4977 - val_loss: -8.1470\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -15.3862 - val_loss: -8.1090\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -15.4185 - val_loss: -8.1834\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -15.5192 - val_loss: -8.3711\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -15.4783 - val_loss: -8.3038\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -15.4260 - val_loss: -8.1112\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -15.4501 - val_loss: -8.1051\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -15.5350 - val_loss: -8.2507\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -15.5147 - val_loss: -8.3931\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -15.4567 - val_loss: -8.4144\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -15.5272 - val_loss: -8.2662\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -15.5496 - val_loss: -8.0679\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -15.4967 - val_loss: -8.0282\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -15.5062 - val_loss: -8.1433\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -15.5485 - val_loss: -8.2906\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -15.5436 - val_loss: -8.3629\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -15.5239 - val_loss: -8.2979\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -15.5531 - val_loss: -8.1733\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -15.5623 - val_loss: -8.1467\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -15.5567 - val_loss: -8.2167\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -15.5683 - val_loss: -8.2589\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -15.5900 - val_loss: -8.2377\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -15.6299 - val_loss: -8.1729\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -15.6814 - val_loss: -8.0462\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -15.7748 - val_loss: -7.7898\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -15.6330 - val_loss: -7.5300\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -15.7752 - val_loss: -7.5958\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -15.6753 - val_loss: -8.0612\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -15.7359 - val_loss: -8.2499\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -15.7503 - val_loss: -8.0299\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -15.7558 - val_loss: -7.7122\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 357ms/step - loss: -11.1303 - val_loss: -6.7358\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -11.7028 - val_loss: -7.2483\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -11.9663 - val_loss: -7.5238\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -11.5311 - val_loss: -7.5325\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -11.7435 - val_loss: -7.2977\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -12.1153 - val_loss: -7.0058\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -11.8823 - val_loss: -6.9241\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -11.7090 - val_loss: -7.0935\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 293ms/step - loss: -12.0002 - val_loss: -7.3929\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -12.1275 - val_loss: -7.5602\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -11.9144 - val_loss: -7.5270\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -12.0533 - val_loss: -7.3255\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -12.2181 - val_loss: -7.1588\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -11.9846 - val_loss: -7.2443\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -12.0977 - val_loss: -7.4573\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -12.1724 - val_loss: -7.5404\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -12.0241 - val_loss: -7.4807\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -12.1753 - val_loss: -7.3145\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -12.1831 - val_loss: -7.2356\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -12.1258 - val_loss: -7.3167\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -12.2275 - val_loss: -7.4381\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -12.1964 - val_loss: -7.4681\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -12.1440 - val_loss: -7.3919\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -12.2366 - val_loss: -7.2880\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -12.2305 - val_loss: -7.3051\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -12.2400 - val_loss: -7.4719\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -12.3612 - val_loss: -7.7409\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -12.5510 - val_loss: -8.5103\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -13.1589 - val_loss: -9.7631\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -12.2759 - val_loss: -9.3863\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -13.1753 - val_loss: -8.1740\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -11.8253 - val_loss: -8.5948\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -12.8595 - val_loss: -9.6426\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -12.7746 - val_loss: -9.8777\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -12.1588 - val_loss: -9.8073\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -12.2779 - val_loss: -9.4333\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -12.9974 - val_loss: -8.7329\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -13.0912 - val_loss: -8.4689\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -12.4901 - val_loss: -8.6692\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -13.0467 - val_loss: -9.1264\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -13.2030 - val_loss: -9.4072\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -12.8157 - val_loss: -9.3982\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -12.8970 - val_loss: -9.1152\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -13.3612 - val_loss: -8.6856\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -13.0547 - val_loss: -8.7048\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -13.0691 - val_loss: -9.1632\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -13.4109 - val_loss: -9.4447\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -13.0935 - val_loss: -9.4121\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -13.1795 - val_loss: -9.0938\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -13.4444 - val_loss: -8.7795\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -11.4789 - val_loss: -18.4631\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -12.0538 - val_loss: -25.7181\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: -12.5250 - val_loss: -25.5919\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: -12.4837 - val_loss: -25.0192\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: -12.6008 - val_loss: -27.3102\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: -13.0159 - val_loss: -35.1358\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -12.7251 - val_loss: -33.4378\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: -12.8953 - val_loss: -26.0437\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 294ms/step - loss: -13.0550 - val_loss: -24.2393\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -12.8223 - val_loss: -25.5298\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 694ms/step - loss: -12.9736 - val_loss: -30.4911\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 666ms/step - loss: -13.3724 - val_loss: -31.6103\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: -13.2046 - val_loss: -21.9680\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -13.3763 - val_loss: -18.0774\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: -13.2277 - val_loss: -21.6747\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -13.2478 - val_loss: -26.4100\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -13.2927 - val_loss: -29.1539\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -13.4350 - val_loss: -33.2164\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -13.3881 - val_loss: -34.6535\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -13.2620 - val_loss: -31.0214\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -13.4669 - val_loss: -28.7952\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -13.3845 - val_loss: -27.3804\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -13.4344 - val_loss: -23.7548\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -13.4998 - val_loss: -21.6042\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -13.4140 - val_loss: -23.5842\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -13.4315 - val_loss: -27.4034\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -13.5489 - val_loss: -29.0398\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -13.4821 - val_loss: -29.4934\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -13.4577 - val_loss: -30.5711\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -13.5270 - val_loss: -30.5752\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -13.4958 - val_loss: -28.2721\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -13.5313 - val_loss: -25.9118\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -13.5584 - val_loss: -24.8065\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -13.5141 - val_loss: -24.8739\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -13.5247 - val_loss: -25.9249\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -13.5695 - val_loss: -27.6475\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -13.5553 - val_loss: -29.1258\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -13.5497 - val_loss: -29.5338\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -13.5653 - val_loss: -29.1977\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -13.5472 - val_loss: -28.5208\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -13.5581 - val_loss: -27.2032\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -13.5724 - val_loss: -25.6981\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -13.5546 - val_loss: -25.1266\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -13.5560 - val_loss: -25.7068\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -13.5669 - val_loss: -26.7373\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -13.5624 - val_loss: -27.6096\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -13.5673 - val_loss: -28.2245\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -13.5750 - val_loss: -28.5260\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -13.5657 - val_loss: -28.4100\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -13.5713 - val_loss: -27.9478\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -13.4957 - val_loss: -13.8056\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -13.5507 - val_loss: -13.4459\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -13.4716 - val_loss: -13.7689\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -13.6226 - val_loss: -14.4746\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -13.6023 - val_loss: -15.2629\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -13.6652 - val_loss: -15.7454\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -13.7498 - val_loss: -16.6419\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -13.7089 - val_loss: -18.9375\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -13.7247 - val_loss: -20.9164\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -13.6595 - val_loss: -19.1476\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -13.7258 - val_loss: -16.3281\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -13.7537 - val_loss: -14.9356\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -13.7437 - val_loss: -14.4415\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -13.7193 - val_loss: -14.2905\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -13.6970 - val_loss: -14.4336\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -13.7317 - val_loss: -15.1258\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -13.7402 - val_loss: -16.7062\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -13.7625 - val_loss: -18.3592\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -13.7276 - val_loss: -18.1459\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -13.7413 - val_loss: -16.8898\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -13.7468 - val_loss: -16.2388\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -13.7579 - val_loss: -16.1687\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -13.7731 - val_loss: -15.9763\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -13.7534 - val_loss: -15.5576\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -13.7741 - val_loss: -15.4536\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -13.7657 - val_loss: -16.0461\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -13.7800 - val_loss: -17.0887\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -13.7790 - val_loss: -17.6043\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -13.7715 - val_loss: -17.2039\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -13.7804 - val_loss: -16.7164\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -13.7765 - val_loss: -16.6764\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -13.8067 - val_loss: -17.0358\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -13.9756 - val_loss: -19.4652\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -15.4100 - val_loss: -25.4284\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -18.7302 - val_loss: -20.9277\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -17.5681 - val_loss: -22.9201\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -18.9989 - val_loss: -14.3144\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 404ms/step - loss: -14.7993 - val_loss: -17.0034\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 1s 505ms/step - loss: -16.8118 - val_loss: -20.4495\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 465ms/step - loss: -17.5630 - val_loss: -18.5646\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 468ms/step - loss: -16.3555 - val_loss: -18.1298\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 419ms/step - loss: -16.0775 - val_loss: -17.9922\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 1s 588ms/step - loss: -15.9903 - val_loss: -17.9392\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 1s 576ms/step - loss: -15.9571 - val_loss: -17.9160\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -15.9428 - val_loss: -17.9048\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 372ms/step - loss: -15.9360 - val_loss: -17.8991\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 443ms/step - loss: -15.9326 - val_loss: -17.8959\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 415ms/step - loss: -15.9307 - val_loss: -17.8940\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 490ms/step - loss: -15.9296 - val_loss: -17.8929\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 435ms/step - loss: -15.9290 - val_loss: -17.8922\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 433ms/step - loss: -14.8036 - val_loss: -11.0483\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: -14.8033 - val_loss: -11.0482\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -14.8031 - val_loss: -11.0481\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -14.8030 - val_loss: -11.0480\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: -14.8029 - val_loss: -11.0480\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -14.8028 - val_loss: -11.0479\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 380ms/step - loss: -14.8028 - val_loss: -11.0479\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 352ms/step - loss: -14.8027 - val_loss: -11.0479\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: -14.8027 - val_loss: -11.0479\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 366ms/step - loss: -14.8027 - val_loss: -11.0479\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 387ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 377ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 367ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 374ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 360ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 398ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 462ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 355ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 340ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -14.8026 - val_loss: -11.0478\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -14.8025 - val_loss: -11.0478\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 550ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 359ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 431ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 1s 529ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 365ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 398ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 365ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 346ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 412ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 364ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 346ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 354ms/step - loss: -12.8275 - val_loss: -13.5816\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 390ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 1s 502ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 402ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 388ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 479ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 399ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 320ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 259ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -12.0943 - val_loss: -10.1407\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 371ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -11.8773 - val_loss: -7.6017\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 391ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 424ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 557ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 366ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 433ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 580ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 1s 547ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 456ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 596ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 1s 754ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 1s 772ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 451ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: -9.5663 - val_loss: -14.6694\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -9.5664 - val_loss: -14.6694\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.0047 - val_loss: -16.0282\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -10.0994 - val_loss: -13.0112\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.9225 - val_loss: -6.6280\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 347ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -10.1513 - val_loss: -6.0421\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 291ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -8.0638 - val_loss: -10.8361\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -7.8047 - val_loss: -2.0251\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -3.7332 - val_loss: -7.1698\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -3.7876 - val_loss: -8.6321\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -3.8191 - val_loss: -inf\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -3.8191 - val_loss: -inf\n"
          ]
        }
      ],
      "source": [
        "best_score = np.inf\n",
        "best_params = None\n",
        "\n",
        "for params in ParameterGrid(rnn_param_grid):\n",
        "  print(\"Testing parameters: \", params)\n",
        "\n",
        "  rnn = create_RNN_model(negative_sharpe_loss,\n",
        "                         asset_num,\n",
        "                         X_train_cnn_reshaped.shape[1:],\n",
        "                         params)\n",
        "\n",
        "  preds, avg_score = walk_forward(n_train=n_train,\n",
        "                                      n_val=n_val,\n",
        "                                      df=df_trainval,\n",
        "                                      epochs=params['epochs'],\n",
        "                                      batch=batch,\n",
        "                                      model=rnn,\n",
        "                                      asset_num=len(x_tickers),\n",
        "                                      best_params=best_params,\n",
        "                                      best_score=best_score,\n",
        "                                      hpo=True)\n",
        "\n",
        "  if avg_score < best_score:\n",
        "    best_score = avg_score\n",
        "    best_params = params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UERpVUFVzyFL",
        "outputId": "93c4d182-ae89-49a4-e94f-aef240e036be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'epochs': 50,\n",
              " 'input_layer_size': 64,\n",
              " 'learning_rate': 0.01,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACVwZdNPzaMc",
        "outputId": "462d2dae-737d-44ae-a40d-5d7e341783e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 1s 73ms/step - loss: -6.4190\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: -6.8972\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 129ms/step - loss: -6.7785\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 143ms/step - loss: -6.9327\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 143ms/step - loss: -6.3665\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 122ms/step - loss: -6.8644\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 143ms/step - loss: -7.1237\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 137ms/step - loss: -6.7410\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 144ms/step - loss: -7.6299\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 135ms/step - loss: -7.0210\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 127ms/step - loss: -7.1123\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 133ms/step - loss: -7.5457\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 127ms/step - loss: -8.3387\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -9.6891\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 70ms/step - loss: -8.8544\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 77ms/step - loss: -8.9600\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -8.1056\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: -8.3197\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 71ms/step - loss: -9.0128\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -8.7564\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 75ms/step - loss: -9.1058\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: -9.2266\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -8.6040\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: -8.8273\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: -8.4250\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 74ms/step - loss: -8.2585\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -8.4612\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -7.6351\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: -8.0473\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 64ms/step - loss: -9.2582\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 75ms/step - loss: -8.2499\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -8.5836\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: -8.0793\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: -7.5885\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 66ms/step - loss: -8.5398\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 73ms/step - loss: -7.7805\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 68ms/step - loss: -7.8620\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: -7.0863\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: -6.8378\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: -7.6633\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 73ms/step - loss: -7.9714\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 70ms/step - loss: -7.6382\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: -7.7729\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 68ms/step - loss: -6.7635\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: -7.2909\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: -7.4387\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 68ms/step - loss: -7.2583\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 64ms/step - loss: -8.2833\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: -7.8387\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: -7.6492\n"
          ]
        }
      ],
      "source": [
        "# train with best params\n",
        "rnn = create_RNN_model(negative_sharpe_loss,\n",
        "                        asset_num,\n",
        "                        X_train_cnn_reshaped.shape[1:],\n",
        "                        best_params)\n",
        "\n",
        "rnn_history = rnn.fit(\n",
        "                      df_trainval.iloc[:, :-asset_num],\n",
        "                      df_trainval.iloc[:, -asset_num:],\n",
        "                      epochs=best_params['epochs'],\n",
        "                      batch_size=batch,\n",
        "                      verbose=1\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QwIcUG-zjFQ",
        "outputId": "23f98144-5d24-4fc8-c07e-35804d0d1490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 155ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_test_rnn = rnn.predict(df_test.iloc[:, :-asset_num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "-e3FNh1H0XqU",
        "outputId": "625f5999-6cdc-4c8e-af7b-39bf0e7a1135"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rnn_wts"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bbeeb435-baba-4b59-bed1-f1c8c2c475b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-07-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbeeb435-baba-4b59-bed1-f1c8c2c475b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbeeb435-baba-4b59-bed1-f1c8c2c475b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbeeb435-baba-4b59-bed1-f1c8c2c475b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70ea9fbf-efac-4865-9f75-098c09d967c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70ea9fbf-efac-4865-9f75-098c09d967c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70ea9fbf-efac-4865-9f75-098c09d967c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ed7bd10d-36df-48bb-bff9-2b696c45a312\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rnn_wts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ed7bd10d-36df-48bb-bff9-2b696c45a312 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rnn_wts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker      ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  \\\n",
              "Date                                                          ...             \n",
              "2021-07-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-08-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-09-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-10-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-11-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2021-12-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-01-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-02-28 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-03-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-04-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-05-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-06-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-07-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-08-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-09-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-10-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-11-30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2022-12-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-01-31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-02-28 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-03-31 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-04-30 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-05-31 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "2023-06-30 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  ... 0.00 0.00   \n",
              "\n",
              "Ticker      SPGI  SWK  SYY  TGT  TROW  WMT  WST  XOM  \n",
              "Date                                                  \n",
              "2021-07-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2021-08-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2021-09-30  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2021-10-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2021-11-30  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2021-12-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-01-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-02-28  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-03-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-04-30  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-05-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-06-30  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-07-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-08-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-09-30  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-10-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-11-30  0.00 0.01 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2022-12-31  0.00 0.01 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-01-31  0.00 0.00 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-02-28  0.00 0.01 0.00 0.00  0.00 0.00 0.00 0.00  \n",
              "2023-03-31  0.00 0.02 0.03 0.00  0.00 0.00 0.01 0.00  \n",
              "2023-04-30  0.00 0.02 0.03 0.00  0.00 0.00 0.01 0.00  \n",
              "2023-05-31  0.00 0.02 0.03 0.00  0.00 0.00 0.01 0.00  \n",
              "2023-06-30  0.00 0.02 0.02 0.00  0.00 0.00 0.01 0.00  \n",
              "\n",
              "[24 rows x 61 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn_wts = pd.DataFrame(y_pred_test_rnn, index=test_date_index, columns=dataset.Ticker[:asset_num])\n",
        "rnn_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoTiwCNj30Nz",
        "outputId": "e9d0bd15-0780-4e15-aa94-ea33fdf08497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/WQU_Capstone/Capstone Project/models/rnn/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/WQU_Capstone/Capstone Project/models/rnn/assets\n"
          ]
        }
      ],
      "source": [
        "# save rnn model to \"disk\" for easier access if needed\n",
        "rnn.save(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/models/rnn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4Xwzb7n30Kh"
      },
      "outputs": [],
      "source": [
        "# # load best model for next time if needed\n",
        "# loaded_rnn_model = tf.keras.models.load_model(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/models/rnn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PFR4IZR42Pp"
      },
      "source": [
        "## A few visuals of weight outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "YATcaGSmcI54",
        "outputId": "0f6290e5-e715-4015-9218-1d87940ff077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b3e4e2c3a00>]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# I'd like to look at the distribution of \"non-zero\" (e.g. greater than 0.1%) tickers\n",
        "plt.plot(cnn_wts[cnn_wts > 0.001].nunique(axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ywgEoNL2noIh",
        "outputId": "5b3c1860-f29c-46f7-f9b9-a3debb53d86a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "colors = plt.cm.viridis(np.linspace(0, 1, asset_num))\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(asset_num):\n",
        "  plt.plot(cnn_wts.iloc[:, i], color=colors[i], label=dataset.Ticker[:asset_num][i])\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Weight Percentage')\n",
        "plt.title('Change in Weight Percentage of Constituents Over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI0QeOKO4503"
      },
      "source": [
        "## Backtest Neural Network Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygbMr2obxWmb"
      },
      "outputs": [],
      "source": [
        "def perform_backtest(prices, model_preds):\n",
        "  price_data = prices.drop(['MDT', 'LIN'], axis=1)\n",
        "  # price_data = price_data[price_data.index.isin(date_index[n_train:])]\n",
        "  price_data = price_data[price_data.index.isin(test_date_index)]\n",
        "  price_data = price_data.sort_index()\n",
        "\n",
        "  p_rets = []\n",
        "  p_metrics = pd.DataFrame()\n",
        "\n",
        "  for idx, preds in enumerate(model_preds):\n",
        "    # portfolio value over time\n",
        "    portfolio_value = (price_data * preds).sum(axis=1)\n",
        "\n",
        "    # monthly portfolio returns\n",
        "    portfolio_returns = portfolio_value.pct_change()\n",
        "    p_rets.append(portfolio_returns)\n",
        "\n",
        "    # total return, annualized return, Sharpe ratio, Volatility, Max Drawdown\n",
        "    totalReturn = portfolio_value[-1] / portfolio_value[0] - 1\n",
        "    years = len(portfolio_value) / 12\n",
        "    annualReturn = ((portfolio_value[-1] / portfolio_value[0]) ** (1 / years)) - 1\n",
        "    monthly_returns = portfolio_value.pct_change()\n",
        "    sharpeRatio = (monthly_returns.mean() / monthly_returns.std()) * np.sqrt(12)\n",
        "    volatility = monthly_returns.std() * np.sqrt(12)\n",
        "    cumulative_returns = (1 + monthly_returns).cumprod()\n",
        "    maxDrawdown = (cumulative_returns / cumulative_returns.cummax() - 1).min()\n",
        "\n",
        "    nn_metrics = pd.DataFrame({f'NN{idx}':[totalReturn, annualReturn, sharpeRatio, volatility, maxDrawdown]})\n",
        "    p_metrics = pd.concat([p_metrics, nn_metrics], axis=1)\n",
        "\n",
        "  p_metrics.index = ['totalReturn', 'annualReturn', 'sharpeRatio', 'volatility', 'maxDrawdown']\n",
        "  return p_rets, p_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-5WaIIE1m7H"
      },
      "source": [
        "#### Equal-Weighted Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "FWOO7858tJOB",
        "outputId": "15c9fca0-6fc3-494c-f583-f03e4bb3158f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ew_wts"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0da84650-06e9-42c7-8071-f2ccec7b8f89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-07-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-28</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0da84650-06e9-42c7-8071-f2ccec7b8f89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0da84650-06e9-42c7-8071-f2ccec7b8f89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0da84650-06e9-42c7-8071-f2ccec7b8f89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29ce67eb-08a6-437d-9e40-56cb316dfd6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29ce67eb-08a6-437d-9e40-56cb316dfd6f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29ce67eb-08a6-437d-9e40-56cb316dfd6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9f0501d7-3cc0-4691-bb5b-fc7e817d7a04\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ew_wts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9f0501d7-3cc0-4691-bb5b-fc7e817d7a04 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ew_wts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker      ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  \\\n",
              "Date                                                          ...             \n",
              "2021-07-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-08-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-09-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-10-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-11-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-12-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-01-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-02-28 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-03-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-04-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-05-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-06-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-07-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-08-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-09-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-10-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-11-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2022-12-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2023-01-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2023-02-28 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2023-03-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2023-04-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2023-05-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2023-06-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "\n",
              "Ticker     SPGI  SWK  SYY  TGT TROW  WMT  WST  XOM  \n",
              "Date                                                \n",
              "2021-07-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2021-08-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2021-09-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2021-10-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2021-11-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2021-12-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-01-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-02-28 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-03-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-04-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-05-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-06-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-07-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-08-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-09-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-10-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-11-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2022-12-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2023-01-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2023-02-28 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2023-03-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2023-04-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2023-05-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "2023-06-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  \n",
              "\n",
              "[24 rows x 61 columns]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ew_wts = pd.DataFrame(index=rnn_wts.index, columns=rnn_wts.columns)\n",
        "ew_wts[:] = 1 / len(ew_wts.columns)\n",
        "ew_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RolhR_6Z5-VH",
        "outputId": "8cbae45a-9539-4e91-8053-5df75b979246"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-116-79e3448a91eb>:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  totalReturn = portfolio_value[-1] / portfolio_value[0] - 1\n",
            "<ipython-input-116-79e3448a91eb>:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  annualReturn = ((portfolio_value[-1] / portfolio_value[0]) ** (1 / years)) - 1\n",
            "<ipython-input-116-79e3448a91eb>:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  totalReturn = portfolio_value[-1] / portfolio_value[0] - 1\n",
            "<ipython-input-116-79e3448a91eb>:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  annualReturn = ((portfolio_value[-1] / portfolio_value[0]) ** (1 / years)) - 1\n",
            "<ipython-input-116-79e3448a91eb>:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  totalReturn = portfolio_value[-1] / portfolio_value[0] - 1\n",
            "<ipython-input-116-79e3448a91eb>:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  annualReturn = ((portfolio_value[-1] / portfolio_value[0]) ** (1 / years)) - 1\n",
            "<ipython-input-116-79e3448a91eb>:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  portfolio_returns = portfolio_value.pct_change()\n",
            "<ipython-input-116-79e3448a91eb>:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  totalReturn = portfolio_value[-1] / portfolio_value[0] - 1\n",
            "<ipython-input-116-79e3448a91eb>:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  annualReturn = ((portfolio_value[-1] / portfolio_value[0]) ** (1 / years)) - 1\n",
            "<ipython-input-116-79e3448a91eb>:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  monthly_returns = portfolio_value.pct_change()\n"
          ]
        }
      ],
      "source": [
        "p_rets, p_metrics = perform_backtest(prices=data_m, model_preds=[mlp_wts, cnn_wts, rnn_wts, ew_wts])\n",
        "p_rets_df = pd.concat(p_rets, axis=1).dropna()\n",
        "p_rets_df.columns = ['MLP', 'CNN', 'RNN', 'EW']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "NcKh-nlQ_QMD",
        "outputId": "cf7c5622-f900-4a07-e416-ed729961b963"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"p_rets_df\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-08-31 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"2022-11-30 00:00:00\",\n          \"2022-05-31 00:00:00\",\n          \"2021-08-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MLP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1196728854930681,\n        \"min\": -0.31863520337188644,\n        \"max\": 0.17952417382671904,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.018535940175114174,\n          0.013330925839435404,\n          0.00797788742418093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CNN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12837548488827355,\n        \"min\": -0.40413861054571254,\n        \"max\": 0.2228632485116988,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.0528914094102646,\n          -0.013624501102405318,\n          0.02149701728574205\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RNN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07132747506331816,\n        \"min\": -0.12890632275009606,\n        \"max\": 0.15392833873154044,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.11598538045901252,\n          -0.010434946774821374,\n          0.036032417181471876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0573125915835923,\n        \"min\": -0.08990534472606826,\n        \"max\": 0.10490946364315645,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.06377974213187199,\n          -0.008355319985421161,\n          0.015767153363252406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "p_rets_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8cca1247-4d45-4876-8fcd-dda7b89dc960\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLP</th>\n",
              "      <th>CNN</th>\n",
              "      <th>RNN</th>\n",
              "      <th>EW</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-31</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-30</th>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-31</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-31</th>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-28</th>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-31</th>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-30</th>\n",
              "      <td>-0.32</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-31</th>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-30</th>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-31</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-31</th>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-30</th>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-31</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-31</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cca1247-4d45-4876-8fcd-dda7b89dc960')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cca1247-4d45-4876-8fcd-dda7b89dc960 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cca1247-4d45-4876-8fcd-dda7b89dc960');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d37d155b-6c15-46f0-a01a-cb6083a0a644\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d37d155b-6c15-46f0-a01a-cb6083a0a644')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d37d155b-6c15-46f0-a01a-cb6083a0a644 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_93239514-dfae-4087-9440-7e387c7c5b3d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('p_rets_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_93239514-dfae-4087-9440-7e387c7c5b3d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('p_rets_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             MLP   CNN   RNN    EW\n",
              "Date                              \n",
              "2021-08-31  0.01  0.02  0.04  0.02\n",
              "2021-09-30  0.14  0.05 -0.02 -0.05\n",
              "2021-10-31  0.10  0.15  0.02  0.08\n",
              "2021-11-30 -0.04 -0.02  0.02 -0.01\n",
              "2021-12-31  0.06  0.11  0.12  0.06\n",
              "2022-01-31 -0.17 -0.06 -0.06 -0.07\n",
              "2022-02-28 -0.08 -0.05 -0.08 -0.04\n",
              "2022-03-31 -0.25  0.22  0.05  0.04\n",
              "2022-04-30 -0.32 -0.14 -0.04 -0.04\n",
              "2022-05-31  0.01 -0.01 -0.01 -0.01\n",
              "2022-06-30 -0.12 -0.40 -0.13 -0.07\n",
              "2022-07-31  0.04  0.08  0.08  0.08\n",
              "2022-08-31 -0.11 -0.09 -0.02 -0.02\n",
              "2022-09-30 -0.14 -0.12 -0.09 -0.09\n",
              "2022-10-31  0.18  0.08  0.15  0.10\n",
              "2022-11-30  0.02  0.05  0.12  0.06\n",
              "2022-12-31 -0.08 -0.04 -0.07 -0.04\n",
              "2023-01-31  0.05  0.06  0.04  0.03\n",
              "2023-02-28 -0.08 -0.09 -0.01 -0.01\n",
              "2023-03-31  0.02  0.13  0.05  0.01\n",
              "2023-04-30  0.01  0.00 -0.02  0.02\n",
              "2023-05-31 -0.09 -0.11  0.01 -0.05\n",
              "2023-06-30  0.04 -0.08  0.05  0.10"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_rets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "85IBN0h7_N2x",
        "outputId": "690361da-c823-4e8d-ea6c-8a86969e753a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wealth_index = 1000*(1+p_rets_df).cumprod()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for column in wealth_index.columns:\n",
        "    plt.plot(wealth_index.index, wealth_index[column], label=column)\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Wealth Index')\n",
        "plt.title('Wealth Index Over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4rpb6VEyl52"
      },
      "source": [
        "## Reinforcement Learning (RL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrJhhMEIdGUX"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/datasets\"):\n",
        "    os.makedirs(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/datasets\")\n",
        "if not os.path.exists(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/trained_models\"):\n",
        "    os.makedirs(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/trained_models\")\n",
        "if not os.path.exists(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/tensorboard_log\"):\n",
        "    os.makedirs(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/tensorboard_log\")\n",
        "if not os.path.exists(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/results\"):\n",
        "    os.makedirs(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mcMB1Z4PyxBp",
        "outputId": "1762876e-92ac-43ce-b0e4-febcc610991d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"rl_df\",\n  \"rows\": 8845,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2011-06-30 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 145,\n        \"samples\": [\n          \"2017-03-31 00:00:00\",\n          \"2023-02-28 00:00:00\",\n          \"2013-09-30 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"ABT\",\n          \"AOS\",\n          \"PEP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ret\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06441960392585432,\n        \"min\": -0.4341311847769642,\n        \"max\": 0.3775794202082716,\n        \"num_unique_values\": 8841,\n        \"samples\": [\n          -0.04201802518427389,\n          0.008484907213191395,\n          -0.001857039108103642\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dividendYield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3905298607132433,\n        \"min\": -0.12967928200422846,\n        \"max\": 10.695479333796454,\n        \"num_unique_values\": 2046,\n        \"samples\": [\n          0.0076917986900330365,\n          0.01085276404028017,\n          0.0054333268515082125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payoutRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.9828036021143918,\n        \"min\": -137.2,\n        \"max\": 91.85325414501361,\n        \"num_unique_values\": 2044,\n        \"samples\": [\n          0.2955032119914347,\n          0.648,\n          0.3220858895705521\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operatingcashFlowRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.1585951990128,\n        \"min\": -47.37960607602297,\n        \"max\": 3425.71875,\n        \"num_unique_values\": 2068,\n        \"samples\": [\n          0.637479085331846,\n          -0.009181895125324944,\n          -0.060279187817258884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01719399114522255,\n        \"min\": -0.12562852548559178,\n        \"max\": 0.21171303737577252,\n        \"num_unique_values\": 2069,\n        \"samples\": [\n          0.012896569512509672,\n          -0.0017775647171620326,\n          0.018769551616266946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"netProfitMargin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.52717838478797,\n        \"min\": -0.9975609756097561,\n        \"max\": 2877.0,\n        \"num_unique_values\": 2068,\n        \"samples\": [\n          0.04060089321965083,\n          -0.0091399341668388,\n          0.09767441860465116\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3270129043589316,\n        \"min\": 0.05,\n        \"max\": 5.4,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          1.23,\n          0.65,\n          2.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0992715136382447,\n        \"min\": 0.11,\n        \"max\": 4.51,\n        \"num_unique_values\": 109,\n        \"samples\": [\n          1.61,\n          0.35,\n          0.41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cov_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "rl_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4b7ff796-a128-4048-b157-c19166d10f78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>ret</th>\n",
              "      <th>dividendYield</th>\n",
              "      <th>payoutRatio</th>\n",
              "      <th>operatingcashFlowRatio</th>\n",
              "      <th>ROA</th>\n",
              "      <th>netProfitMargin</th>\n",
              "      <th>1 Yr</th>\n",
              "      <th>3 Yr</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ABT</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ADM</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.27</td>\n",
              "      <td>2.19</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ADP</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>AFL</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.46</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ALB</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8840</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>TGT</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8841</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>TROW</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.30</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8842</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>WMT</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8843</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>WST</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.21</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8844</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>XOM</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8845 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b7ff796-a128-4048-b157-c19166d10f78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b7ff796-a128-4048-b157-c19166d10f78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b7ff796-a128-4048-b157-c19166d10f78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e711a050-a811-43e8-b9ff-955aa0602eda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e711a050-a811-43e8-b9ff-955aa0602eda')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e711a050-a811-43e8-b9ff-955aa0602eda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9936ea7f-1a4c-4522-b401-17f1344bb027\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rl_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9936ea7f-1a4c-4522-b401-17f1344bb027 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rl_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Date Ticker   ret  dividendYield  payoutRatio  \\\n",
              "0    2011-06-30    ABT  0.01           0.02         0.39   \n",
              "1    2011-06-30    ADM -0.07           0.01         0.27   \n",
              "2    2011-06-30    ADP -0.04           0.01         0.74   \n",
              "3    2011-06-30    AFL -0.02           0.02         0.46   \n",
              "4    2011-06-30    ALB -0.02           0.00         0.13   \n",
              "...         ...    ...   ...            ...          ...   \n",
              "8840 2023-06-30    TGT  0.01           0.01         0.52   \n",
              "8841 2023-06-30   TROW  0.06           0.01         0.59   \n",
              "8842 2023-06-30    WMT  0.07           0.01         0.92   \n",
              "8843 2023-06-30    WST  0.13           0.00         0.09   \n",
              "8844 2023-06-30    XOM  0.05           0.01         0.49   \n",
              "\n",
              "      operatingcashFlowRatio  ROA  netProfitMargin  1 Yr  3 Yr  \\\n",
              "0                       0.88 0.03             0.20  0.19  0.81   \n",
              "1                       2.19 0.01             0.02  0.19  0.81   \n",
              "2                       0.49 0.01             0.10  0.19  0.81   \n",
              "3                      -0.85 0.00             0.05  0.19  0.81   \n",
              "4                       0.59 0.03             0.16  0.19  0.81   \n",
              "...                      ...  ...              ...   ...   ...   \n",
              "8840                    1.07 0.02             0.04  5.40  4.49   \n",
              "8841                    0.49 0.04             0.30  5.40  4.49   \n",
              "8842                    0.13 0.01             0.01  5.40  4.49   \n",
              "8843                    0.86 0.04             0.21  5.40  4.49   \n",
              "8844                    0.12 0.02             0.10  5.40  4.49   \n",
              "\n",
              "                                               cov_list  \\\n",
              "0     [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "1     [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "2     [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "3     [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "4     [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "...                                                 ...   \n",
              "8840  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "8841  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "8842  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "8843  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "8844  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "\n",
              "                                            return_list  \n",
              "0     Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "1     Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "2     Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "3     Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "4     Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "...                                                 ...  \n",
              "8840  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "8841  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "8842  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "8843  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "8844  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "\n",
              "[8845 rows x 12 columns]"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add covariance matrix as states\n",
        "rl_df = dataset\n",
        "rl_df.index = rl_df.Date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=12\n",
        "for i in range(lookback, len(rl_df.index.unique())):\n",
        "  data_lookback = rl_df.loc[i-lookback:i,:]\n",
        "  return_lookback = data_lookback.pivot_table(index = 'Date',columns = 'Ticker', values = 'ret')\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values\n",
        "  cov_list.append(covs)\n",
        "\n",
        "df_cov = pd.DataFrame({'Date':rl_df.Date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "rl_df = rl_df.merge(df_cov, on='Date')\n",
        "rl_df = rl_df.sort_values(['Date','Ticker']).reset_index(drop=True)\n",
        "rl_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1_5Y1_I7rZU"
      },
      "outputs": [],
      "source": [
        "# monthly price data\n",
        "price_data = data_m.drop(['MDT', 'LIN'], axis=1)\n",
        "# price_data = price_data[price_data.index.isin(date_index[n_train:])]\n",
        "price_data = price_data.sort_index()\n",
        "price_long = price_data.reset_index().melt(id_vars=['Date'], var_name='Ticker', value_name='close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBFswj2J8ebL"
      },
      "outputs": [],
      "source": [
        "rl_df = price_long.merge(rl_df, on=['Date', 'Ticker']).drop('ret', axis=1)\n",
        "rl_df = rl_df.sort_values(by=['Date', 'Ticker'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3sf9Zn1AuMr"
      },
      "source": [
        "## Build Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qiyXMoKAtas",
        "outputId": "537c2808-d3a9-4324-ac62-c973ac04aa7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Timestamp('2021-06-30 00:00:00')"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_trainval\n",
        "trainval_date_index[-1]\n",
        "# df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Erc7sb20Yo",
        "outputId": "5ba72c59-7039-4e18-f222-52306bc45240"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "train_pct = 0.8\n",
        "unique_dates = sorted(rl_df.Date.unique())\n",
        "train_end_date = unique_dates[int(train_pct * len(unique_dates))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "A_PGxnr-yMPw",
        "outputId": "813790c0-3638-4f8e-a462-e9848c0e3a1c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"rl_train\",\n  \"rows\": 7381,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2011-06-30 00:00:00\",\n        \"max\": \"2021-06-30 00:00:00\",\n        \"num_unique_values\": 121,\n        \"samples\": [\n          \"2015-02-28 00:00:00\",\n          \"2015-05-31 00:00:00\",\n          \"2011-10-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"ABT\",\n          \"AOS\",\n          \"PEP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.812992069120924,\n        \"min\": 6.617712497711182,\n        \"max\": 462.2679748535156,\n        \"num_unique_values\": 7374,\n        \"samples\": [\n          84.99034118652344,\n          71.89155578613281,\n          37.65695571899414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dividendYield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4273980204395439,\n        \"min\": -0.12967928200422846,\n        \"max\": 10.695479333796454,\n        \"num_unique_values\": 1621,\n        \"samples\": [\n          0.010571585144499088,\n          0.006206054493393016,\n          0.006610738205341532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payoutRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.809060769071198,\n        \"min\": -137.2,\n        \"max\": 69.87179487179488,\n        \"num_unique_values\": 1620,\n        \"samples\": [\n          0.4326797385620915,\n          0.22903225806451613,\n          1.2155172413793103\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operatingcashFlowRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69.13180633133469,\n        \"min\": -47.37960607602297,\n        \"max\": 3425.71875,\n        \"num_unique_values\": 1642,\n        \"samples\": [\n          0.22698359558085035,\n          0.1976534296028881,\n          1.6033519553072626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01690240863537172,\n        \"min\": -0.12562852548559178,\n        \"max\": 0.12479081998565623,\n        \"num_unique_values\": 1642,\n        \"samples\": [\n          0.011711649588806062,\n          0.005124548816897643,\n          0.0024758539761956955\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"netProfitMargin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64.06583183473573,\n        \"min\": -0.7548060833674191,\n        \"max\": 2877.0,\n        \"num_unique_values\": 1641,\n        \"samples\": [\n          0.1750841750841751,\n          0.11206611094314632,\n          0.1455392809587217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8247919562824859,\n        \"min\": 0.05,\n        \"max\": 2.7,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          0.12,\n          2.0,\n          0.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7463582769064567,\n        \"min\": 0.11,\n        \"max\": 2.93,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          0.97,\n          0.69,\n          1.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cov_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "rl_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8db1a8bc-328c-40fb-bebb-686c124220cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>close</th>\n",
              "      <th>dividendYield</th>\n",
              "      <th>payoutRatio</th>\n",
              "      <th>operatingcashFlowRatio</th>\n",
              "      <th>ROA</th>\n",
              "      <th>netProfitMargin</th>\n",
              "      <th>1 Yr</th>\n",
              "      <th>3 Yr</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ABT</td>\n",
              "      <td>19.29</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ADM</td>\n",
              "      <td>21.52</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.27</td>\n",
              "      <td>2.19</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ADP</td>\n",
              "      <td>34.43</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>AFL</td>\n",
              "      <td>17.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.46</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-06-30</td>\n",
              "      <td>ALB</td>\n",
              "      <td>57.81</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.81</td>\n",
              "      <td>[[0.002305626314804774, 0.001835166014818884, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>TGT</td>\n",
              "      <td>226.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.46</td>\n",
              "      <td>[[0.0028717702094912716, 1.2472444194352184e-0...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>TROW</td>\n",
              "      <td>177.79</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.46</td>\n",
              "      <td>[[0.0028717702094912716, 1.2472444194352184e-0...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>WMT</td>\n",
              "      <td>45.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.46</td>\n",
              "      <td>[[0.0028717702094912716, 1.2472444194352184e-0...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>WST</td>\n",
              "      <td>356.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.46</td>\n",
              "      <td>[[0.0028717702094912716, 1.2472444194352184e-0...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>2021-06-30</td>\n",
              "      <td>XOM</td>\n",
              "      <td>56.50</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.46</td>\n",
              "      <td>[[0.0028717702094912716, 1.2472444194352184e-0...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7381 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8db1a8bc-328c-40fb-bebb-686c124220cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8db1a8bc-328c-40fb-bebb-686c124220cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8db1a8bc-328c-40fb-bebb-686c124220cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7965ec97-70f5-4fcf-b634-d26b274face5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7965ec97-70f5-4fcf-b634-d26b274face5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7965ec97-70f5-4fcf-b634-d26b274face5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a3e81fef-b775-47f5-9128-2f1fd1cef3ec\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rl_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a3e81fef-b775-47f5-9128-2f1fd1cef3ec button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rl_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Date Ticker  close  dividendYield  payoutRatio  \\\n",
              "0   2011-06-30    ABT  19.29           0.02         0.39   \n",
              "0   2011-06-30    ADM  21.52           0.01         0.27   \n",
              "0   2011-06-30    ADP  34.43           0.01         0.74   \n",
              "0   2011-06-30    AFL  17.00           0.02         0.46   \n",
              "0   2011-06-30    ALB  57.81           0.00         0.13   \n",
              "..         ...    ...    ...            ...          ...   \n",
              "120 2021-06-30    TGT 226.08           0.00         0.16   \n",
              "120 2021-06-30   TROW 177.79           0.01         0.31   \n",
              "120 2021-06-30    WMT  45.08           0.01         0.57   \n",
              "120 2021-06-30    WST 356.70           0.00         0.07   \n",
              "120 2021-06-30    XOM  56.50           0.02         0.81   \n",
              "\n",
              "     operatingcashFlowRatio  ROA  netProfitMargin  1 Yr  3 Yr  \\\n",
              "0                      0.88 0.03             0.20  0.19  0.81   \n",
              "0                      2.19 0.01             0.02  0.19  0.81   \n",
              "0                      0.49 0.01             0.10  0.19  0.81   \n",
              "0                     -0.85 0.00             0.05  0.19  0.81   \n",
              "0                      0.59 0.03             0.16  0.19  0.81   \n",
              "..                      ...  ...              ...   ...   ...   \n",
              "120                    0.06 0.04             0.09  0.07  0.46   \n",
              "120                    0.67 0.07             0.42  0.07  0.46   \n",
              "120                    0.08 0.01             0.02  0.07  0.46   \n",
              "120                    0.65 0.06             0.26  0.07  0.46   \n",
              "120                    0.15 0.01             0.07  0.07  0.46   \n",
              "\n",
              "                                              cov_list  \\\n",
              "0    [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "0    [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "0    [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "0    [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "0    [[0.002305626314804774, 0.001835166014818884, ...   \n",
              "..                                                 ...   \n",
              "120  [[0.0028717702094912716, 1.2472444194352184e-0...   \n",
              "120  [[0.0028717702094912716, 1.2472444194352184e-0...   \n",
              "120  [[0.0028717702094912716, 1.2472444194352184e-0...   \n",
              "120  [[0.0028717702094912716, 1.2472444194352184e-0...   \n",
              "120  [[0.0028717702094912716, 1.2472444194352184e-0...   \n",
              "\n",
              "                                           return_list  \n",
              "0    Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0    Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0    Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0    Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0    Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "..                                                 ...  \n",
              "120  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "120  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "120  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "120  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "120  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "\n",
              "[7381 rows x 12 columns]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rl_train = rl_df.set_index('Date')\n",
        "# rl_train = rl_train.loc[:train_end_date, :]\n",
        "rl_train = rl_train.loc[:trainval_date_index[-1], :]\n",
        "rl_train = rl_train.reset_index()\n",
        "rl_train.index = rl_train.Date.factorize()[0]\n",
        "rl_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIWtiNYmYXfN"
      },
      "outputs": [],
      "source": [
        "# rl_df.to_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/rl_df.csv\", index=False)\n",
        "# rl_train.to_csv(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/rl_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkdKtHIvC27j"
      },
      "outputs": [],
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A single stock trading environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then\n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax, # max number of shares to trade\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=12,\n",
        "                day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct = transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        # Shape = (34, 30)\n",
        "        # covariance matrix + technical indicators\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.Date.unique()[0]]\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['monthly_return']\n",
        "            plt.plot(df.monthly_return.cumsum(),'r')\n",
        "            plt.savefig(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/results/cumulative_reward.png\")\n",
        "            plt.close()\n",
        "\n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/results/rewards.png\")\n",
        "            plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_monthly_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_monthly_return.columns = ['monthly_return']\n",
        "            if df_monthly_return['monthly_return'].std() !=0:\n",
        "              sharpe = (12**0.5)*df_monthly_return['monthly_return'].mean()/ \\\n",
        "                       df_monthly_return['monthly_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            #print(\"Model actions: \",actions)\n",
        "            # actions are the portfolio weight\n",
        "            # normalize to sum of 1\n",
        "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "            #else:\n",
        "            #  norm_actions = actions\n",
        "            weights = self.softmax_normalization(actions)\n",
        "            #print(\"Normalized actions: \", weights)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            #print(self.state)\n",
        "            # calcualte portfolio return\n",
        "            # individual stocks' return * weight\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            # update portfolio value\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.Date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value\n",
        "            #print(\"Step reward: \", self.reward)\n",
        "            #self.reward = self.reward*self.reward_scaling\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.Date.unique()[0]]\n",
        "\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['Date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.Date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB2teSnOC7SS",
        "outputId": "a5810a53-bb77-4d7a-cf8e-6e6740784f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 61, State Space: 61\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(rl_train.Ticker.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X361eAOuC_Sb"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": rl_train.columns[3:10],\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "\n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = rl_train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp7cXnR3DDWw",
        "outputId": "201a9c35-4247-4aca-de14-bd6620de4668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2Buh_1rAv1E"
      },
      "source": [
        "## Use Different Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z75zV7vUA1EL",
        "outputId": "ac68dec5-35c6-49df-9039-46c4906a7ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
        "\n",
        "# this can be done for other agents plus custom agents as well\n",
        "# custom will be important depending upon how we try new things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ichf04ESDPLN",
        "outputId": "4fe5868b-3102-44cb-b314-80293f74ef83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4227.864014317276\n",
            "Sharpe:  1.1988363661466321\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4333.814712485309\n",
            "Sharpe:  1.2124922034013181\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4180.469792782893\n",
            "Sharpe:  1.1837825805127273\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4375.426645054914\n",
            "Sharpe:  1.2240227379592885\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 110       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.4     |\n",
            "|    explained_variance | -1.63e-05 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 2.81e+05  |\n",
            "|    reward             | 1168.5149 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 1.29e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4221.885762601076\n",
            "Sharpe:  1.1933078830739452\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4253.960851699557\n",
            "Sharpe:  1.1750110804537057\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4284.528521806502\n",
            "Sharpe:  1.2009807613586083\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4209.237488149195\n",
            "Sharpe:  1.1778096353062053\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 109       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.4     |\n",
            "|    explained_variance | -5.72e-06 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 3.66e+05  |\n",
            "|    reward             | 1543.0566 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 2.05e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4115.403750201234\n",
            "Sharpe:  1.1678410043196028\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4387.645801076708\n",
            "Sharpe:  1.2247312365574916\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4247.4725392161445\n",
            "Sharpe:  1.1857137159176443\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:3977.9625586220127\n",
            "Sharpe:  1.1371132850476264\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 119       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.4     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 4.5e+05   |\n",
            "|    reward             | 1754.2206 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 3.17e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4345.4287927753685\n",
            "Sharpe:  1.1995550525666323\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4119.640345821155\n",
            "Sharpe:  1.154192583577899\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4221.3639572727925\n",
            "Sharpe:  1.1856166325314152\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4084.857349292923\n",
            "Sharpe:  1.1700712921107819\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 124       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | -1.67e-06 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 4.84e+05  |\n",
            "|    reward             | 1982.8214 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 3.97e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4119.195733660458\n",
            "Sharpe:  1.178895129131352\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4102.547306823009\n",
            "Sharpe:  1.187322805201634\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4041.613568233045\n",
            "Sharpe:  1.1555637446299454\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:3984.2228588411394\n",
            "Sharpe:  1.1402612221328785\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 121       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 6.13e+05  |\n",
            "|    reward             | 2525.1956 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 5.76e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4352.685445682114\n",
            "Sharpe:  1.2013891188416048\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4134.025527388073\n",
            "Sharpe:  1.1644566421854585\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4187.72305411355\n",
            "Sharpe:  1.186130629491022\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4196.897329263848\n",
            "Sharpe:  1.1744069305060487\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 122       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 6.65e+05  |\n",
            "|    reward             | 2968.9111 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 7.4e+07   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4252.257139104149\n",
            "Sharpe:  1.1892255998718861\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4235.725516968951\n",
            "Sharpe:  1.1981138799277715\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4099.056874744463\n",
            "Sharpe:  1.1683994487624856\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4097.176280014759\n",
            "Sharpe:  1.1529773581989635\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 125       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | 3.93e-06  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 7.1e+05   |\n",
            "|    reward             | 3131.4385 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 8.42e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4042.7876988827393\n",
            "Sharpe:  1.1408736096110497\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4357.532040775237\n",
            "Sharpe:  1.1989564539968873\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4095.653122397773\n",
            "Sharpe:  1.1667927855939833\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4240.381875993549\n",
            "Sharpe:  1.207079369842844\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4195.078727402282\n",
            "Sharpe:  1.190897878698907\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 125       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | 5.36e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 5.24e+05  |\n",
            "|    reward             | 1041.7659 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 4.94e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4190.74280994582\n",
            "Sharpe:  1.1803173146179204\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4130.598494065997\n",
            "Sharpe:  1.1746803624318616\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4172.721930287015\n",
            "Sharpe:  1.1762423429840272\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4313.511616331487\n",
            "Sharpe:  1.20055555672163\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 123       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 2.96e+05  |\n",
            "|    reward             | 1344.012  |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 1.42e+07  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4098.223136182516\n",
            "Sharpe:  1.15493263027392\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4111.509216617106\n",
            "Sharpe:  1.150405412848056\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4256.61934706273\n",
            "Sharpe:  1.1989301916115345\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:4037.3966342983067\n",
            "Sharpe:  1.1462221391473446\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 125       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -86.3     |\n",
            "|    explained_variance | -1.14e-05 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 4.04e+05  |\n",
            "|    reward             | 1607.8029 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 2.49e+07  |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c,\n",
        "                                tb_log_name='a2c',\n",
        "                                total_timesteps=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0drIcItDSnD"
      },
      "outputs": [],
      "source": [
        "trained_a2c.save(\"/content/drive/My Drive/WQU_Capstone/Capstone Project/data/RL/trained_models/trained_a2c.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UdCifUph84x"
      },
      "source": [
        "## Backtest RL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PhAm1Bt3h7zN",
        "outputId": "e5f8258e-320b-4295-cca0-120d246f1be9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"rl_test\",\n  \"rows\": 1464,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-07-31 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"2022-03-31 00:00:00\",\n          \"2022-11-30 00:00:00\",\n          \"2021-07-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"ABT\",\n          \"AOS\",\n          \"PEP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.23352214397788,\n        \"min\": 20.092256546020508,\n        \"max\": 783.1229248046875,\n        \"num_unique_values\": 1461,\n        \"samples\": [\n          181.18771362304688,\n          29.46796989440918,\n          61.5048713684082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dividendYield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0042464967606990174,\n        \"min\": -0.010990081383170012,\n        \"max\": 0.029309617644359555,\n        \"num_unique_values\": 487,\n        \"samples\": [\n          0.0016893594782670322,\n          0.004516673362956814,\n          0.0016785034862193983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payoutRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.7633380313246265,\n        \"min\": -43.26470588235294,\n        \"max\": 91.85325414501361,\n        \"num_unique_values\": 487,\n        \"samples\": [\n          0.17759562841530055,\n          0.4103072348860258,\n          0.17121848739495799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operatingcashFlowRatio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.904787807770155,\n        \"min\": -37.888888888888886,\n        \"max\": 5.011167828132629,\n        \"num_unique_values\": 488,\n        \"samples\": [\n          0.3223595837283181,\n          0.8230874316939891,\n          0.7177804295942721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018469339388228277,\n        \"min\": -0.040069639926891415,\n        \"max\": 0.21171303737577252,\n        \"num_unique_values\": 488,\n        \"samples\": [\n          0.015203755244464753,\n          0.02719603245195547,\n          0.026616947409026617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"netProfitMargin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14702798919844945,\n        \"min\": -0.9975609756097561,\n        \"max\": 2.383282364933741,\n        \"num_unique_values\": 488,\n        \"samples\": [\n          0.19005582240685448,\n          0.1813932584269663,\n          0.08957161401990481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9640742267930456,\n        \"min\": 0.07,\n        \"max\": 5.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          4.74,\n          2.08,\n          0.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3 Yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4636577028257802,\n        \"min\": 0.35,\n        \"max\": 4.51,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          2.45,\n          4.13,\n          0.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cov_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "rl_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b9ec7889-6cc0-455d-a12e-23abe9b5ed93\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>tic</th>\n",
              "      <th>close</th>\n",
              "      <th>dividendYield</th>\n",
              "      <th>payoutRatio</th>\n",
              "      <th>operatingcashFlowRatio</th>\n",
              "      <th>ROA</th>\n",
              "      <th>netProfitMargin</th>\n",
              "      <th>1 Yr</th>\n",
              "      <th>3 Yr</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-31</td>\n",
              "      <td>ABT</td>\n",
              "      <td>115.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "      <td>[[0.0026583283744045093, -0.000188816209082187...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-31</td>\n",
              "      <td>ADM</td>\n",
              "      <td>56.10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "      <td>[[0.0026583283744045093, -0.000188816209082187...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-31</td>\n",
              "      <td>ADP</td>\n",
              "      <td>198.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "      <td>[[0.0026583283744045093, -0.000188816209082187...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-31</td>\n",
              "      <td>AFL</td>\n",
              "      <td>51.45</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "      <td>[[0.0026583283744045093, -0.000188816209082187...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-31</td>\n",
              "      <td>ALB</td>\n",
              "      <td>201.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "      <td>[[0.0026583283744045093, -0.000188816209082187...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>TGT</td>\n",
              "      <td>128.49</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>TROW</td>\n",
              "      <td>108.30</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.30</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>WMT</td>\n",
              "      <td>51.84</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>WST</td>\n",
              "      <td>381.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.21</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>XOM</td>\n",
              "      <td>104.44</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>5.40</td>\n",
              "      <td>4.49</td>\n",
              "      <td>[[0.003941050224425369, 0.002496377560835761, ...</td>\n",
              "      <td>Ticker       ABT   ADM   ADP   AFL   ALB   AOS...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1464 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9ec7889-6cc0-455d-a12e-23abe9b5ed93')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9ec7889-6cc0-455d-a12e-23abe9b5ed93 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9ec7889-6cc0-455d-a12e-23abe9b5ed93');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-890efa23-de1f-4451-88c8-ecc01ea8ce02\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-890efa23-de1f-4451-88c8-ecc01ea8ce02')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-890efa23-de1f-4451-88c8-ecc01ea8ce02 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_57ef1c3b-7a27-40de-b40f-72cea314e83d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rl_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_57ef1c3b-7a27-40de-b40f-72cea314e83d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rl_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Date   tic  close  dividendYield  payoutRatio  \\\n",
              "0  2021-07-31   ABT 115.07           0.00         0.68   \n",
              "0  2021-07-31   ADM  56.10           0.01         0.29   \n",
              "0  2021-07-31   ADP 198.20           0.00         0.74   \n",
              "0  2021-07-31   AFL  51.45           0.01         0.19   \n",
              "0  2021-07-31   ALB 201.63           0.00         0.15   \n",
              "..        ...   ...    ...            ...          ...   \n",
              "23 2023-06-30   TGT 128.49           0.01         0.52   \n",
              "23 2023-06-30  TROW 108.30           0.01         0.59   \n",
              "23 2023-06-30   WMT  51.84           0.01         0.92   \n",
              "23 2023-06-30   WST 381.64           0.00         0.09   \n",
              "23 2023-06-30   XOM 104.44           0.01         0.49   \n",
              "\n",
              "    operatingcashFlowRatio  ROA  netProfitMargin  1 Yr  3 Yr  \\\n",
              "0                     0.88 0.02             0.12  0.07  0.35   \n",
              "0                     1.85 0.01             0.03  0.07  0.35   \n",
              "0                     1.41 0.01             0.14  0.07  0.35   \n",
              "0                    -1.06 0.01             0.20  0.07  0.35   \n",
              "0                     0.92 0.04             0.55  0.07  0.35   \n",
              "..                     ...  ...              ...   ...   ...   \n",
              "23                    1.07 0.02             0.04  5.40  4.49   \n",
              "23                    0.49 0.04             0.30  5.40  4.49   \n",
              "23                    0.13 0.01             0.01  5.40  4.49   \n",
              "23                    0.86 0.04             0.21  5.40  4.49   \n",
              "23                    0.12 0.02             0.10  5.40  4.49   \n",
              "\n",
              "                                             cov_list  \\\n",
              "0   [[0.0026583283744045093, -0.000188816209082187...   \n",
              "0   [[0.0026583283744045093, -0.000188816209082187...   \n",
              "0   [[0.0026583283744045093, -0.000188816209082187...   \n",
              "0   [[0.0026583283744045093, -0.000188816209082187...   \n",
              "0   [[0.0026583283744045093, -0.000188816209082187...   \n",
              "..                                                ...   \n",
              "23  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "23  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "23  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "23  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "23  [[0.003941050224425369, 0.002496377560835761, ...   \n",
              "\n",
              "                                          return_list  \n",
              "0   Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0   Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0   Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0   Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "0   Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "..                                                ...  \n",
              "23  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "23  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "23  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "23  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "23  Ticker       ABT   ADM   ADP   AFL   ALB   AOS...  \n",
              "\n",
              "[1464 rows x 12 columns]"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rl_test = rl_df.set_index('Date')\n",
        "rl_test = rl_test.loc[test_date_index[0]:, :]\n",
        "rl_test = rl_test.reset_index()\n",
        "rl_test.index = rl_test.Date.factorize()[0]\n",
        "rl_test = rl_test.rename(columns={'Ticker':'tic'})\n",
        "rl_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql_FduJXh6WV"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockPortfolioEnv(df = rl_test, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGvUS3VfDUaz",
        "outputId": "fb9a14d8-2184-423f-89d2-b484b27af4ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000\n",
            "end_total_asset:1121.9001514455024\n",
            "Sharpe:  0.3980663176077524\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "df_monthly_return, df_actions = DRLAgent.DRL_prediction(model=trained_a2c, environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M3pzvbgoj-J4",
        "outputId": "50b15897-5d8d-483a-e5f3-6d6dad5cdfbd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_monthly_return\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-07-31 00:00:00\",\n        \"max\": \"2023-06-30 00:00:00\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"2022-03-31 00:00:00\",\n          \"2022-11-30 00:00:00\",\n          \"2021-07-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05372745134645685,\n        \"min\": -0.09202320395260846,\n        \"max\": 0.10292758778141921,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.04020467685091259,\n          0.06955359452119675,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_monthly_return"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0cc02157-4082-47ea-9fd1-162893208d2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-07-31</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-10-31</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-11-30</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cc02157-4082-47ea-9fd1-162893208d2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cc02157-4082-47ea-9fd1-162893208d2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cc02157-4082-47ea-9fd1-162893208d2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-591037b1-843b-4c47-9447-a7f02a2c4627\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-591037b1-843b-4c47-9447-a7f02a2c4627')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-591037b1-843b-4c47-9447-a7f02a2c4627 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        date  daily_return\n",
              "0 2021-07-31          0.00\n",
              "1 2021-08-31          0.02\n",
              "2 2021-09-30         -0.05\n",
              "3 2021-10-31          0.07\n",
              "4 2021-11-30         -0.01"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_monthly_return.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "43OHN0G5kFJQ",
        "outputId": "7b1cc971-c91c-4d1a-ea90-6ca0d62f649e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_actions"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-66f41ea9-0f15-4ae7-9e48-d004f72d96a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-07-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66f41ea9-0f15-4ae7-9e48-d004f72d96a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66f41ea9-0f15-4ae7-9e48-d004f72d96a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66f41ea9-0f15-4ae7-9e48-d004f72d96a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64e43346-e022-4bb9-85b5-aaff80723741\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64e43346-e022-4bb9-85b5-aaff80723741')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64e43346-e022-4bb9-85b5-aaff80723741 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  \\\n",
              "Date                                                          ...             \n",
              "2021-07-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-08-31 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-09-30 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02  ... 0.02 0.02   \n",
              "2021-10-31 0.02 0.02 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "2021-11-30 0.02 0.02 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "\n",
              "            SPGI  SWK  SYY  TGT  TROW  WMT  WST  XOM  \n",
              "Date                                                  \n",
              "2021-07-31  0.02 0.02 0.02 0.02  0.02 0.02 0.02 0.02  \n",
              "2021-08-31  0.02 0.02 0.02 0.02  0.02 0.02 0.02 0.02  \n",
              "2021-09-30  0.02 0.02 0.02 0.02  0.02 0.02 0.02 0.02  \n",
              "2021-10-31  0.02 0.01 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "2021-11-30  0.02 0.01 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_actions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "EwzxU9IAkHpc",
        "outputId": "fa68ef73-a83c-4b8a-8141-24597e3e3282"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-caf55e7e-6cac-4645-8570-b82adde9c9d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABT</th>\n",
              "      <th>ADM</th>\n",
              "      <th>ADP</th>\n",
              "      <th>AFL</th>\n",
              "      <th>ALB</th>\n",
              "      <th>AOS</th>\n",
              "      <th>APD</th>\n",
              "      <th>ATO</th>\n",
              "      <th>BDX</th>\n",
              "      <th>BEN</th>\n",
              "      <th>...</th>\n",
              "      <th>SHW</th>\n",
              "      <th>SJM</th>\n",
              "      <th>SPGI</th>\n",
              "      <th>SWK</th>\n",
              "      <th>SYY</th>\n",
              "      <th>TGT</th>\n",
              "      <th>TROW</th>\n",
              "      <th>WMT</th>\n",
              "      <th>WST</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-28</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caf55e7e-6cac-4645-8570-b82adde9c9d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-caf55e7e-6cac-4645-8570-b82adde9c9d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-caf55e7e-6cac-4645-8570-b82adde9c9d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3857e740-ed2f-4d06-96ed-5c974095cbc7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3857e740-ed2f-4d06-96ed-5c974095cbc7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3857e740-ed2f-4d06-96ed-5c974095cbc7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            ABT  ADM  ADP  AFL  ALB  AOS  APD  ATO  BDX  BEN  ...  SHW  SJM  \\\n",
              "Date                                                          ...             \n",
              "2023-02-28 0.02 0.01 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "2023-03-31 0.02 0.01 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "2023-04-30 0.02 0.01 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "2023-05-31 0.02 0.01 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "2023-06-30 0.02 0.01 0.01 0.02 0.02 0.01 0.01 0.01 0.01 0.01  ... 0.02 0.01   \n",
              "\n",
              "            SPGI  SWK  SYY  TGT  TROW  WMT  WST  XOM  \n",
              "Date                                                  \n",
              "2023-02-28  0.02 0.02 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "2023-03-31  0.02 0.02 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "2023-04-30  0.02 0.02 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "2023-05-31  0.02 0.02 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "2023-06-30  0.02 0.02 0.01 0.02  0.01 0.01 0.01 0.02  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_actions.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz1P0pxCkfVp",
        "outputId": "dc5f9dcb-9df3-45d8-8374-ed8a4006242d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-116-79e3448a91eb>:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  totalReturn = portfolio_value[-1] / portfolio_value[0] - 1\n",
            "<ipython-input-116-79e3448a91eb>:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  annualReturn = ((portfolio_value[-1] / portfolio_value[0]) ** (1 / years)) - 1\n"
          ]
        }
      ],
      "source": [
        "rl_rets, rl_metrics = perform_backtest(prices=data_m, model_preds=[df_actions])\n",
        "rl_rets = rl_rets[0].replace(np.inf, np.nan).dropna()\n",
        "rl_rets.columns = ['RL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrEeifSrkxJN",
        "outputId": "376b3a8c-52b9-4eac-d34c-a5877f6aae00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date\n",
              "2021-08-31    0.02\n",
              "2021-09-30   -0.05\n",
              "2021-10-31    0.08\n",
              "2021-11-30   -0.01\n",
              "2021-12-31    0.06\n",
              "Freq: ME, dtype: float64"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rl_rets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xwlxFZQbk_3a",
        "outputId": "f8ad4f59-c546-4b39-8f7a-b1e4432ca6ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"rl_metrics\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"NN0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1911172772297539,\n        \"min\": -0.19867693221642913,\n        \"max\": 0.3092566345068716,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.04205214140865432,\n          -0.19867693221642913,\n          0.3092566345068716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "rl_metrics"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b42555a1-3455-49fa-a25f-4417c2c1ceaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NN0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>totalReturn</th>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annualReturn</th>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sharpeRatio</th>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volatility</th>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxDrawdown</th>\n",
              "      <td>-0.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b42555a1-3455-49fa-a25f-4417c2c1ceaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b42555a1-3455-49fa-a25f-4417c2c1ceaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b42555a1-3455-49fa-a25f-4417c2c1ceaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56627dd4-b3b3-4a2a-8d6b-89c29cf46a31\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56627dd4-b3b3-4a2a-8d6b-89c29cf46a31')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56627dd4-b3b3-4a2a-8d6b-89c29cf46a31 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_70c42b7a-009a-48f0-9cb0-bc05e0a3e902\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rl_metrics')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_70c42b7a-009a-48f0-9cb0-bc05e0a3e902 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rl_metrics');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               NN0\n",
              "totalReturn   0.09\n",
              "annualReturn  0.04\n",
              "sharpeRatio   0.31\n",
              "volatility    0.20\n",
              "maxDrawdown  -0.20"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rl_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mFyGRnDaHzhW",
        "outputId": "de30b2ce-f243-47f0-cf5b-ead06c6a7e45"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wealth_index = 1000*(1+pd.DataFrame(rl_rets, columns=['RL'])).cumprod()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for column in wealth_index.columns:\n",
        "    plt.plot(wealth_index.index, wealth_index[column], label=column)\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Wealth Index')\n",
        "plt.title('Wealth Index Over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfNOm8YcDVBm"
      },
      "source": [
        "# Compare Results from RL vs. NNs vs. MVO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi4fdMgtDYq1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "POAQOHApyT_i"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
