{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-4R_ONVwTh5",
        "outputId": "0b03d071-9da5-4f5f-8771-e964713b8b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4zHsL1YwrKe"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "# matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import requests\n",
        "import json\n",
        "import random\n",
        "import cvxpy\n",
        "# from cvxpy import *\n",
        "import gym\n",
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, SimpleRNN, Dense, Dropout\n",
        "from dateutil.relativedelta import relativedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rOxCtF_72UT"
      },
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf9U80H2xKCm"
      },
      "source": [
        "# Neural Nets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwdo48-yxAWa"
      },
      "outputs": [],
      "source": [
        "class PortfolioModelTrainer:\n",
        "    def __init__(self, model_type, asset_num, input_shape, param_grid, timestamp, wts=None):\n",
        "        self.model_type = model_type\n",
        "        self.model = None\n",
        "        self.asset_num = asset_num\n",
        "        self.input_shape = input_shape\n",
        "        self.param_grid = param_grid\n",
        "        self.best_params = None\n",
        "        self.best_score = np.inf\n",
        "        self.wts = wts\n",
        "        self.timestamp = timestamp\n",
        "\n",
        "    # custom loss function for gradient ascent Sharpe Ratio\n",
        "    def negative_sharpe_loss(self, rets, wts):\n",
        "\n",
        "        mean_return = tf.reduce_mean(tf.reduce_sum(wts * rets, axis=1))\n",
        "        std_return = tf.math.reduce_std(tf.reduce_sum(wts * rets, axis=1))\n",
        "        if std_return != 0.0:\n",
        "          return -mean_return / std_return\n",
        "        else:\n",
        "          return 0.0\n",
        "\n",
        "    def build_model(self, params):\n",
        "        self.model = Sequential()\n",
        "\n",
        "        if self.model_type == \"CNN\":\n",
        "\n",
        "          self.model.add(Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation=params['activation'], input_shape=self.input_shape))\n",
        "          self.model.add(MaxPooling1D(pool_size=2))\n",
        "          self.model.add(Flatten())\n",
        "          self.model.add(Dropout(params['dropout_rate']))\n",
        "          self.model.add(Dense(params['dense_units'], activation=params['activation']))\n",
        "\n",
        "        elif self.model_type == \"RNN\":\n",
        "           self.model.add(SimpleRNN(params['input_layer_size'], input_shape=self.input_shape))\n",
        "           self.model.add(Dropout(params['dropout_rate']))\n",
        "\n",
        "        elif self.model_type == \"MLP\":\n",
        "\n",
        "          for i in range(params['num_hidden_layers']):\n",
        "            if i==0:\n",
        "              self.model.add(Dense(units=params['hidden_layer_sizes'], activation=params['activation'], input_shape=self.input_shape))\n",
        "            else:\n",
        "              self.model.add(Dense(units=params['hidden_layer_sizes'], activation=params['activation']))\n",
        "\n",
        "            if params['dropout_rate'] > 0.0:\n",
        "              self.model.add(Dropout(params['dropout_rate']))\n",
        "\n",
        "        else:\n",
        "           raise ValueError(\"Invalid model type. Supported types: 'CNN', 'RNN', 'MLP'\")\n",
        "\n",
        "        self.model.add(Dense(units=self.asset_num, activation=\"softmax\")) # <- softmax creates long-only portfolios\n",
        "\n",
        "        optimizer_instance = tf.keras.optimizers.get(params['optimizer'])\n",
        "        optimizer_instance.learning_rate = params['learning_rate']\n",
        "\n",
        "        self.model.compile(optimizer=optimizer_instance, loss=self.negative_sharpe_loss)\n",
        "\n",
        "    def walk_forward_train(self, n_train, n_val, df, batch, params, idx):\n",
        "        n_splits = (df.shape[0] - n_train) // n_val + 1\n",
        "        avg_score = 0.0\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        if not os.path.exists(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/preds/{timestamp}/{self.model_type}/\"):\n",
        "            os.makedirs(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/preds/{timestamp}/{self.model_type}/\")\n",
        "\n",
        "        with open(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/preds/{timestamp}/{self.model_type}/param_mapping.txt\", \"a\") as f:\n",
        "            if idx == 0:\n",
        "              f.write(self.model_type)\n",
        "              f.write('\\n')\n",
        "            f.write(f'{idx}: {str(params)}\\n')\n",
        "\n",
        "        for i in range(0, df.shape[0] - n_train, n_val):\n",
        "\n",
        "            if params['window_type'] == 'fix':\n",
        "\n",
        "                X_train, y_train = df.iloc[i : i + n_train, :-self.asset_num], df.iloc[i : i + n_train, -self.asset_num:]\n",
        "                X_val, y_val = df.iloc[i + n_train : i + n_train + n_val, :-self.asset_num], df.iloc[i + n_train : i + n_train + n_val, -self.asset_num:]\n",
        "\n",
        "            elif params['window_type'] == 'exp':\n",
        "                X_train, y_train = df.iloc[: i + n_train, :-self.asset_num], df.iloc[: i + n_train, -self.asset_num:]\n",
        "                X_val, y_val = df.iloc[i + n_train : i + n_train + n_val, :-self.asset_num], df.iloc[i + n_train : i + n_train + n_val, -self.asset_num:]\n",
        "\n",
        "            # Define EarlyStopping callback\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "            history = self.model.fit(\n",
        "                X_train,\n",
        "                y_train,\n",
        "                epochs=params['epochs'],\n",
        "                batch_size=batch,\n",
        "                validation_data = (X_val, y_val),\n",
        "                callbacks=[early_stopping],\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            y_pred = self.model.predict(X_val, verbose=0)\n",
        "            preds.append(y_pred)\n",
        "            pd.DataFrame(y_pred).to_csv(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/preds/{timestamp}/{self.model_type}/y_pred_{i}_params{idx}.csv\")\n",
        "\n",
        "            y_val.to_csv(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/preds/{timestamp}/{self.model_type}/y_val_{i}_params{idx}.csv\")\n",
        "\n",
        "            score = self.model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "            avg_score += score / n_splits\n",
        "\n",
        "        return preds, avg_score\n",
        "\n",
        "    def grid_search(self, n_train, n_val, df, batch):\n",
        "       total_combos = len(ParameterGrid(self.param_grid))\n",
        "\n",
        "       for idx, params in enumerate(ParameterGrid(self.param_grid)):\n",
        "            print(f'Only {total_combos} left!!')\n",
        "            print('Testing parameters: ', params)\n",
        "            # time.sleep(1)\n",
        "\n",
        "            self.build_model(params)\n",
        "\n",
        "            preds, avg_score = self.walk_forward_train(n_train=n_train,\n",
        "                                                      n_val=n_val,\n",
        "                                                      df=df,\n",
        "                                                      batch=batch,\n",
        "                                                      params=params,\n",
        "                                                      idx=idx\n",
        "                                                )\n",
        "\n",
        "            if avg_score < self.best_score:\n",
        "                self.best_score = avg_score\n",
        "                self.best_params = params\n",
        "\n",
        "            total_combos -= 1\n",
        "\n",
        "\n",
        "\n",
        "    def train_optimal(self, df, batch):\n",
        "\n",
        "        # train with best params\n",
        "        self.build_model(self.best_params)\n",
        "\n",
        "        history = self.model.fit(df.iloc[:, :-self.asset_num],\n",
        "                                        df.iloc[:, -self.asset_num:],\n",
        "                                        epochs=self.best_params['epochs'],\n",
        "                                        batch_size=batch,\n",
        "                                        verbose=1)\n",
        "\n",
        "\n",
        "    def evaluate(self, df, date_index, tickers):\n",
        "        y_pred = self.model.predict(df.iloc[:, :-self.asset_num])\n",
        "        self.wts = pd.DataFrame(y_pred, index=date_index, columns=tickers)\n",
        "\n",
        "        return self.wts\n",
        "\n",
        "    def save_model(self, timestamp, model_version):\n",
        "        if not os.path.exists(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/models/{timestamp}/\"):\n",
        "            os.makedirs(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/models/{timestamp}/\")\n",
        "\n",
        "        if not os.path.exists(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/{timestamp}/\"):\n",
        "            os.makedirs(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/{timestamp}/\")\n",
        "\n",
        "        self.model.save(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/models/{timestamp}/{self.model_type}\")\n",
        "\n",
        "        self.wts.to_csv(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/{timestamp}/{self.model_type}_{model_version}_wts.csv\")\n",
        "\n",
        "    def build_benchmark(self, date_index, tickers):\n",
        "        if self.model_type == 'EW':\n",
        "            bench_wts = pd.DataFrame(index = date_index, columns = tickers)\n",
        "            bench_wts[:] = 1 / len(bench_wts.columns)\n",
        "\n",
        "        self.wts = bench_wts\n",
        "\n",
        "        # return bench_wts\n",
        "\n",
        "    def perform_backtest(self, price_data, initial_amount, timestamp, model_version):\n",
        "\n",
        "\n",
        "        ind_rets = price_data.pct_change().dropna()\n",
        "        portfolio_returns = (ind_rets * self.wts.iloc[1:,:]).sum(axis=1)\n",
        "        p_rets = pd.DataFrame({self.model_type: portfolio_returns})\n",
        "\n",
        "        cumulative_rets = (1 + portfolio_returns).cumprod()\n",
        "        wealth_index = initial_amount * cumulative_rets\n",
        "\n",
        "        sharpeRatio = (portfolio_returns.mean() / portfolio_returns.std()) * np.sqrt(12)\n",
        "        totalReturn = wealth_index[-1] / wealth_index[0] - 1\n",
        "        years = len(portfolio_returns) / 12\n",
        "        annualReturn = (wealth_index[-1]/wealth_index[0])**(1 / years) - 1\n",
        "        volatility = portfolio_returns.std() * np.sqrt(12)\n",
        "        maxDrawdown = (cumulative_rets / cumulative_rets.cummax() - 1).min()\n",
        "\n",
        "\n",
        "        p_metrics = pd.DataFrame({f'{self.model_type}':[totalReturn, annualReturn, sharpeRatio, volatility, maxDrawdown]})\n",
        "        p_metrics.index = ['totalReturn', 'annualReturn', 'sharpeRatio', 'volatility', 'maxDrawdown']\n",
        "\n",
        "        return p_metrics, p_rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpQv9BMqyETL"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed_state):\n",
        "    np.random.seed(seed_state)\n",
        "    random.seed(seed_state)\n",
        "    tf.random.set_seed(seed_state)\n",
        "\n",
        "\n",
        "\n",
        "def plot_wealth_index(portfolio_returns, initial_amount, timestamp, model_version):\n",
        "    # need to insert a row of 0s at the beginning so each line starts at the initial amount\n",
        "    first_date = portfolio_returns.index[0]\n",
        "    previous_month_end = first_date - relativedelta(months=1)\n",
        "    new_row_values = [0] * len(portfolio_returns.columns)\n",
        "    portfolio_returns = pd.concat([pd.DataFrame([new_row_values], columns=portfolio_returns.columns, index=[previous_month_end]), portfolio_returns], axis=0)\n",
        "\n",
        "    # now calculate cumulative rets and wealth index\n",
        "    cumulative_rets = (1 + portfolio_returns).cumprod()\n",
        "    wealth_index = initial_amount * cumulative_rets\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for column in wealth_index.columns:\n",
        "        plt.plot(wealth_index.index, wealth_index[column], label=column)\n",
        "\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Wealth Index')\n",
        "    plt.title('Wealth Index Over Time')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.savefig(f'/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/{timestamp}/wealth_index_{model_version}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGK0kegWyL-P"
      },
      "outputs": [],
      "source": [
        "# set seeds\n",
        "set_seeds(seed_state=42)\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiC4yZo_yb_J"
      },
      "outputs": [],
      "source": [
        "# some needed params\n",
        "# trainval_split = 0.85\n",
        "n_train = 24\n",
        "n_val = 6\n",
        "# batch = 50\n",
        "raw_start_date = '2010-04-30'\n",
        "end_date = '2023-12-31'\n",
        "final_start_date = '2010-06-30'\n",
        "asset_num = 61\n",
        "initial_amount = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4brcd5cyhwO"
      },
      "outputs": [],
      "source": [
        "# grid search params\n",
        "# Epoch Changed from 50 to 20 and Hidden layer changed for MLP from 2 to 1\n",
        "param_grids={\n",
        "    'mlp_param_grid': {\n",
        "            'hidden_layer_sizes': [64, 128],\n",
        "            'num_hidden_layers': [2],\n",
        "            'activation': ['relu'],\n",
        "            'optimizer': ['adam',],\n",
        "            'learning_rate': [0.001, 0.01],\n",
        "            'epochs': [50],\n",
        "            'dropout_rate': [0.1, 0.2],\n",
        "            'window_type': ['fix']\n",
        "            },\n",
        "\n",
        "      'cnn_param_grid': {\n",
        "          'filters': [64, 128],\n",
        "          'kernel_size': [5],\n",
        "          'dense_units': [128],\n",
        "          'optimizer': ['adam'],\n",
        "          'learning_rate': [0.001, 0.01],\n",
        "          'activation': ['relu'],\n",
        "          'epochs': [50],\n",
        "          'dropout_rate': [0.1, 0.2],\n",
        "          'window_type': ['fix']\n",
        "          },\n",
        "\n",
        "      'rnn_param_grid': {\n",
        "          'input_layer_size': [64, 128],\n",
        "          'optimizer': ['adam'],\n",
        "          'epochs': [50],\n",
        "          'learning_rate': [0.001, 0.01],\n",
        "          'dropout_rate': [0.1, 0.2],\n",
        "          'window_type': ['fix']\n",
        "          }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OirOw01mytm6"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSpAe2pEyoCj"
      },
      "outputs": [],
      "source": [
        "# load master dataset\n",
        "df_pivot = pd.read_csv('/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/final_dataset.csv', index_col='Date')\n",
        "df_pivot.index = pd.to_datetime(df_pivot.index)\n",
        "ticker_list = [i.split('ret_')[1] for i in df_pivot.columns[-asset_num:]]\n",
        "\n",
        "# let's establish train, validation, and test periods here:\n",
        "trainval_date_index = df_pivot.index[:-n_val]\n",
        "test_date_index = df_pivot.index[-n_val:]\n",
        "\n",
        "# load and prep price data for performance metric calcs later\n",
        "price_data = pd.read_csv('/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/price_data.csv', index_col='Date')\n",
        "price_data.index = pd.to_datetime(price_data.index)\n",
        "price_data = price_data.resample('M').last()\n",
        "\n",
        "test_prices = price_data[price_data.index.isin(test_date_index)]\n",
        "test_prices = test_prices.sort_index()\n",
        "\n",
        "train_prices = price_data[price_data.index.isin(trainval_date_index)]\n",
        "train_prices = train_prices.sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kpy3hVjALIhc",
        "outputId": "8e3534a5-5831-41df-ce31-f00d2670b97f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0    1    2    3    4    5    6    7    8    9  ...  ret_SHW  ret_SJM  \\\n",
              "0   1.21 1.21 1.21 1.21 1.21 1.21 1.21 1.21 1.21 1.21  ...    -0.10     0.09   \n",
              "1   1.30 1.30 1.30 1.30 1.30 1.30 1.30 1.30 1.30 1.30  ...    -0.00     0.02   \n",
              "2   0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70 0.70  ...     0.02    -0.04   \n",
              "3   0.92 0.92 0.92 0.92 0.92 0.92 0.92 0.92 0.92 0.92  ...     0.07     0.03   \n",
              "4   1.31 1.31 1.31 1.31 1.31 1.31 1.31 1.31 1.31 1.31  ...    -0.03     0.06   \n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...      ...   \n",
              "158 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59  ...    -0.02    -0.03   \n",
              "159 2.28 2.28 2.28 2.28 2.28 2.28 2.28 2.28 2.28 2.28  ...    -0.06    -0.16   \n",
              "160 2.68 2.68 2.68 2.68 2.68 2.68 2.68 2.68 2.68 2.68  ...    -0.07    -0.08   \n",
              "161 2.03 2.03 2.03 2.03 2.03 2.03 2.03 2.03 2.03 2.03  ...     0.16    -0.03   \n",
              "162 1.37 1.37 1.37 1.37 1.37 1.37 1.37 1.37 1.37 1.37  ...     0.11     0.14   \n",
              "\n",
              "     ret_SPGI  ret_SWK  ret_SYY  ret_TGT  ret_TROW  ret_WMT  ret_WST  ret_XOM  \n",
              "0        0.01    -0.10    -0.03    -0.10     -0.10    -0.05    -0.08    -0.06  \n",
              "1        0.09     0.14     0.08     0.04      0.08     0.06     0.00     0.04  \n",
              "2       -0.10    -0.08    -0.12     0.00     -0.10    -0.01    -0.08    -0.00  \n",
              "3        0.18     0.14     0.05     0.04      0.14     0.07     0.02     0.04  \n",
              "4        0.13     0.01     0.03    -0.03      0.10     0.01     0.04     0.07  \n",
              "..        ...      ...      ...      ...       ...      ...      ...      ...  \n",
              "158     -0.01    -0.05    -0.09    -0.07     -0.09     0.02     0.10     0.04  \n",
              "159     -0.07    -0.11    -0.05    -0.13     -0.06    -0.02    -0.08     0.06  \n",
              "160     -0.05     0.02     0.01     0.00     -0.15     0.02    -0.16    -0.11  \n",
              "161      0.18     0.08     0.08     0.20      0.10    -0.05     0.10    -0.02  \n",
              "162      0.06     0.08     0.01     0.06      0.08     0.02     0.00    -0.03  \n",
              "\n",
              "[163 rows x 488 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1348310-fc2b-4770-b42d-be2542c1e9cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>ret_SHW</th>\n",
              "      <th>ret_SJM</th>\n",
              "      <th>ret_SPGI</th>\n",
              "      <th>ret_SWK</th>\n",
              "      <th>ret_SYY</th>\n",
              "      <th>ret_TGT</th>\n",
              "      <th>ret_TROW</th>\n",
              "      <th>ret_WMT</th>\n",
              "      <th>ret_WST</th>\n",
              "      <th>ret_XOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>...</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.31</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.59</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>2.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.37</td>\n",
              "      <td>...</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>163 rows × 488 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1348310-fc2b-4770-b42d-be2542c1e9cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1348310-fc2b-4770-b42d-be2542c1e9cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1348310-fc2b-4770-b42d-be2542c1e9cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f9a201c-98ed-466a-88af-60a30bf484a4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f9a201c-98ed-466a-88af-60a30bf484a4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f9a201c-98ed-466a-88af-60a30bf484a4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_daccc4d4-a914-44d4-9eec-2b5414ee8419\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('scaled_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_daccc4d4-a914-44d4-9eec-2b5414ee8419 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('scaled_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "scaled_dataset"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_features = pd.DataFrame(scaler.fit_transform(df_pivot.iloc[:, :-61]))\n",
        "unscaled_rets = df_pivot.iloc[:, -61:].reset_index(drop=True)\n",
        "scaled_dataset = pd.concat([scaled_features, unscaled_rets], axis=1)\n",
        "scaled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2t9lsitMbzw"
      },
      "outputs": [],
      "source": [
        "# # now set test dataset aside for post-training evaluation\n",
        "# df_trainval = scaled_dataset.iloc[:int(trainval_split*scaled_dataset.shape[0])]\n",
        "# df_test = scaled_dataset.iloc[int(trainval_split*scaled_dataset.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL8lj_VFVHJM"
      },
      "outputs": [],
      "source": [
        "df_trainval = scaled_dataset.iloc[:-n_val]\n",
        "df_test = scaled_dataset.iloc[-n_val:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-SHFEcUJOdr"
      },
      "outputs": [],
      "source": [
        "# # need to scale our full dataset for training\n",
        "# df_pivot.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# # let's re-scale all of the data points\n",
        "# scaler = MinMaxScaler()\n",
        "# df_pivot_scaled = pd.DataFrame(scaler.fit_transform(df_pivot))\n",
        "\n",
        "# # now set test dataset aside for post-training evaluation\n",
        "# df_trainval = df_pivot_scaled.iloc[:int(trainval_split*df_pivot.shape[0])]\n",
        "# df_test = df_pivot_scaled.iloc[int(trainval_split*df_pivot.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oiU6YhVRLiJ6",
        "outputId": "f4ef001e-d70a-4dc3-aec2-96d1fc44219e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.7396 - val_loss: -0.9491\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.7396 - val_loss: -0.9944\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.7396 - val_loss: -1.0053\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.7396 - val_loss: -1.0081\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.7396 - val_loss: -1.0088\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.7396 - val_loss: -1.0090\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.7396 - val_loss: -1.0088\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.7396 - val_loss: -1.0082\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.7396 - val_loss: -1.0070\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.7396 - val_loss: -1.0048\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.7396 - val_loss: -1.0009\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.7161 - val_loss: 0.0977\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.7158 - val_loss: 0.0935\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.7162 - val_loss: 0.0897\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.7161 - val_loss: 0.0889\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.7161 - val_loss: 0.0886\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7161 - val_loss: 0.0887\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.7161 - val_loss: 0.0894\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.7161 - val_loss: 0.0901\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7161 - val_loss: 0.0908\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.7161 - val_loss: 0.0915\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.4354 - val_loss: 0.0168\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.4459 - val_loss: -0.1785\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4575 - val_loss: -0.6086\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.4575 - val_loss: -0.7103\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.4575 - val_loss: -0.7205\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.4575 - val_loss: -0.7219\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -0.4575 - val_loss: -0.7222\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4575 - val_loss: -0.7222\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.4575 - val_loss: -0.7222\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.4575 - val_loss: -0.7223\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.4575 - val_loss: -0.7224\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.4575 - val_loss: -0.7225\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.4575 - val_loss: -0.7227\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.4575 - val_loss: -0.7231\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.4575 - val_loss: -0.7237\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.4575 - val_loss: -0.7245\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4575 - val_loss: -0.7256\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4575 - val_loss: -0.7272\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.4575 - val_loss: -0.7292\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.4575 - val_loss: -0.7319\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.4575 - val_loss: -0.7353\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.4575 - val_loss: -0.7395\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4575 - val_loss: -0.7445\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.4575 - val_loss: -0.7503\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4575 - val_loss: -0.7575\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.4581 - val_loss: -0.7860\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.4577 - val_loss: -0.8456\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.4579 - val_loss: -1.0011\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.4677 - val_loss: -1.2464\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5647 - val_loss: -1.2355\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.5648 - val_loss: -1.2354\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.5647 - val_loss: -1.2354\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.5209 - val_loss: -1.2354\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.5566 - val_loss: -1.2444\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.8057 - val_loss: -0.0591\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7261 - val_loss: -0.0591\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -0.8060 - val_loss: -0.0591\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -0.8060 - val_loss: -0.0591\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.8060 - val_loss: -0.0591\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.8060 - val_loss: -0.0591\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.8060 - val_loss: -0.0591\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5141 - val_loss: 0.4902\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.5141 - val_loss: 0.4902\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -0.5141 - val_loss: 0.4902\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -0.5141 - val_loss: 0.4902\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.5141 - val_loss: 0.4902\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5141 - val_loss: 0.4902\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 130ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.1036 - val_loss: -0.8215\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.2442 - val_loss: -0.2194\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.2442 - val_loss: -0.2194\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.2442 - val_loss: -0.2194\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.2442 - val_loss: -0.2194\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -0.2442 - val_loss: -0.2194\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -0.2442 - val_loss: -0.2194\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.1297 - val_loss: -0.4191\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.1297 - val_loss: -0.4144\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.1297 - val_loss: -0.4115\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.1297 - val_loss: -0.4097\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.1297 - val_loss: -0.4084\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.1297 - val_loss: -0.4076\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.1902 - val_loss: 0.0760\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -0.2098 - val_loss: 0.0756\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.2092 - val_loss: 0.0748\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.2092 - val_loss: 0.0730\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.2092 - val_loss: 0.0698\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2092 - val_loss: 0.0654\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.2092 - val_loss: 0.0602\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.2092 - val_loss: 0.0557\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.2092 - val_loss: 0.0533\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2092 - val_loss: 0.0539\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.2092 - val_loss: 0.0574\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.2092 - val_loss: 0.0632\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.2092 - val_loss: 0.0707\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.2092 - val_loss: 0.0789\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -0.2812 - val_loss: 0.0470\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.4451 - val_loss: 0.1300\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4070 - val_loss: 0.1300\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4962 - val_loss: 0.1300\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.4904 - val_loss: 0.1300\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.4868 - val_loss: 0.1300\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 285ms/step - loss: -0.2646 - val_loss: -0.5913\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.2964 - val_loss: -0.5912\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.3941 - val_loss: -0.5775\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.4007 - val_loss: -0.1230\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.4007 - val_loss: -0.1124\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -0.4007 - val_loss: -0.1124\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: -0.3878 - val_loss: -0.4074\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.3311 - val_loss: -0.4074\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.3318 - val_loss: -0.4074\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.1410 - val_loss: -0.4074\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -0.2102 - val_loss: -0.4074\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.1957 - val_loss: -0.4074\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.1411 - val_loss: -0.4074\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3171 - val_loss: -0.2228\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.3251 - val_loss: -0.2228\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.3668 - val_loss: -0.3765\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -0.2619 - val_loss: -0.3765\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.2643 - val_loss: -0.3765\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.3911 - val_loss: -0.3762\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -0.4672 - val_loss: -0.4420\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -0.4679 - val_loss: -0.4610\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 121ms/step - loss: -0.4679 - val_loss: -0.2532\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -0.4679 - val_loss: -0.2228\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 127ms/step - loss: -0.4679 - val_loss: -0.2228\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 124ms/step - loss: -0.4679 - val_loss: -0.2228\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.4679 - val_loss: -0.2228\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -0.4667 - val_loss: -0.3886\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4109 - val_loss: -0.3886\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4109 - val_loss: -0.3886\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.4109 - val_loss: -0.3886\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.4109 - val_loss: -0.3886\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.4109 - val_loss: -0.3886\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.3866 - val_loss: -0.0160\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3867 - val_loss: 0.1258\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 126ms/step - loss: -0.3867 - val_loss: 0.0184\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -0.3867 - val_loss: 0.0165\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3867 - val_loss: 0.0165\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3867 - val_loss: 0.0165\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.2605 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -0.2106 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -0.2452 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 123ms/step - loss: -0.2453 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 125ms/step - loss: -0.2453 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.2453 - val_loss: 0.0000e+00\n",
            "Found best params for CNN!\n",
            "Training optimal model for CNN...\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: -0.2619\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 350ms/step - loss: -0.3801\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 464ms/step - loss: -0.5840\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 1s 509ms/step - loss: -0.7458\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 506ms/step - loss: -0.8614\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 473ms/step - loss: -0.9404\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 480ms/step - loss: -1.0337\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 497ms/step - loss: -1.1508\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 503ms/step - loss: -1.2466\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 463ms/step - loss: -1.3256\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -1.3715\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 409ms/step - loss: -1.4304\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 374ms/step - loss: -1.5131\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 483ms/step - loss: -1.5818\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 1s 502ms/step - loss: -1.6206\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 457ms/step - loss: -1.6364\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 449ms/step - loss: -1.6930\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 420ms/step - loss: -1.6906\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 371ms/step - loss: -1.7378\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -1.7537\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 302ms/step - loss: -1.8182\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: -1.8711\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 310ms/step - loss: -1.8906\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: -1.8841\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: -1.8906\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: -1.8584\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 327ms/step - loss: -1.8857\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 355ms/step - loss: -1.9716\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: -2.1151\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: -2.0600\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: -2.0391\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: -2.1122\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: -2.1328\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: -2.1718\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: -2.2003\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -2.2574\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 315ms/step - loss: -2.1410\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -2.2150\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 328ms/step - loss: -2.3613\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 308ms/step - loss: -2.3512\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -2.4016\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 323ms/step - loss: -2.3655\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 294ms/step - loss: -2.3487\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: -2.4097\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: -2.4789\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: -2.3257\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: -2.4649\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 314ms/step - loss: -1.9356\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: -2.2276\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: -2.2869\n",
            "5/5 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Done training CNN!!!\n",
            "\n",
            "\n",
            "\n",
            "Training: RNN...\n",
            "Only 8 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.1, 'epochs': 50, 'input_layer_size': 64, 'learning_rate': 0.001, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.2966 - val_loss: -1.8405\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3067 - val_loss: -1.8175\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.3189 - val_loss: -1.7873\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.3307 - val_loss: -1.7550\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.3523 - val_loss: -1.7150\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.3605 - val_loss: -1.6721\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.3345 - val_loss: -1.4532\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.3626 - val_loss: -1.4490\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.3707 - val_loss: -1.4441\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.3888 - val_loss: -1.4378\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.4020 - val_loss: -1.4301\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.4227 - val_loss: -1.4232\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3557 - val_loss: -0.4600\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3689 - val_loss: -0.4589\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.3898 - val_loss: -0.4587\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4052 - val_loss: -0.4595\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.4325 - val_loss: -0.4611\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.4444 - val_loss: -0.4648\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4679 - val_loss: -0.4706\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.4916 - val_loss: -0.4760\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.4964 - val_loss: -0.4728\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.5087 - val_loss: -0.4765\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.5311 - val_loss: -0.4701\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.5560 - val_loss: -0.4731\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.5708 - val_loss: -0.4686\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.5835 - val_loss: -0.4604\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.6219 - val_loss: -0.4513\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.8610 - val_loss: -0.4134\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.8748 - val_loss: -0.4087\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.8945 - val_loss: -0.4143\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.8969 - val_loss: -0.4235\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.9272 - val_loss: -0.4141\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.9651 - val_loss: -0.4109\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.9659 - val_loss: -0.4127\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -1.0083 - val_loss: -0.4178\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -1.0154 - val_loss: -0.4240\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -1.0478 - val_loss: -0.4229\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -1.0838 - val_loss: -0.4220\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -1.1293 - val_loss: -0.4351\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -1.1224 - val_loss: -0.4266\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -1.1652 - val_loss: -0.4221\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -1.1643 - val_loss: -0.4290\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -1.2086 - val_loss: -0.4348\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -1.2249 - val_loss: -0.4365\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -1.2453 - val_loss: -0.4375\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -1.3163 - val_loss: -0.4351\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -1.3599 - val_loss: -0.4434\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -1.3827 - val_loss: -0.4462\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -1.4107 - val_loss: -0.4376\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -1.4365 - val_loss: -0.4415\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -1.5108 - val_loss: -0.4649\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -1.5592 - val_loss: -0.4364\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -1.5707 - val_loss: -0.4461\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -1.6182 - val_loss: -0.4457\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -1.6394 - val_loss: -0.4441\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -1.7413 - val_loss: -0.4480\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: -1.0392 - val_loss: -0.4891\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -1.0695 - val_loss: -0.4903\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -1.1153 - val_loss: -0.5005\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -1.1420 - val_loss: -0.5004\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -1.1826 - val_loss: -0.4815\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -1.2057 - val_loss: -0.5094\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -1.2872 - val_loss: -0.5068\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -1.3491 - val_loss: -0.4938\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -1.2738 - val_loss: -0.4779\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -1.3499 - val_loss: -0.4702\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -1.3553 - val_loss: -0.4859\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.8643 - val_loss: -0.1271\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.8250 - val_loss: -0.1194\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.8073 - val_loss: -0.1188\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.8018 - val_loss: -0.1215\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.8262 - val_loss: -0.1183\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.8705 - val_loss: -0.1175\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.4722 - val_loss: -0.0148\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.5239 - val_loss: -0.0154\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.5584 - val_loss: -0.0173\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5599 - val_loss: -0.0199\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.5874 - val_loss: -0.0210\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.5749 - val_loss: -0.0201\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5953 - val_loss: -0.0183\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.6308 - val_loss: -0.0172\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.6327 - val_loss: -0.0176\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.6081 - val_loss: -0.0201\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.3006 - val_loss: -0.8345\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.3192 - val_loss: -0.8216\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.3104 - val_loss: -0.8155\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3270 - val_loss: -0.8176\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.3372 - val_loss: -0.8337\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.3467 - val_loss: -0.8564\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.3720 - val_loss: -0.7329\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.3668 - val_loss: -0.5930\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.3655 - val_loss: -0.7963\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.4024 - val_loss: -0.8854\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.4056 - val_loss: -0.8657\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.4107 - val_loss: -0.8625\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4265 - val_loss: -0.8695\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4248 - val_loss: -0.8900\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4656 - val_loss: -0.9215\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4724 - val_loss: -0.9394\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4538 - val_loss: -0.9458\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4411 - val_loss: -0.9512\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.4614 - val_loss: -0.9567\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.5086 - val_loss: -0.9594\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.5050 - val_loss: -0.9579\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5135 - val_loss: -0.9547\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.5264 - val_loss: -0.9475\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.5420 - val_loss: -0.9349\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.5796 - val_loss: -0.9307\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: -0.4985 - val_loss: -0.2641\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.5179 - val_loss: -0.2558\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -0.5383 - val_loss: -0.2490\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -0.5475 - val_loss: -0.2454\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.5475 - val_loss: -0.2448\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.5796 - val_loss: -0.2469\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 303ms/step - loss: -0.4035 - val_loss: -0.8449\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.4223 - val_loss: -0.8445\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.4242 - val_loss: -0.8420\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -0.4418 - val_loss: -0.8378\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.4419 - val_loss: -0.8307\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4878 - val_loss: -0.8263\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.4330 - val_loss: -1.1431\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.4624 - val_loss: -1.1419\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4930 - val_loss: -1.1462\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.5051 - val_loss: -1.1552\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.5087 - val_loss: -1.1688\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.4883 - val_loss: -1.1775\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.5450 - val_loss: -1.1614\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.5619 - val_loss: -1.1449\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.5866 - val_loss: -1.1407\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.6054 - val_loss: -1.1300\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.6374 - val_loss: -1.1150\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.7812 - val_loss: 0.0520\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.7876 - val_loss: 0.0558\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.8126 - val_loss: 0.0622\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.8518 - val_loss: 0.0608\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.6978 - val_loss: 0.0334\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.8013 - val_loss: -0.0073\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.7947 - val_loss: -0.0320\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.8052 - val_loss: 0.0130\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.5473 - val_loss: -0.0476\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.7733 - val_loss: 0.1069\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.4894 - val_loss: 0.1470\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.4867 - val_loss: 0.0512\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.6679 - val_loss: 0.0283\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.6122 - val_loss: 0.0986\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.5085 - val_loss: -0.1146\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.4181 - val_loss: -0.2166\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.4231 - val_loss: -0.2006\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.3476 - val_loss: -0.1254\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.3501 - val_loss: -0.1360\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.3722 - val_loss: -0.3279\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -0.3911 - val_loss: -0.1249\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.4047 - val_loss: -0.1303\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.5798 - val_loss: -0.2943\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.4659 - val_loss: -0.3097\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.4168 - val_loss: -0.3617\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.4392 - val_loss: -0.1380\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.3495 - val_loss: -0.2920\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.3845 - val_loss: -0.2623\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3678 - val_loss: -0.1386\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.4753 - val_loss: -0.2309\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.4924 - val_loss: -0.0931\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.2919 - val_loss: -0.1023\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.4626 - val_loss: -0.1431\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.3136 - val_loss: -0.0263\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5471 - val_loss: -0.0315\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.4135 - val_loss: -0.0155\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.5637 - val_loss: 0.0127\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4672 - val_loss: -0.1375\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: -0.2028 - val_loss: -0.9400\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.2205 - val_loss: -0.6743\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.2814 - val_loss: -0.6887\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.2882 - val_loss: -0.8203\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -0.2714 - val_loss: -0.9965\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.2047 - val_loss: -0.5399\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.2424 - val_loss: -0.6774\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.2509 - val_loss: -1.2432\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -0.2513 - val_loss: -0.7751\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -0.2612 - val_loss: -0.8844\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -0.2001 - val_loss: -0.6825\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -0.1809 - val_loss: -0.7810\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -0.1973 - val_loss: -1.2828\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -0.1978 - val_loss: -0.8555\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.2479 - val_loss: -1.0102\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.2053 - val_loss: -1.1128\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.1919 - val_loss: -1.0309\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.2843 - val_loss: -0.9978\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.2175 - val_loss: 0.0238\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.2854 - val_loss: 0.1143\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.2282 - val_loss: 0.0931\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.2196 - val_loss: 0.0988\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.3015 - val_loss: 0.1139\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.2227 - val_loss: 0.1026\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.1775 - val_loss: -0.5584\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.1535 - val_loss: -0.7987\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.1431 - val_loss: -0.6325\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.1283 - val_loss: -0.6282\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.0938 - val_loss: -0.5830\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.2009 - val_loss: -0.8194\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.1288 - val_loss: -0.7675\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.1283 - val_loss: -0.7869\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.1461 - val_loss: -0.7755\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.1426 - val_loss: -0.8135\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.1159 - val_loss: -0.6163\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.2342 - val_loss: -0.5449\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.2351 - val_loss: -0.6239\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.1711 - val_loss: -0.5992\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.2684 - val_loss: -0.5358\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.2327 - val_loss: -0.5397\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.2821 - val_loss: -0.6449\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.1867 - val_loss: -0.4867\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.2251 - val_loss: -0.6639\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.2201 - val_loss: -0.4302\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.2160 - val_loss: -0.5339\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.2128 - val_loss: -0.5437\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.2304 - val_loss: -0.4744\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.2441 - val_loss: -0.4552\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.3019 - val_loss: -0.1058\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.3233 - val_loss: -0.0994\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.3222 - val_loss: -0.1977\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.3452 - val_loss: -0.1490\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.3197 - val_loss: -0.1660\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.3074 - val_loss: -0.1025\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.3249 - val_loss: -0.0912\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.3566 - val_loss: -0.0568\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.2514 - val_loss: 0.0561\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.2205 - val_loss: 0.1587\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.2315 - val_loss: 0.3019\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -0.2845 - val_loss: 0.0235\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.2018 - val_loss: 0.1000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.2577 - val_loss: 0.2836\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2921 - val_loss: 0.0987\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.2966 - val_loss: 0.0662\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -0.2895 - val_loss: 0.1402\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: -0.2656 - val_loss: -0.1372\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.2282 - val_loss: -0.1199\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -0.2728 - val_loss: -0.1107\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.2523 - val_loss: -0.0685\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.3401 - val_loss: -0.1224\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -0.2976 - val_loss: -0.1138\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.0963 - val_loss: 0.3027\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.1166 - val_loss: 0.3183\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.1371 - val_loss: 0.4185\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.1150 - val_loss: 0.3009\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.0873 - val_loss: 0.3594\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.1597 - val_loss: 0.2818\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.1292 - val_loss: 0.3334\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.1477 - val_loss: 0.5272\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.1320 - val_loss: 0.3885\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.0800 - val_loss: 0.5109\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.1415 - val_loss: 0.3633\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.0587 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.0360 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0853 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0154 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0208 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0420 - val_loss: 0.0000e+00\n",
            "Only 7 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.1, 'epochs': 50, 'input_layer_size': 64, 'learning_rate': 0.01, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.3167 - val_loss: -1.7856\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.3965 - val_loss: -1.8825\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.4581 - val_loss: -1.8818\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.5309 - val_loss: -1.5430\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.6468 - val_loss: -1.2277\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.7614 - val_loss: -0.8050\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.8197 - val_loss: -0.9277\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.5016 - val_loss: -1.3106\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.5942 - val_loss: -1.1592\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.6850 - val_loss: -1.0806\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.8811 - val_loss: -1.0810\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.9564 - val_loss: -1.0568\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -1.0776 - val_loss: -0.9275\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 306ms/step - loss: -0.5341 - val_loss: -0.3875\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.6711 - val_loss: -0.3500\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -0.8000 - val_loss: -0.3354\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.9074 - val_loss: -0.3152\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -1.0350 - val_loss: -0.3015\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -1.0836 - val_loss: -0.2657\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -0.8458 - val_loss: -0.4289\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -0.9993 - val_loss: -0.4442\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -1.1394 - val_loss: -0.4265\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -1.2362 - val_loss: -0.4206\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -1.3507 - val_loss: -0.4539\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -1.4439 - val_loss: -0.3690\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -1.3690 - val_loss: -0.3347\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -1.5416 - val_loss: -0.4682\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -1.5732 - val_loss: -0.4065\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -1.5036 - val_loss: -0.1712\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.9646 - val_loss: -0.4513\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.9423 - val_loss: -0.4138\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -1.0605 - val_loss: -0.4758\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -0.6143 - val_loss: -0.3543\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.9610 - val_loss: -0.2609\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.5411 - val_loss: -0.4524\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.9352 - val_loss: -0.0854\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 259ms/step - loss: -0.6223 - val_loss: -0.1246\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.7565 - val_loss: -0.5195\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.6448 - val_loss: -0.1350\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.8596 - val_loss: -0.5621\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.6626 - val_loss: -0.5827\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.6741 - val_loss: -0.5086\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.8644 - val_loss: -0.3005\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -1.2057 - val_loss: -0.6641\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.7753 - val_loss: -0.2585\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -1.1454 - val_loss: -0.4547\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.9616 - val_loss: -1.1161\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -1.0637 - val_loss: -1.0938\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.9401 - val_loss: -1.0200\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.8777 - val_loss: -0.6513\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.7687 - val_loss: -1.1824\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.7479 - val_loss: -0.5353\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.6754 - val_loss: -1.1992\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.7934 - val_loss: -1.0277\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.9407 - val_loss: -0.9972\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.7549 - val_loss: -1.0580\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.8069 - val_loss: -1.0377\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.7846 - val_loss: -0.1643\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.8766 - val_loss: -0.2053\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7271 - val_loss: -0.3970\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.7367 - val_loss: -0.3243\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.7079 - val_loss: -0.3662\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.5376 - val_loss: -0.3154\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -1.0364 - val_loss: -0.2630\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.9865 - val_loss: 0.0858\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.6638 - val_loss: -0.2026\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.3347 - val_loss: -0.2653\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.7828 - val_loss: -0.1118\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.5978 - val_loss: -0.2488\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.7693 - val_loss: 0.0514\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.4872 - val_loss: -0.5633\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.8374 - val_loss: -0.5665\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.9615 - val_loss: -0.0919\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.7498 - val_loss: -0.1064\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.7292 - val_loss: -0.2477\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.8889 - val_loss: 0.0617\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.6946 - val_loss: -0.4145\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.8456 - val_loss: 0.1437\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.2312 - val_loss: -0.0018\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3833 - val_loss: -0.0706\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.5937 - val_loss: 0.0405\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.6477 - val_loss: 0.6385\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.2922 - val_loss: -0.3621\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.7458 - val_loss: -0.0250\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.5126 - val_loss: 0.2021\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.3666 - val_loss: -0.3756\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.2714 - val_loss: 0.4192\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -0.4469 - val_loss: 0.4497\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4925 - val_loss: 0.5183\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.4357 - val_loss: 0.1698\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.3984 - val_loss: -0.0818\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: -0.1924 - val_loss: -0.5092\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.3296 - val_loss: 0.2730\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.3006 - val_loss: 0.1191\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.1801 - val_loss: -0.0820\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.1689 - val_loss: -0.6370\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.5515 - val_loss: -0.6445\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.4182 - val_loss: -0.0339\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.1688 - val_loss: -0.3657\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.3015 - val_loss: 0.0395\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.3567 - val_loss: -0.2832\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.2183 - val_loss: 0.1326\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: -0.3369 - val_loss: -0.4614\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.1180 - val_loss: -0.0691\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.3255 - val_loss: -0.3382\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.2025 - val_loss: -0.8925\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.2006 - val_loss: -0.2471\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -0.2388 - val_loss: -1.2152\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.2493 - val_loss: -1.0810\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0104 - val_loss: -1.0264\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.1385 - val_loss: -0.4120\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.1544 - val_loss: -1.1372\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.2152 - val_loss: -0.6446\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.4128 - val_loss: -0.7739\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.2953 - val_loss: -1.0248\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.3963 - val_loss: -0.7581\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.0936 - val_loss: -0.9005\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.1346 - val_loss: -1.3135\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2232 - val_loss: -0.5987\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.3264 - val_loss: 0.0114\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.3628 - val_loss: -0.2571\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.3961 - val_loss: -0.2106\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.3774 - val_loss: -0.5272\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.2988 - val_loss: -0.7805\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.5734 - val_loss: -0.3771\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5855 - val_loss: -0.4892\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4315 - val_loss: -0.8314\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.4579 - val_loss: 0.3080\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4670 - val_loss: 0.3609\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.3964 - val_loss: 0.0483\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.3525 - val_loss: 0.2810\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.5593 - val_loss: 0.8106\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5823 - val_loss: -0.3811\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4158 - val_loss: -0.2921\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6291 - val_loss: -0.2261\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.3445 - val_loss: -0.1026\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.8060 - val_loss: -0.5060\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4266 - val_loss: -0.0987\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6587 - val_loss: -0.6886\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.3442 - val_loss: -0.0989\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.8454 - val_loss: -0.1155\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.4068 - val_loss: -0.0457\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.3551 - val_loss: -0.1596\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.5995 - val_loss: -0.2298\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.6322 - val_loss: 0.1413\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.3661 - val_loss: -0.4457\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4591 - val_loss: 0.2006\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.4238 - val_loss: 0.1651\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.5784 - val_loss: -0.2047\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.7108 - val_loss: -0.3443\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4624 - val_loss: 0.2595\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.4510 - val_loss: -0.1502\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.2689 - val_loss: -0.9368\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.1194 - val_loss: -7.7017e-04\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.1028 - val_loss: -0.5184\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -0.1448 - val_loss: -0.1988\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.2431 - val_loss: -1.3984\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.2602 - val_loss: -1.5744\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2585 - val_loss: -0.3048\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.1192 - val_loss: -0.6205\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.0540 - val_loss: -0.0733\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.2395 - val_loss: -0.4454\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.1832 - val_loss: -0.8532\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -0.3008 - val_loss: 0.1508\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.1629 - val_loss: -0.2163\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.1613 - val_loss: 0.0417\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -0.2059 - val_loss: -0.1674\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -0.2059 - val_loss: -0.0083\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.4592 - val_loss: -0.2852\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.6141 - val_loss: -0.2398\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.5313 - val_loss: -0.2487\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -0.3086 - val_loss: 0.0572\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.1770 - val_loss: 0.0075\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.5668 - val_loss: -0.2832\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 347ms/step - loss: -0.4891 - val_loss: -0.8956\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -0.1505 - val_loss: -0.9099\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.1099 - val_loss: -0.3968\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.3559 - val_loss: -1.2708\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.1393 - val_loss: -0.5163\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.0573 - val_loss: 0.0524\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.3479 - val_loss: -0.1110\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.4699 - val_loss: -0.2977\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.2384 - val_loss: -0.5217\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2931 - val_loss: -0.8511\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.2480 - val_loss: -0.0015\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.3398 - val_loss: 0.4309\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.1888 - val_loss: 0.0035\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.0730 - val_loss: -0.8459\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.1052 - val_loss: 0.0222\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3643 - val_loss: -0.5481\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4193 - val_loss: -0.4960\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.1417 - val_loss: -0.5847\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3817 - val_loss: -0.5229\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5355 - val_loss: -0.2641\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.1347 - val_loss: 0.0654\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.2864 - val_loss: 0.3043\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.0731 - val_loss: -0.6371\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.2942 - val_loss: -0.9782\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.4249 - val_loss: -0.5229\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.1968 - val_loss: -0.3802\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.1173 - val_loss: 0.3904\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.0760 - val_loss: -0.5230\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.0990 - val_loss: -0.5168\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.5427 - val_loss: 0.0264\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.1046 - val_loss: 0.2597\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.1418 - val_loss: 3.4960e-04\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.2063 - val_loss: -0.0831\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.3898 - val_loss: 0.2588\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.1771 - val_loss: -0.2380\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.0472 - val_loss: 0.2384\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.1885 - val_loss: -0.0686\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -0.1331 - val_loss: -0.0548\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.5240 - val_loss: 0.1860\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.2202 - val_loss: -0.0483\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.2733 - val_loss: 0.1210\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 134ms/step - loss: -0.1377 - val_loss: 0.1197\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.2909 - val_loss: -0.0059\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.1908 - val_loss: -0.0051\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.2690 - val_loss: -0.0102\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.2962 - val_loss: -0.0324\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.3062 - val_loss: -0.0323\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.3101 - val_loss: -0.0350\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.2355 - val_loss: -0.0315\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.2456 - val_loss: -0.0145\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2015 - val_loss: -0.0035\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.2030 - val_loss: 0.0088\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.2217 - val_loss: 0.0209\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -0.0948 - val_loss: 0.8260\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -0.1075 - val_loss: 0.9083\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -0.1523 - val_loss: 1.0142\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.1169 - val_loss: 0.6019\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -0.1262 - val_loss: 0.2518\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.1331 - val_loss: 0.1015\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: -0.1411 - val_loss: -0.0890\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -0.1339 - val_loss: -0.1188\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.1214 - val_loss: -0.1244\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.1758 - val_loss: -0.1374\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2299 - val_loss: -0.1031\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.2877 - val_loss: -0.0200\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.4045 - val_loss: 0.1215\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.3831 - val_loss: 0.1658\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.4660 - val_loss: -0.0828\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 349ms/step - loss: -0.2085 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.1306 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.0808 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: -0.0394 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -0.0202 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.0246 - val_loss: 0.0000e+00\n",
            "Only 6 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.1, 'epochs': 50, 'input_layer_size': 128, 'learning_rate': 0.001, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 3s 3s/step - loss: -0.3126 - val_loss: -1.5409\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.3578 - val_loss: -1.4557\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -0.3911 - val_loss: -1.3948\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.4276 - val_loss: -1.3370\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4561 - val_loss: -1.2845\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.4821 - val_loss: -1.2647\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.3935 - val_loss: -1.4409\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4309 - val_loss: -1.3783\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.4699 - val_loss: -1.2722\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5187 - val_loss: -1.1732\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5765 - val_loss: -1.0890\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.2603 - val_loss: -1.7363\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2397 - val_loss: -1.7295\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.2561 - val_loss: -1.7004\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2943 - val_loss: -1.5421\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3600 - val_loss: -1.1479\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5832 - val_loss: -1.1638\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.2635 - val_loss: -0.3662\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3790 - val_loss: -0.3885\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.6094 - val_loss: -0.4315\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.5420 - val_loss: -0.4339\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.5469 - val_loss: -0.4577\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5507 - val_loss: -0.4626\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.5637 - val_loss: -0.4602\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.6084 - val_loss: -0.4526\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.6185 - val_loss: -0.4386\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.6626 - val_loss: -0.4244\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.7032 - val_loss: -0.4157\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.9073 - val_loss: -0.4786\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.9152 - val_loss: -0.4659\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.9522 - val_loss: -0.4507\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.9979 - val_loss: -0.4796\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -1.0646 - val_loss: -0.4633\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -1.1057 - val_loss: -0.4372\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -1.0745 - val_loss: -0.4603\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -1.1222 - val_loss: -0.4284\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -1.1086 - val_loss: -0.4342\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.7592 - val_loss: -0.4701\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.7590 - val_loss: -0.4696\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.7707 - val_loss: -0.4682\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -0.7907 - val_loss: -0.4699\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.8279 - val_loss: -0.4705\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.8621 - val_loss: -0.4739\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.8692 - val_loss: -0.4821\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 259ms/step - loss: -0.9054 - val_loss: -0.5074\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.9153 - val_loss: -0.5129\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.9238 - val_loss: -0.5064\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.9988 - val_loss: -0.5027\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 288ms/step - loss: -0.9960 - val_loss: -0.4919\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -1.0479 - val_loss: -0.4912\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -1.0960 - val_loss: -0.4920\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 319ms/step - loss: -0.7296 - val_loss: -0.1073\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.7454 - val_loss: -0.1002\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.7421 - val_loss: -0.0993\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.7873 - val_loss: -0.0835\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.8013 - val_loss: -0.0811\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -0.8603 - val_loss: -0.0750\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 343ms/step - loss: -0.4444 - val_loss: 0.0088\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.4576 - val_loss: 0.0077\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -0.4598 - val_loss: 0.0096\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.4766 - val_loss: 0.0127\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5034 - val_loss: 0.0147\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5027 - val_loss: 0.0133\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.5295 - val_loss: 0.0109\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.2557 - val_loss: -0.5550\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.2710 - val_loss: -0.5430\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2843 - val_loss: -0.5335\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2978 - val_loss: -0.5331\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3249 - val_loss: -0.5314\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.3611 - val_loss: -0.5031\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.2806 - val_loss: -0.2816\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.2934 - val_loss: -0.2921\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.3225 - val_loss: -0.2915\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.3460 - val_loss: -0.2585\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.3690 - val_loss: -0.2096\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.3945 - val_loss: -0.1861\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.4176 - val_loss: -0.1745\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.2359 - val_loss: -1.0197\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2737 - val_loss: -1.0436\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.2970 - val_loss: -1.0724\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.3302 - val_loss: -1.0958\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3391 - val_loss: -1.1176\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3659 - val_loss: -1.1316\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4011 - val_loss: -1.1408\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4136 - val_loss: -1.1499\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.4505 - val_loss: -1.1898\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4680 - val_loss: -1.2855\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4686 - val_loss: -1.3015\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5469 - val_loss: -1.2743\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.5851 - val_loss: -1.2899\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5808 - val_loss: -1.2794\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.5945 - val_loss: -1.2978\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.6409 - val_loss: -1.3356\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.6774 - val_loss: -1.2484\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.5088 - val_loss: -1.1653\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.6882 - val_loss: -1.1982\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.6763 - val_loss: -1.1753\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.6992 - val_loss: -1.1225\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.6660 - val_loss: -0.9484\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5917 - val_loss: -0.9887\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.6508 - val_loss: -0.9792\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.7057 - val_loss: -0.9870\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.7422 - val_loss: -0.9993\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.7895 - val_loss: -0.9941\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.8444 - val_loss: -0.9073\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.9172 - val_loss: -0.8937\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.8955 - val_loss: -0.8448\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -0.9703 - val_loss: -0.9214\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: -0.8235 - val_loss: 0.2609\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.8458 - val_loss: 0.2768\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -0.8868 - val_loss: 0.2461\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.9308 - val_loss: 0.2886\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -0.8767 - val_loss: 0.2073\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: -1.0228 - val_loss: 0.1679\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.8950 - val_loss: 0.2248\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -0.8735 - val_loss: 0.2068\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -0.9039 - val_loss: 0.1998\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -0.9114 - val_loss: 0.2010\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.7530 - val_loss: 0.2048\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: -0.5223 - val_loss: -0.0793\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.5951 - val_loss: -0.1062\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -0.6103 - val_loss: -0.1610\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -0.6571 - val_loss: -0.1759\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -0.6837 - val_loss: -0.1917\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.6776 - val_loss: -0.2095\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.7103 - val_loss: -0.2481\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.7713 - val_loss: -0.2062\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.8607 - val_loss: -0.1872\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.8900 - val_loss: -0.2065\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.9194 - val_loss: -0.2657\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.9873 - val_loss: -0.2968\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -1.0153 - val_loss: -0.2938\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.9982 - val_loss: -0.2836\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -1.0597 - val_loss: -0.3165\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -1.1598 - val_loss: -0.3684\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -1.1635 - val_loss: -0.3541\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -1.2782 - val_loss: -0.3039\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -1.3061 - val_loss: -0.3079\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -1.4387 - val_loss: -0.3328\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -1.4404 - val_loss: -0.3240\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.8899 - val_loss: 0.1598\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.9699 - val_loss: 0.2862\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -1.0035 - val_loss: 0.1021\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.9248 - val_loss: -0.0694\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.9797 - val_loss: 0.0287\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -1.1224 - val_loss: -0.1244\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -1.2627 - val_loss: -0.1243\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -1.3184 - val_loss: -0.1138\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -1.3886 - val_loss: -0.1526\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -1.1781 - val_loss: -0.0532\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -1.2748 - val_loss: -0.1198\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.6646 - val_loss: -0.1000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.6474 - val_loss: -0.1393\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.6971 - val_loss: -0.2145\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.7541 - val_loss: -0.1683\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.8842 - val_loss: -0.1412\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.9712 - val_loss: -0.1278\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.9516 - val_loss: -0.1158\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.9884 - val_loss: -0.1082\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.4187 - val_loss: -1.0687\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4430 - val_loss: -1.0164\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.4717 - val_loss: -0.9564\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.4939 - val_loss: -0.9345\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.5056 - val_loss: -0.9330\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.5462 - val_loss: -0.9085\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: -0.5206 - val_loss: -0.0567\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.5295 - val_loss: -0.0587\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.5661 - val_loss: -0.1228\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -0.5838 - val_loss: -0.1353\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.5989 - val_loss: -0.1492\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.6507 - val_loss: -0.1107\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.6794 - val_loss: -0.1081\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.7067 - val_loss: -0.1307\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -0.7285 - val_loss: 0.0133\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -0.7133 - val_loss: 0.0412\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.4259 - val_loss: -0.6580\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4351 - val_loss: -0.7046\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4499 - val_loss: -0.7593\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.3780 - val_loss: -0.7747\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.3900 - val_loss: -0.7614\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4231 - val_loss: -0.7651\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4323 - val_loss: -0.7649\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.4515 - val_loss: -0.7642\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4401 - val_loss: -0.7635\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.4208 - val_loss: -0.9492\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4399 - val_loss: -0.9774\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4427 - val_loss: -1.0019\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.4447 - val_loss: -1.0215\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4684 - val_loss: -1.0365\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4617 - val_loss: -1.0476\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4860 - val_loss: -1.0555\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.4758 - val_loss: -1.0612\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4918 - val_loss: -1.0652\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4901 - val_loss: -1.0681\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4905 - val_loss: -1.0701\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.4877 - val_loss: -1.0717\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4935 - val_loss: -1.0728\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4926 - val_loss: -1.0737\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4957 - val_loss: -1.0743\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.4917 - val_loss: -1.0750\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4977 - val_loss: -1.0754\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.4898 - val_loss: -1.0758\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4930 - val_loss: -1.0762\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4874 - val_loss: -1.0765\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.4997 - val_loss: -1.0767\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.5008 - val_loss: -1.0769\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4929 - val_loss: -1.0770\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.5020 - val_loss: -1.0771\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4958 - val_loss: -1.0772\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.4947 - val_loss: -1.0773\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.5032 - val_loss: -1.0773\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4892 - val_loss: -1.0774\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4903 - val_loss: -1.0775\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5016 - val_loss: -1.0775\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.5100 - val_loss: -1.0775\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.5004 - val_loss: -1.0775\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.4932 - val_loss: -1.0775\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4951 - val_loss: -1.0775\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4974 - val_loss: -1.0775\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.4968 - val_loss: -1.0775\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4956 - val_loss: -1.0775\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.5045 - val_loss: -1.0775\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4962 - val_loss: -1.0775\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 408ms/step - loss: -0.5019 - val_loss: -0.1737\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -0.4978 - val_loss: -0.1739\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: -0.4987 - val_loss: -0.1741\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -0.4884 - val_loss: -0.1742\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: -0.5095 - val_loss: -0.1745\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: -0.4935 - val_loss: -0.1747\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: -0.5018 - val_loss: -0.1749\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: -0.4889 - val_loss: -0.1751\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 309ms/step - loss: -0.4958 - val_loss: -0.1753\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 299ms/step - loss: -0.4950 - val_loss: -0.1755\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -0.4987 - val_loss: -0.1758\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.4989 - val_loss: -0.1761\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.5024 - val_loss: -0.1764\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.4906 - val_loss: -0.1766\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4894 - val_loss: -0.1768\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.5068 - val_loss: -0.1772\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.5004 - val_loss: -0.1775\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.4966 - val_loss: -0.1779\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.4989 - val_loss: -0.1783\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.5048 - val_loss: -0.1788\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4933 - val_loss: -0.1793\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5076 - val_loss: -0.1799\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5004 - val_loss: -0.1806\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -0.4980 - val_loss: -0.1814\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.5010 - val_loss: -0.1822\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.5075 - val_loss: -0.1832\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.5081 - val_loss: -0.1844\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.5047 - val_loss: -0.1859\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.5048 - val_loss: -0.1875\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: -0.4895 - val_loss: -0.1892\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.4995 - val_loss: -0.1913\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.4956 - val_loss: -0.1936\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.5197 - val_loss: -0.1964\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.5138 - val_loss: -0.2002\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.5093 - val_loss: -0.2046\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.5221 - val_loss: -0.2105\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -0.5348 - val_loss: -0.2184\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.5248 - val_loss: -0.2277\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.5274 - val_loss: -0.2389\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.5881 - val_loss: -0.2539\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.5485 - val_loss: -0.2730\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.5319 - val_loss: -0.2944\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.6021 - val_loss: -0.3195\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.5908 - val_loss: -0.3445\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 358ms/step - loss: -0.5604 - val_loss: -0.3669\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.5739 - val_loss: -0.3803\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -0.6397 - val_loss: -0.3813\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.5800 - val_loss: -0.3756\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 341ms/step - loss: -0.6152 - val_loss: -0.3660\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 300ms/step - loss: -0.6051 - val_loss: -0.3506\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.5029 - val_loss: 0.2845\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4761 - val_loss: 0.2917\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.5168 - val_loss: 0.2940\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5518 - val_loss: 0.2922\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4639 - val_loss: 0.2872\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4978 - val_loss: 0.2783\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4756 - val_loss: 0.2678\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.5193 - val_loss: 0.2554\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4987 - val_loss: 0.2421\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5526 - val_loss: 0.2292\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.5473 - val_loss: 0.2178\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5355 - val_loss: 0.2083\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.5476 - val_loss: 0.2014\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5635 - val_loss: 0.1965\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5786 - val_loss: 0.1942\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.5414 - val_loss: 0.1935\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5390 - val_loss: 0.1943\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5383 - val_loss: 0.1969\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.5334 - val_loss: 0.1995\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5896 - val_loss: 0.2022\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5919 - val_loss: 0.2034\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -0.3230 - val_loss: -0.2751\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.3351 - val_loss: -0.2734\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.3540 - val_loss: -0.2713\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.3461 - val_loss: -0.2689\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -0.3481 - val_loss: -0.2658\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.4042 - val_loss: -0.2619\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 321ms/step - loss: -0.1791 - val_loss: -0.0636\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2145 - val_loss: -0.0548\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -0.2150 - val_loss: -0.0458\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -0.2298 - val_loss: -0.0349\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.2075 - val_loss: -0.0207\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -0.1908 - val_loss: 0.0017\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 349ms/step - loss: -0.1200 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -0.1195 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: -0.1296 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -0.1594 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -0.1828 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -0.1682 - val_loss: 0.0000e+00\n",
            "Only 5 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.1, 'epochs': 50, 'input_layer_size': 128, 'learning_rate': 0.01, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 3s 3s/step - loss: -0.3091 - val_loss: -1.6181\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4514 - val_loss: -1.3943\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.2764 - val_loss: -1.2590\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3813 - val_loss: -1.0911\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.5941 - val_loss: -0.6976\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.5118 - val_loss: -0.6402\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.5233 - val_loss: -1.0107\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5836 - val_loss: -1.0544\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5489 - val_loss: -0.8788\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.6626 - val_loss: -0.6757\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3935 - val_loss: -0.7218\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.9919 - val_loss: -1.1992\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.8155 - val_loss: -0.8119\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3696 - val_loss: -1.0734\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.5019 - val_loss: -1.0869\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3084 - val_loss: -1.1797\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.6133 - val_loss: -0.8019\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.7107 - val_loss: -0.4811\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4299 - val_loss: -0.5252\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.6160 - val_loss: -0.2538\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.4015 - val_loss: -0.4108\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.3930 - val_loss: -0.3035\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.3012 - val_loss: -0.4377\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.5047 - val_loss: -0.4327\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.8872 - val_loss: -0.4252\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.6270 - val_loss: -0.6588\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.9461 - val_loss: -0.1669\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.7346 - val_loss: -0.9716\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -0.8290 - val_loss: -0.6689\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -1.1214 - val_loss: -0.4774\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -1.3728 - val_loss: -0.3594\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -1.5179 - val_loss: -0.3904\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -1.5013 - val_loss: -0.3993\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 351ms/step - loss: -0.9417 - val_loss: -0.4484\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -1.0593 - val_loss: -0.4055\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -1.2837 - val_loss: -0.3375\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: -1.4635 - val_loss: -0.3770\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: -1.4566 - val_loss: -0.4025\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -1.8809 - val_loss: -0.4891\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 292ms/step - loss: -1.4692 - val_loss: -0.5685\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -1.5116 - val_loss: -0.5634\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -1.6296 - val_loss: -0.5398\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -1.6074 - val_loss: -0.5533\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -1.5285 - val_loss: -0.5721\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -1.4945 - val_loss: -0.5936\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 305ms/step - loss: -1.5930 - val_loss: -0.4974\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -1.5220 - val_loss: -0.6141\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 288ms/step - loss: -1.8683 - val_loss: -0.6341\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -1.5965 - val_loss: -0.6049\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -1.7870 - val_loss: -0.5770\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -1.8127 - val_loss: -0.5713\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -1.7457 - val_loss: -0.6052\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -1.5585 - val_loss: -0.5591\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -1.0555 - val_loss: -0.7883\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -1.0949 - val_loss: -0.6860\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -1.0991 - val_loss: -0.5653\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -1.1217 - val_loss: -0.4763\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -1.2375 - val_loss: -0.3910\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -1.3291 - val_loss: -0.2449\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.8622 - val_loss: -0.0510\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.8675 - val_loss: -0.0318\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.8636 - val_loss: -0.0401\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -1.0717 - val_loss: 0.0274\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.9454 - val_loss: -0.0060\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.9920 - val_loss: -0.1476\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.9571 - val_loss: -0.2003\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.9402 - val_loss: -0.2172\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.9336 - val_loss: -0.2239\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.9157 - val_loss: -0.2268\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.9812 - val_loss: -0.2323\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.9678 - val_loss: -0.2594\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -1.0374 - val_loss: -0.3824\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -1.0822 - val_loss: -0.5827\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -1.0990 - val_loss: -0.5500\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -1.0589 - val_loss: -0.4563\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -1.1346 - val_loss: -0.3287\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -1.1157 - val_loss: -0.3044\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -1.0448 - val_loss: -0.3874\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.9044 - val_loss: -0.6715\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.8538 - val_loss: -0.6044\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.8619 - val_loss: -0.6406\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.8280 - val_loss: -0.6291\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.8711 - val_loss: -0.5732\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.8809 - val_loss: -0.5484\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -0.7252 - val_loss: 0.1720\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.7399 - val_loss: 0.1449\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.6519 - val_loss: 0.2104\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -0.6706 - val_loss: 0.2629\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 286ms/step - loss: -0.7005 - val_loss: 0.2872\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -0.7139 - val_loss: 0.2716\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: -0.7202 - val_loss: 0.2187\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 403ms/step - loss: -0.3892 - val_loss: -0.4009\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -0.4171 - val_loss: -0.1086\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.3361 - val_loss: -0.0384\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -0.3228 - val_loss: -0.3245\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.3210 - val_loss: -0.7397\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -0.4117 - val_loss: -0.8575\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.4069 - val_loss: -0.8702\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -0.4110 - val_loss: -0.8668\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: -0.4080 - val_loss: -0.8620\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -0.4144 - val_loss: -0.8586\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -0.4103 - val_loss: -0.8561\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 313ms/step - loss: -0.4116 - val_loss: -0.8544\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: -0.3231 - val_loss: -0.6225\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.3184 - val_loss: -0.6208\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3388 - val_loss: -0.6198\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.3277 - val_loss: -0.6191\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.3236 - val_loss: -0.6186\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.3307 - val_loss: -0.6181\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -0.4221 - val_loss: -0.0015\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4366 - val_loss: 0.0031\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.4324 - val_loss: 0.0078\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4344 - val_loss: 0.0128\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4502 - val_loss: 0.0222\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4053 - val_loss: 0.0272\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -0.4141 - val_loss: 0.5137\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.4183 - val_loss: 0.5158\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4205 - val_loss: 0.5185\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4153 - val_loss: 0.5225\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4249 - val_loss: 0.5257\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.4090 - val_loss: 0.5305\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.1101 - val_loss: 0.1986\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.1098 - val_loss: 0.1985\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.1066 - val_loss: 0.1984\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.1078 - val_loss: 0.1987\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.1203 - val_loss: 0.1994\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.1283 - val_loss: 0.2008\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.1601 - val_loss: 0.2049\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.1891 - val_loss: 0.2194\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0803 - val_loss: -0.5291\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.0633 - val_loss: -0.5377\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.0965 - val_loss: -0.5431\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0691 - val_loss: -0.5134\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0798 - val_loss: -0.3830\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.0086 - val_loss: -0.2091\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.0621 - val_loss: -0.1398\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.0416 - val_loss: -0.1116\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 214ms/step - loss: -0.0108 - val_loss: -0.5414\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.0623 - val_loss: -0.9559\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0224 - val_loss: -1.3042\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.0617 - val_loss: -1.3502\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -0.0623 - val_loss: -1.1433\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.0819 - val_loss: -0.5792\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.1900 - val_loss: -0.0870\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.3466 - val_loss: 0.0069\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.3755 - val_loss: 0.0199\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 322ms/step - loss: -0.3845 - val_loss: -0.2701\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.3339 - val_loss: -0.4400\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -0.2597 - val_loss: -0.3454\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.3616 - val_loss: -0.1301\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -0.4430 - val_loss: -0.0342\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.4029 - val_loss: 0.0014\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -0.4492 - val_loss: 0.0122\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: -0.2656 - val_loss: 0.1933\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.2170 - val_loss: 0.2699\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: -0.2482 - val_loss: 0.2891\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: -0.2123 - val_loss: 0.2978\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.2236 - val_loss: 0.3011\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.2025 - val_loss: 0.3034\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.1874 - val_loss: 0.1611\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.2799 - val_loss: 0.0565\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4037 - val_loss: -0.0460\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3469 - val_loss: -0.0768\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.3014 - val_loss: -0.0892\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3418 - val_loss: -0.0930\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.3272 - val_loss: -0.0946\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3403 - val_loss: -0.0952\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.3276 - val_loss: -0.0955\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.3283 - val_loss: -0.0957\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3283 - val_loss: -0.0958\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.3270 - val_loss: -0.0958\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.3261 - val_loss: -0.0958\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3266 - val_loss: -0.0959\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.3274 - val_loss: -0.0959\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3271 - val_loss: -0.0959\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.3272 - val_loss: -0.0959\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3266 - val_loss: -0.0959\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3269 - val_loss: -0.0959\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3268 - val_loss: -0.0959\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 270ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -0.2223 - val_loss: -0.0599\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: -0.2788 - val_loss: -0.2590\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -0.2788 - val_loss: -0.2590\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -0.2788 - val_loss: -0.2590\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.2788 - val_loss: -0.2590\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.2787 - val_loss: -0.2590\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 295ms/step - loss: -0.2788 - val_loss: -0.2590\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 365ms/step - loss: -0.1732 - val_loss: 0.3652\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.1772 - val_loss: 0.3634\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.1913 - val_loss: 0.3584\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.1776 - val_loss: 0.3489\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.2022 - val_loss: 0.3228\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.2021 - val_loss: 0.2484\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.2013 - val_loss: 0.0811\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -0.2516 - val_loss: -0.0776\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2848 - val_loss: -0.1404\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.2923 - val_loss: -0.1611\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.2945 - val_loss: -0.1684\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.2959 - val_loss: -0.1712\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2970 - val_loss: -0.1724\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.2974 - val_loss: -0.1730\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2974 - val_loss: -0.1733\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.2975 - val_loss: -0.1735\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2975 - val_loss: -0.1736\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.2975 - val_loss: -0.1737\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.2975 - val_loss: -0.1737\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.2975 - val_loss: -0.1737\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.2975 - val_loss: -0.1738\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.2976 - val_loss: -0.1738\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -0.2793 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.2793 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.2793 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.2793 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.2793 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.2793 - val_loss: 0.0000e+00\n",
            "Only 4 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.2, 'epochs': 50, 'input_layer_size': 64, 'learning_rate': 0.001, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.3130 - val_loss: -1.8139\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.3314 - val_loss: -1.7974\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.3507 - val_loss: -1.7677\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.3657 - val_loss: -1.7324\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.3794 - val_loss: -1.6934\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3896 - val_loss: -1.6517\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.3812 - val_loss: -1.5450\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.3878 - val_loss: -1.5247\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.4101 - val_loss: -1.4996\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4270 - val_loss: -1.4705\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.4538 - val_loss: -1.4393\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.4709 - val_loss: -1.4064\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.4026 - val_loss: -0.4765\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4247 - val_loss: -0.4756\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4365 - val_loss: -0.4737\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.4579 - val_loss: -0.4707\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4752 - val_loss: -0.4678\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.4780 - val_loss: -0.4621\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.7596 - val_loss: -0.4103\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7808 - val_loss: -0.4098\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.7758 - val_loss: -0.4093\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.8014 - val_loss: -0.4099\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.8106 - val_loss: -0.4071\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.8235 - val_loss: -0.3990\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.7056 - val_loss: -0.4339\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.7130 - val_loss: -0.4326\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.7438 - val_loss: -0.4303\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.7407 - val_loss: -0.4281\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.7478 - val_loss: -0.4261\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.7692 - val_loss: -0.4275\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.5881 - val_loss: -0.0947\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5796 - val_loss: -0.0872\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.5922 - val_loss: -0.0813\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.6049 - val_loss: -0.0785\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6116 - val_loss: -0.0809\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.6336 - val_loss: -0.0867\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.3539 - val_loss: -0.0303\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.3802 - val_loss: -0.0271\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.3844 - val_loss: -0.0243\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.3959 - val_loss: -0.0222\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.3980 - val_loss: -0.0215\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.4056 - val_loss: -0.0221\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.2185 - val_loss: -0.4589\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.2262 - val_loss: -0.4594\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.2410 - val_loss: -0.4604\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.2295 - val_loss: -0.4615\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.2550 - val_loss: -0.4625\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.2572 - val_loss: -0.4632\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.2781 - val_loss: -0.4636\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.2731 - val_loss: -0.4642\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.3034 - val_loss: -0.4647\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.3039 - val_loss: -0.4657\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.3258 - val_loss: -0.4676\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.3213 - val_loss: -0.4699\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -0.3496 - val_loss: -0.4726\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -0.3557 - val_loss: -0.4765\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.3733 - val_loss: -0.4801\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.3767 - val_loss: -0.4841\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.4121 - val_loss: -0.4876\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.4198 - val_loss: -0.4901\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.4221 - val_loss: -0.4855\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.4588 - val_loss: -0.4814\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.4553 - val_loss: -0.4883\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.4843 - val_loss: -0.4855\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.5030 - val_loss: -0.4830\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 337ms/step - loss: -0.4009 - val_loss: -0.2810\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -0.4288 - val_loss: -0.2741\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.4115 - val_loss: -0.2652\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.4541 - val_loss: -0.2513\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.4621 - val_loss: -0.2346\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -0.5140 - val_loss: -0.2171\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.3531 - val_loss: -1.1968\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3567 - val_loss: -1.1730\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3845 - val_loss: -1.1453\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.3932 - val_loss: -1.1300\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4330 - val_loss: -1.0944\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4254 - val_loss: -1.1004\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -0.4582 - val_loss: -1.1190\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.4523 - val_loss: -1.1199\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.4981 - val_loss: -1.1428\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4912 - val_loss: -1.1693\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.5394 - val_loss: -1.1853\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.5247 - val_loss: -1.1811\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.5714 - val_loss: -1.1615\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.5663 - val_loss: -1.1414\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.6314 - val_loss: -1.1261\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.6436 - val_loss: -1.1184\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.7084 - val_loss: -0.0479\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.7252 - val_loss: -0.0469\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.7577 - val_loss: -0.0440\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7957 - val_loss: -0.0371\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.7651 - val_loss: -0.0289\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.8426 - val_loss: -0.0208\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.5415 - val_loss: -0.3572\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.5430 - val_loss: -0.3450\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.5640 - val_loss: -0.3367\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.6001 - val_loss: -0.3382\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6080 - val_loss: -0.3426\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.6342 - val_loss: -0.3410\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.5142 - val_loss: 0.0428\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.4767 - val_loss: 0.0411\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5072 - val_loss: 0.0319\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.5546 - val_loss: 0.0161\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.5665 - val_loss: 0.0039\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.5981 - val_loss: -0.0036\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.6215 - val_loss: -0.0087\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.6801 - val_loss: -0.0131\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.6778 - val_loss: -0.0178\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.7253 - val_loss: -0.0196\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.7286 - val_loss: -0.0207\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.8173 - val_loss: -0.0196\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.8223 - val_loss: -0.0193\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.8635 - val_loss: -0.0195\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.8653 - val_loss: -0.0218\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.9657 - val_loss: -0.0272\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.9865 - val_loss: -0.0306\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -1.0448 - val_loss: -0.0311\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -1.1700 - val_loss: -0.0332\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -1.1387 - val_loss: -0.0366\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -1.2488 - val_loss: -0.0401\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -1.2724 - val_loss: -0.0434\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -1.3076 - val_loss: -0.0459\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -1.3978 - val_loss: -0.0464\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -1.5264 - val_loss: -0.0424\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -1.5329 - val_loss: -0.0406\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -1.6761 - val_loss: -0.0424\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -1.9878 - val_loss: -0.0240\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -2.0433 - val_loss: -0.0338\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 333ms/step - loss: -0.6034 - val_loss: -0.7453\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.6057 - val_loss: -0.6479\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.6048 - val_loss: -0.5782\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.6285 - val_loss: -0.5775\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.6283 - val_loss: -0.5818\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.6302 - val_loss: -0.5800\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 275ms/step - loss: -0.4970 - val_loss: 0.0663\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5636 - val_loss: 0.0647\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.5588 - val_loss: 0.0630\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.6162 - val_loss: 0.0609\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.6796 - val_loss: 0.0586\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.6471 - val_loss: 0.0558\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.6509 - val_loss: 0.0541\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.7086 - val_loss: 0.0533\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.6548 - val_loss: 0.0534\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.7223 - val_loss: 0.0533\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.7237 - val_loss: 0.0525\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.7728 - val_loss: 0.0519\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.8357 - val_loss: 0.0509\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.8490 - val_loss: 0.0507\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.7906 - val_loss: 0.0513\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.9114 - val_loss: 0.0501\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.9686 - val_loss: 0.0492\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.9290 - val_loss: 0.0494\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.9582 - val_loss: 0.0498\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.9521 - val_loss: 0.0492\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.9518 - val_loss: 0.0474\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -1.0574 - val_loss: 0.0458\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -1.0381 - val_loss: 0.0452\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -1.0956 - val_loss: 0.0448\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -1.1764 - val_loss: 0.0435\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -1.2892 - val_loss: 0.0416\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -1.3162 - val_loss: 0.0407\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -1.2753 - val_loss: 0.0398\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -1.2686 - val_loss: 0.0400\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -1.2096 - val_loss: 0.0405\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -1.3246 - val_loss: 0.0376\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -1.6181 - val_loss: 0.0360\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -1.5758 - val_loss: 0.0349\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -1.5402 - val_loss: 0.0323\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -1.4951 - val_loss: 0.0553\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -1.4149 - val_loss: 0.0624\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.7967 - val_loss: 0.0565\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.7171 - val_loss: 0.0375\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.6102 - val_loss: 0.0439\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 326ms/step - loss: -0.4432 - val_loss: -0.6183\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.4629 - val_loss: -0.6024\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.3922 - val_loss: -0.5880\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.3434 - val_loss: -0.5755\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -0.3121 - val_loss: -0.5662\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.2529 - val_loss: -0.5588\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 418ms/step - loss: -0.3486 - val_loss: -0.7149\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.3870 - val_loss: -0.7186\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.3171 - val_loss: -0.7209\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.3470 - val_loss: -0.7211\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.3732 - val_loss: -0.7187\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.3839 - val_loss: -0.7172\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.4161 - val_loss: -0.7172\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.3749 - val_loss: -0.7171\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.4004 - val_loss: -0.7168\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 318ms/step - loss: -0.3934 - val_loss: -0.0528\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.4121 - val_loss: -0.0405\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -0.3919 - val_loss: -0.0532\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.4343 - val_loss: -0.0745\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.4316 - val_loss: -0.0655\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.4480 - val_loss: -0.0570\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.4342 - val_loss: -0.0324\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.4538 - val_loss: -0.0163\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.4427 - val_loss: -0.0034\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 325ms/step - loss: -0.2495 - val_loss: -0.0755\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.2788 - val_loss: -0.0761\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.2615 - val_loss: -0.0773\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.2786 - val_loss: -0.0747\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.2748 - val_loss: -0.0715\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.3118 - val_loss: -0.0691\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.3074 - val_loss: -0.0677\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.3025 - val_loss: -0.0666\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.3721 - val_loss: -0.0979\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.3588 - val_loss: -0.0981\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.4002 - val_loss: -0.0961\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.3837 - val_loss: -0.0932\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.4422 - val_loss: -0.0894\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4376 - val_loss: -0.0873\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.4215 - val_loss: -0.0826\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.1699 - val_loss: 0.6585\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.2099 - val_loss: 0.6508\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.2167 - val_loss: 0.6450\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.1835 - val_loss: 0.6414\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.2458 - val_loss: 0.6338\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.2588 - val_loss: 0.6214\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.2471 - val_loss: 0.6087\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.2620 - val_loss: 0.6008\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2464 - val_loss: 0.5962\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.2550 - val_loss: 0.5979\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.2519 - val_loss: 0.5908\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -0.3024 - val_loss: 0.5741\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.3056 - val_loss: 0.5647\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.3408 - val_loss: 0.5559\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.3080 - val_loss: 0.5498\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.3568 - val_loss: 0.5461\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.3358 - val_loss: 0.5436\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -0.3483 - val_loss: 0.5419\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.3694 - val_loss: 0.5372\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.3472 - val_loss: 0.5267\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.3729 - val_loss: 0.5166\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.3735 - val_loss: 0.5079\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3997 - val_loss: 0.4994\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.4005 - val_loss: 0.4916\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.3959 - val_loss: 0.4855\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.3837 - val_loss: 0.4781\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.4030 - val_loss: 0.4707\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 273ms/step - loss: -0.4162 - val_loss: 0.4608\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.4464 - val_loss: 0.4491\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.4678 - val_loss: 0.4368\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.4246 - val_loss: 0.4269\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.4490 - val_loss: 0.4203\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.4359 - val_loss: 0.4181\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -0.5132 - val_loss: 0.4194\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.4916 - val_loss: 0.4184\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.4872 - val_loss: 0.4137\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.5093 - val_loss: 0.4063\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -0.5032 - val_loss: 0.3959\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 282ms/step - loss: -0.5585 - val_loss: 0.3844\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.5274 - val_loss: 0.3729\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: -0.5489 - val_loss: 0.3587\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.5680 - val_loss: 0.3451\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.5438 - val_loss: 0.3308\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5857 - val_loss: 0.3165\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.5447 - val_loss: 0.3022\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5864 - val_loss: 0.2854\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.5599 - val_loss: 0.2704\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.5669 - val_loss: 0.2576\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.5548 - val_loss: 0.2495\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.6262 - val_loss: 0.2431\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 317ms/step - loss: -0.2573 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.3003 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.3504 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.3553 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.3649 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.3783 - val_loss: 0.0000e+00\n",
            "Only 3 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.2, 'epochs': 50, 'input_layer_size': 64, 'learning_rate': 0.01, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.3070 - val_loss: -1.6151\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.3867 - val_loss: -1.4873\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4558 - val_loss: -1.2764\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.5281 - val_loss: -1.0885\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.6180 - val_loss: -0.6432\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.7025 - val_loss: -0.5156\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.4334 - val_loss: -1.2394\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.4934 - val_loss: -1.0295\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.6807 - val_loss: -0.7490\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.8908 - val_loss: -0.6183\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.4466 - val_loss: -0.5611\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.4168 - val_loss: -0.5216\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.4922 - val_loss: -0.4233\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.5975 - val_loss: -0.4238\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.6920 - val_loss: -0.4010\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -0.7678 - val_loss: -0.3960\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.6869 - val_loss: -0.5085\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.3328 - val_loss: -0.5070\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.4290 - val_loss: -0.5071\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.5180 - val_loss: -0.5135\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.5267 - val_loss: -0.5293\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.9095 - val_loss: -0.5472\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.9342 - val_loss: -0.5660\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.6751 - val_loss: -0.5980\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -0.7248 - val_loss: -0.6283\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.7412 - val_loss: -0.6446\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.8123 - val_loss: -0.6548\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.7574 - val_loss: -0.6482\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.8440 - val_loss: -0.6393\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.9520 - val_loss: -0.3982\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.7707 - val_loss: -0.4308\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.8566 - val_loss: -0.7153\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.9462 - val_loss: -0.7171\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.9761 - val_loss: -0.7161\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -1.1251 - val_loss: -0.5116\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.9431 - val_loss: -0.6864\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3914 - val_loss: -0.6489\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4709 - val_loss: -0.5863\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -1.0481 - val_loss: -0.3570\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -1.0362 - val_loss: -0.3641\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -1.0136 - val_loss: -0.3445\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -1.0830 - val_loss: -0.3109\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -1.0242 - val_loss: -0.2880\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -1.2088 - val_loss: -0.2609\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.9775 - val_loss: -0.5113\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.9355 - val_loss: -0.4708\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -1.5856 - val_loss: -0.0700\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -1.1777 - val_loss: -0.4757\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.7597 - val_loss: 0.0635\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -1.5625 - val_loss: 0.1261\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: -0.9744 - val_loss: -0.5132\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.8935 - val_loss: -0.8575\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.8589 - val_loss: -1.0206\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -0.9048 - val_loss: -1.1280\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.8314 - val_loss: -1.1694\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.9912 - val_loss: -1.1350\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -1.0298 - val_loss: -1.0403\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 232ms/step - loss: -1.0272 - val_loss: -0.9700\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -1.0114 - val_loss: -0.9280\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -1.0215 - val_loss: -0.8960\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 338ms/step - loss: -0.8170 - val_loss: -1.0404\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.8873 - val_loss: -1.0401\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.8671 - val_loss: -1.0018\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.8104 - val_loss: -0.9488\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.8628 - val_loss: -0.8642\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.8288 - val_loss: -0.8361\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.7377 - val_loss: 0.1430\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.7716 - val_loss: 0.1526\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.7456 - val_loss: 0.1601\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.7383 - val_loss: 0.1659\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.7834 - val_loss: 0.0415\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.7256 - val_loss: 0.0480\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.7699 - val_loss: 0.0531\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.7687 - val_loss: -0.0710\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7825 - val_loss: -0.0678\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.7698 - val_loss: -0.0622\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.7704 - val_loss: -0.0564\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.7610 - val_loss: -0.0515\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.7547 - val_loss: -0.0507\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.5029 - val_loss: -0.0532\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.4575 - val_loss: -0.0520\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.4868 - val_loss: -0.2111\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.5101 - val_loss: -0.2180\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.5017 - val_loss: -0.2289\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 151ms/step - loss: -0.5393 - val_loss: -0.2581\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.5103 - val_loss: 0.2049\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.5485 - val_loss: 0.2073\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -0.5612 - val_loss: 0.2061\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5851 - val_loss: 0.1992\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.5739 - val_loss: 0.1780\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.5712 - val_loss: -0.1228\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.4439 - val_loss: -0.1333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4789 - val_loss: -0.1451\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.4819 - val_loss: -0.1662\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4287 - val_loss: -0.1916\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4105 - val_loss: -0.1934\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.4066 - val_loss: -0.1283\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.4260 - val_loss: -0.1461\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4308 - val_loss: -0.0765\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.2929 - val_loss: -0.0880\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.3579 - val_loss: -0.1997\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.3896 - val_loss: 0.0026\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.7285 - val_loss: -0.0815\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.4026 - val_loss: -0.0846\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.3842 - val_loss: -0.0797\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.4230 - val_loss: -0.1461\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.3260 - val_loss: -0.5696\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.2570 - val_loss: -1.1593\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.2569 - val_loss: -1.3109\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.3183 - val_loss: -1.5971\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.4139 - val_loss: -1.5559\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.3793 - val_loss: -1.3766\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.4036 - val_loss: -1.0694\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4193 - val_loss: -0.8259\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.2660 - val_loss: -0.6483\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 343ms/step - loss: -0.3726 - val_loss: -0.6174\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.5005 - val_loss: -0.6051\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 231ms/step - loss: -0.5554 - val_loss: -0.5768\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.6468 - val_loss: -0.4841\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.5558 - val_loss: -0.4351\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.6946 - val_loss: -0.4893\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.5105 - val_loss: 0.1088\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.6014 - val_loss: 0.1241\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.6854 - val_loss: 0.1438\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.7221 - val_loss: 0.1646\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5371 - val_loss: 0.1674\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7414 - val_loss: 0.1492\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.4340 - val_loss: -0.4626\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.4139 - val_loss: -0.4245\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.3184 - val_loss: -0.3871\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.4753 - val_loss: -0.3578\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 141ms/step - loss: -0.4673 - val_loss: -0.3122\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5268 - val_loss: -0.1048\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.5099 - val_loss: -0.1673\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4850 - val_loss: -0.0778\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.5328 - val_loss: -0.0220\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.5304 - val_loss: -0.0048\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.4783 - val_loss: -0.0393\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.6581 - val_loss: -0.1097\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.2237 - val_loss: -0.9177\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.3753 - val_loss: -1.0607\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.5707 - val_loss: -1.3742\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.5135 - val_loss: -1.7229\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4905 - val_loss: -1.7206\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.5468 - val_loss: -1.4882\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6037 - val_loss: -1.3055\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.7356 - val_loss: -1.2931\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.6740 - val_loss: -1.3892\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.5536 - val_loss: -0.0636\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7039 - val_loss: -0.0575\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.7418 - val_loss: -0.0516\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.7593 - val_loss: -0.0745\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7186 - val_loss: -0.0749\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.7061 - val_loss: -0.1084\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.7768 - val_loss: -0.1376\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.9331 - val_loss: -0.1653\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.9437 - val_loss: -0.1787\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.6741 - val_loss: -0.1996\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.7382 - val_loss: -0.2028\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.7867 - val_loss: -0.2307\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.9135 - val_loss: -0.2519\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.9693 - val_loss: -0.2766\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -0.8840 - val_loss: -0.2859\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -1.0255 - val_loss: -0.2771\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -1.0164 - val_loss: -0.2465\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -1.0056 - val_loss: -0.2651\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -1.0644 - val_loss: -0.2880\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -1.0629 - val_loss: -0.2938\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -1.0123 - val_loss: -0.2998\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.9287 - val_loss: -0.3000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -1.0635 - val_loss: -0.3215\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -1.0535 - val_loss: -0.3397\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.9920 - val_loss: -0.3565\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -1.0613 - val_loss: -0.3412\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.9239 - val_loss: -0.3396\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -1.0811 - val_loss: -0.3322\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -1.1523 - val_loss: -0.3328\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -1.0304 - val_loss: -0.3472\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -0.7004 - val_loss: -0.4194\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.6735 - val_loss: -0.4021\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.7201 - val_loss: -0.3759\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.7297 - val_loss: -0.3497\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.7747 - val_loss: -0.3220\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 210ms/step - loss: -0.7845 - val_loss: -0.2985\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.4813 - val_loss: -0.0439\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4343 - val_loss: -0.0784\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.5378 - val_loss: -0.1268\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.5129 - val_loss: -0.1824\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.4680 - val_loss: -0.2280\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.6457 - val_loss: -0.2556\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.4668 - val_loss: -0.2863\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.5825 - val_loss: -0.3254\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.7440 - val_loss: -0.3418\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.5380 - val_loss: -0.3590\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.6606 - val_loss: -0.3656\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.7773 - val_loss: -0.3829\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.6248 - val_loss: -0.3956\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.6285 - val_loss: -0.3709\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 148ms/step - loss: -0.7127 - val_loss: -0.3448\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.6813 - val_loss: -0.3268\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 147ms/step - loss: -0.7540 - val_loss: -0.3222\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.6924 - val_loss: -0.3131\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.7463 - val_loss: -0.5348\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.7202 - val_loss: -0.5490\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.6795 - val_loss: -0.5571\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6703 - val_loss: -0.5652\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.7254 - val_loss: -0.5668\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.7847 - val_loss: -0.5499\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.6947 - val_loss: -0.5220\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.7853 - val_loss: -0.4767\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.7003 - val_loss: -0.4465\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.7045 - val_loss: -0.4359\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.5948 - val_loss: 0.3478\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.6457 - val_loss: 0.3273\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 143ms/step - loss: -0.6488 - val_loss: 0.2904\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -0.6308 - val_loss: 0.2721\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 146ms/step - loss: -0.6149 - val_loss: 0.2727\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.6475 - val_loss: 0.2925\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.5821 - val_loss: 0.3263\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.6574 - val_loss: 0.3843\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.6997 - val_loss: 0.4510\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -0.3347 - val_loss: -0.3300\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -0.3327 - val_loss: -0.3124\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.3034 - val_loss: -0.2970\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.2145 - val_loss: -0.2979\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 205ms/step - loss: -0.2619 - val_loss: -0.3047\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.2978 - val_loss: -0.3124\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 330ms/step - loss: -0.1831 - val_loss: 0.4749\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.2764 - val_loss: 0.5063\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.2770 - val_loss: 0.5675\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.2149 - val_loss: 0.6571\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.2424 - val_loss: 0.7716\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.2569 - val_loss: 0.9159\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.0898 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 135ms/step - loss: -0.1235 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.1283 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -0.1456 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.1822 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 145ms/step - loss: -0.1861 - val_loss: 0.0000e+00\n",
            "Only 2 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.2, 'epochs': 50, 'input_layer_size': 128, 'learning_rate': 0.001, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.3332 - val_loss: -1.8003\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.3735 - val_loss: -1.7949\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4058 - val_loss: -1.8016\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4419 - val_loss: -1.8283\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.4761 - val_loss: -1.8368\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5272 - val_loss: -1.8327\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.5549 - val_loss: -1.8292\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.6169 - val_loss: -1.8212\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.6470 - val_loss: -1.8988\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.7149 - val_loss: -1.9491\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.7963 - val_loss: -1.9476\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.8322 - val_loss: -1.9733\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.8773 - val_loss: -1.6180\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.9743 - val_loss: -1.8158\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -1.0716 - val_loss: -1.7527\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -1.1638 - val_loss: -1.4487\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -1.2322 - val_loss: -1.2117\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.9378 - val_loss: -0.9940\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -1.0727 - val_loss: -0.7810\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -1.0322 - val_loss: -0.9586\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -1.2279 - val_loss: -0.9338\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -1.2701 - val_loss: -0.9256\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -1.3760 - val_loss: -0.6785\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 329ms/step - loss: -0.9876 - val_loss: -0.2927\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -0.8779 - val_loss: -0.2841\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.9183 - val_loss: -0.2565\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -1.1136 - val_loss: -0.2507\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.9564 - val_loss: -0.4022\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.6927 - val_loss: -0.3522\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.7211 - val_loss: -0.3110\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -0.8030 - val_loss: -0.3134\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 223ms/step - loss: -0.9654 - val_loss: -0.2883\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -1.0048 - val_loss: -0.2189\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 348ms/step - loss: -0.8198 - val_loss: -0.4222\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -0.8173 - val_loss: -0.3933\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.8808 - val_loss: -0.3644\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.9081 - val_loss: -0.3498\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.9367 - val_loss: -0.3469\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.9356 - val_loss: -0.3793\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.5745 - val_loss: -0.4329\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.6310 - val_loss: -0.4483\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.6768 - val_loss: -0.4557\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.6847 - val_loss: -0.4656\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.6705 - val_loss: -0.4120\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.6368 - val_loss: -0.4298\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.7166 - val_loss: -0.4294\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.7705 - val_loss: -0.4927\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.6676 - val_loss: -0.4015\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.6961 - val_loss: -0.4604\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.6730 - val_loss: -0.4326\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.7436 - val_loss: -0.4411\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.7533 - val_loss: -0.4445\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.5676 - val_loss: -0.0674\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.6031 - val_loss: -0.0860\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.5751 - val_loss: -0.1995\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.5982 - val_loss: -0.1861\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5632 - val_loss: -0.0759\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.6235 - val_loss: -0.0854\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5578 - val_loss: -0.0142\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.6886 - val_loss: -0.0260\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.3950 - val_loss: -0.0280\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -0.3697 - val_loss: -0.0025\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3729 - val_loss: -0.0324\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.3468 - val_loss: -0.0757\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3712 - val_loss: 0.0071\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3375 - val_loss: 0.0233\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3523 - val_loss: -0.0342\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3376 - val_loss: -0.0632\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.3578 - val_loss: -0.0123\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.2443 - val_loss: -0.3777\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.2085 - val_loss: -0.4219\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.2257 - val_loss: -0.5797\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2520 - val_loss: -0.5084\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2686 - val_loss: -0.4917\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.2538 - val_loss: -0.3877\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.2413 - val_loss: -0.4672\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2634 - val_loss: -0.3819\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 382ms/step - loss: -0.3009 - val_loss: -0.0997\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.2541 - val_loss: -0.0966\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -0.2838 - val_loss: -0.0632\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -0.2737 - val_loss: -0.2297\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -0.2423 - val_loss: -0.0489\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.2124 - val_loss: -0.0589\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.2880 - val_loss: -0.2184\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.2815 - val_loss: -0.1482\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -0.3099 - val_loss: -0.2370\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -0.3745 - val_loss: -0.1194\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.3206 - val_loss: -0.2320\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2720 - val_loss: -0.2284\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.2955 - val_loss: -0.2576\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.3506 - val_loss: -0.0661\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -0.3288 - val_loss: -0.0897\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -0.3271 - val_loss: -0.2294\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -0.3502 - val_loss: -0.2531\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -0.3367 - val_loss: -0.2445\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 359ms/step - loss: -0.2780 - val_loss: -0.7396\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.2913 - val_loss: -1.7530\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.2549 - val_loss: -0.9717\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2272 - val_loss: -1.6938\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3058 - val_loss: -1.7746\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.2737 - val_loss: -1.0083\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3252 - val_loss: -0.7079\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.2864 - val_loss: -1.8619\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3577 - val_loss: -2.2021\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.2227 - val_loss: -0.6296\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.2112 - val_loss: -0.5771\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3350 - val_loss: -0.9325\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2567 - val_loss: -2.2278\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.3028 - val_loss: -0.5515\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.2269 - val_loss: -2.2856\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3351 - val_loss: -1.8482\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.3017 - val_loss: -0.4227\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2722 - val_loss: -0.4318\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3179 - val_loss: -0.6458\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.2220 - val_loss: -2.4160\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3554 - val_loss: -0.7913\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3177 - val_loss: -0.5735\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.3164 - val_loss: -0.6183\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.2663 - val_loss: -2.7340\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4229 - val_loss: -1.7232\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3633 - val_loss: -1.4235\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.2901 - val_loss: -0.4564\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.3134 - val_loss: -1.1612\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.2897 - val_loss: -0.5454\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 335ms/step - loss: -0.5562 - val_loss: -1.1263\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -0.3342 - val_loss: -0.6878\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.3425 - val_loss: -0.5134\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -0.4961 - val_loss: -1.5777\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: -0.3765 - val_loss: -1.3712\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.4694 - val_loss: -0.4988\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -0.4254 - val_loss: -0.6341\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 229ms/step - loss: -0.3684 - val_loss: -0.5992\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: -0.4342 - val_loss: -0.6184\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 359ms/step - loss: -0.7503 - val_loss: -0.0298\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 218ms/step - loss: -0.6930 - val_loss: 0.1201\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.7732 - val_loss: -0.1263\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -0.5694 - val_loss: 0.4049\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -0.5484 - val_loss: 0.3829\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.5693 - val_loss: 0.0367\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.5024 - val_loss: -0.0837\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -0.7357 - val_loss: 0.0094\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 356ms/step - loss: -0.4888 - val_loss: -0.6332\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.3911 - val_loss: -0.5341\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -0.5367 - val_loss: -0.4921\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -0.5967 - val_loss: -0.5424\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.5089 - val_loss: -0.5900\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.3729 - val_loss: -0.6182\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 202ms/step - loss: -0.5003 - val_loss: -0.0801\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4360 - val_loss: 0.0458\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.3107 - val_loss: -0.1354\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.3643 - val_loss: -0.0774\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.6423 - val_loss: -0.0817\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.2833 - val_loss: -0.0927\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.2813 - val_loss: -0.0580\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.6894 - val_loss: -0.1711\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.3065 - val_loss: -0.1476\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4453 - val_loss: -0.1885\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.6770 - val_loss: -0.1395\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.4855 - val_loss: 0.0332\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4172 - val_loss: -0.0878\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.6656 - val_loss: -0.2083\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.6108 - val_loss: -0.1638\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4485 - val_loss: -0.2170\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.7460 - val_loss: -0.1204\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.4549 - val_loss: -0.2498\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.7357 - val_loss: -0.0021\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.6044 - val_loss: -0.1135\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.5061 - val_loss: -0.1862\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.5550 - val_loss: -0.2433\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.7385 - val_loss: -0.0857\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.4610 - val_loss: -0.8939\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.3451 - val_loss: -1.8719\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3322 - val_loss: -0.7611\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.2258 - val_loss: -0.9164\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.3738 - val_loss: -0.7113\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.2427 - val_loss: -0.8568\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.2691 - val_loss: -0.8285\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.4693 - val_loss: 0.0367\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3460 - val_loss: 0.0738\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.4929 - val_loss: 0.2046\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.2099 - val_loss: 0.0115\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3976 - val_loss: 0.1645\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.2375 - val_loss: 0.2032\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.1990 - val_loss: 0.2066\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.1906 - val_loss: 0.2549\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3563 - val_loss: 0.1478\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.2671 - val_loss: -0.5107\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.1052 - val_loss: -0.4036\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 195ms/step - loss: -0.2739 - val_loss: -0.5530\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.1503 - val_loss: -0.4576\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.1631 - val_loss: -0.5356\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -0.0758 - val_loss: -0.6362\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -0.1279 - val_loss: -0.4559\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.2409 - val_loss: -0.4211\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -0.3341 - val_loss: -0.4265\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -0.2749 - val_loss: -0.3587\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 283ms/step - loss: -0.2407 - val_loss: -0.7074\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: -0.2062 - val_loss: -0.6468\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.1908 - val_loss: -0.5486\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.1984 - val_loss: -0.4638\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.2288 - val_loss: -0.3965\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 289ms/step - loss: -0.3242 - val_loss: -0.8425\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.1651 - val_loss: -0.6354\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.2676 - val_loss: -0.7783\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.2256 - val_loss: -0.5806\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 288ms/step - loss: -0.3339 - val_loss: -0.7081\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -0.2069 - val_loss: -0.7699\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: -0.1960 - val_loss: -0.9624\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 269ms/step - loss: -0.2515 - val_loss: -0.9644\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.2401 - val_loss: -0.2103\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -0.1614 - val_loss: -0.2469\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -0.2406 - val_loss: -0.0778\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.3093 - val_loss: -0.2265\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 230ms/step - loss: -0.2945 - val_loss: -0.1266\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.2516 - val_loss: -0.4407\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.2193 - val_loss: 0.1410\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.2541 - val_loss: 0.0132\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3699 - val_loss: 0.1322\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.3240 - val_loss: -0.1544\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3137 - val_loss: -0.4104\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.2206 - val_loss: -0.1852\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.1620 - val_loss: 0.0469\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.1541 - val_loss: 0.0740\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.3341 - val_loss: 0.0476\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.2756 - val_loss: -0.2427\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2496 - val_loss: 0.0827\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.2278 - val_loss: 0.0522\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.2289 - val_loss: -0.1946\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.1848 - val_loss: 0.1834\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.2686 - val_loss: 0.1082\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 216ms/step - loss: -0.3327 - val_loss: -0.1568\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.2284 - val_loss: -0.0316\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3399 - val_loss: -0.0741\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.2156 - val_loss: -0.1820\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.2985 - val_loss: -0.1377\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.3733 - val_loss: 0.0808\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.3271 - val_loss: -0.2170\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.2988 - val_loss: -0.2664\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.2385 - val_loss: -0.2537\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.2075 - val_loss: -0.1572\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3572 - val_loss: -0.0533\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2000 - val_loss: -0.1481\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.3499 - val_loss: -0.2485\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.1462 - val_loss: 0.0191\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.1151 - val_loss: 0.4508\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.1368 - val_loss: -0.0498\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.1759 - val_loss: 0.1126\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.1326 - val_loss: 0.1068\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.1349 - val_loss: 0.1198\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.1448 - val_loss: 0.7062\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.1594 - val_loss: -0.0648\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.1841 - val_loss: 0.2341\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -7.8799e-04 - val_loss: 0.1474\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.1743 - val_loss: 0.1948\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -0.1974 - val_loss: -0.0868\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 268ms/step - loss: -0.1634 - val_loss: 0.2786\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.2167 - val_loss: -0.0406\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 207ms/step - loss: -0.1631 - val_loss: 0.2561\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.2320 - val_loss: 0.3732\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.2860 - val_loss: 0.1866\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 372ms/step - loss: -0.1339 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 212ms/step - loss: -0.0948 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.1220 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.0495 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.0563 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.0114 - val_loss: 0.0000e+00\n",
            "Only 1 left!!\n",
            "Testing parameters:  {'dropout_rate': 0.2, 'epochs': 50, 'input_layer_size': 128, 'learning_rate': 0.01, 'optimizer': 'adam', 'window_type': 'fix'}\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.3021 - val_loss: -1.7732\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3920 - val_loss: -2.0714\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.3569 - val_loss: -1.7888\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.4221 - val_loss: -1.8576\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: -0.3270 - val_loss: -1.1202\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.1943 - val_loss: -2.1131\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.2113 - val_loss: -1.3853\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5392 - val_loss: -1.9391\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3218 - val_loss: -0.8939\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.4337 - val_loss: -1.6857\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.6676 - val_loss: -0.9343\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.3099 - val_loss: -0.7041\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5301 - val_loss: -1.4291\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.4711 - val_loss: -1.5276\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4112 - val_loss: -0.5622\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4186 - val_loss: -1.0433\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2732 - val_loss: -1.3137\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4910 - val_loss: -0.4745\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.6552 - val_loss: -0.8300\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.3525 - val_loss: -0.5281\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.3851 - val_loss: -0.3446\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.4853 - val_loss: 0.0566\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.7605 - val_loss: 0.2790\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.8390 - val_loss: -0.4091\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.3540 - val_loss: -0.5007\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.5323 - val_loss: -0.2949\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5076 - val_loss: -0.3122\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.5139 - val_loss: -0.6029\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.8031 - val_loss: -0.5410\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.7047 - val_loss: -0.5164\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.8344 - val_loss: -0.8460\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3835 - val_loss: -1.7306\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5355 - val_loss: -0.0050\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.7487 - val_loss: -0.3296\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.3795 - val_loss: 2.7992\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.9482 - val_loss: -0.0225\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 248ms/step - loss: -0.4904 - val_loss: -0.4377\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 344ms/step - loss: -0.6241 - val_loss: -0.7376\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -0.7491 - val_loss: -0.6255\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.7152 - val_loss: -0.9380\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -0.7286 - val_loss: -0.4366\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.5662 - val_loss: -0.9736\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.5205 - val_loss: -0.9472\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.5399 - val_loss: -0.8506\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 199ms/step - loss: -0.6153 - val_loss: -0.7635\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.7329 - val_loss: -0.6223\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.5914 - val_loss: -0.5883\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 339ms/step - loss: -0.6368 - val_loss: -0.2685\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 241ms/step - loss: -0.5891 - val_loss: -0.2512\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 250ms/step - loss: -0.5377 - val_loss: -0.2867\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.6184 - val_loss: -0.4967\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.6944 - val_loss: -0.7292\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -0.6663 - val_loss: -0.7862\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 209ms/step - loss: -0.6818 - val_loss: -0.7743\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.7174 - val_loss: -0.6822\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -0.7892 - val_loss: -0.6614\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 311ms/step - loss: -0.8536 - val_loss: -0.6532\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.9055 - val_loss: -0.6591\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.5534 - val_loss: 0.0270\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5588 - val_loss: 0.0134\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.5660 - val_loss: -0.0484\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.7179 - val_loss: -0.2220\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.8213 - val_loss: -0.3144\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.7909 - val_loss: -0.3457\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.8095 - val_loss: -0.3522\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.7730 - val_loss: -0.3618\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.8158 - val_loss: -0.3620\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.7902 - val_loss: -0.3596\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.7884 - val_loss: -0.3555\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 186ms/step - loss: -0.8006 - val_loss: -0.3429\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.8081 - val_loss: -0.3137\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.8209 - val_loss: -0.2690\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.5898 - val_loss: -0.1295\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.5855 - val_loss: -0.1284\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.5859 - val_loss: -0.1267\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.5987 - val_loss: -0.1248\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5654 - val_loss: -0.1252\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.5872 - val_loss: -0.1265\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 219ms/step - loss: -0.4974 - val_loss: -0.5461\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5030 - val_loss: -0.5466\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5017 - val_loss: -0.5474\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5006 - val_loss: -0.5482\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5024 - val_loss: -0.5488\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.5021 - val_loss: -0.5493\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.5026 - val_loss: -0.5496\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.5021 - val_loss: -0.5499\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.5030 - val_loss: -0.5501\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.5025 - val_loss: -0.5503\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5026 - val_loss: -0.5505\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 198ms/step - loss: -0.5030 - val_loss: -0.5506\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 185ms/step - loss: -0.5022 - val_loss: -0.5507\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5028 - val_loss: -0.5507\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.5029 - val_loss: -0.5508\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.5028 - val_loss: -0.5508\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.5034 - val_loss: -0.5509\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.5028 - val_loss: -0.5509\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.5026 - val_loss: -0.5509\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 260ms/step - loss: -0.5031 - val_loss: -0.5510\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.5029 - val_loss: -0.5510\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.5030 - val_loss: -0.5510\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 244ms/step - loss: -0.5028 - val_loss: -0.5510\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.5030 - val_loss: -0.5510\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 236ms/step - loss: -0.5030 - val_loss: -0.5510\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.5029 - val_loss: -0.5510\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.5028 - val_loss: -0.5510\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.5029 - val_loss: -0.5510\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 256ms/step - loss: -0.5029 - val_loss: -0.5511\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -0.5031 - val_loss: -0.5511\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 287ms/step - loss: -0.5031 - val_loss: -0.5511\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.5029 - val_loss: -0.5511\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 211ms/step - loss: -0.5029 - val_loss: -0.5511\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 235ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.5029 - val_loss: -0.5511\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.5031 - val_loss: -0.5511\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 255ms/step - loss: -0.5031 - val_loss: -0.5511\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.5032 - val_loss: -0.5511\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.5029 - val_loss: -0.5511\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 312ms/step - loss: -0.5029 - val_loss: -0.5511\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 257ms/step - loss: -0.5030 - val_loss: -0.5511\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.4178 - val_loss: -0.5131\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4177 - val_loss: -0.5131\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4179 - val_loss: -0.5131\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4180 - val_loss: -0.5131\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4178 - val_loss: -0.5131\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.4178 - val_loss: -0.5131\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.4177 - val_loss: -0.5131\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 200ms/step - loss: -0.3757 - val_loss: -1.3309\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3754 - val_loss: -1.3309\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.3755 - val_loss: -1.3309\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3756 - val_loss: -1.3309\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 173ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.3755 - val_loss: -1.3310\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 213ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.3754 - val_loss: -1.3310\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.3757 - val_loss: -1.3310\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 191ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 222ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 263ms/step - loss: -0.3756 - val_loss: -1.3310\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 331ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 280ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 227ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 261ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 254ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 240ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 228ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 296ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 258ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 284ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 279ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 290ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 276ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 152ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 181ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 158ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 187ms/step - loss: -0.5225 - val_loss: -0.6957\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: -0.5224 - val_loss: -0.6957\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 264ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 245ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 233ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 238ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.5226 - val_loss: -0.6957\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.5227 - val_loss: -0.6957\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 206ms/step - loss: -0.6702 - val_loss: -0.0986\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.6701 - val_loss: -0.0986\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.6702 - val_loss: -0.0986\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.6702 - val_loss: -0.0986\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.6701 - val_loss: -0.0986\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -0.6702 - val_loss: -0.0986\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 204ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4798 - val_loss: -0.3696\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4798 - val_loss: -0.3696\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 182ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 183ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 175ms/step - loss: -0.4798 - val_loss: -0.3696\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 184ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 224ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 221ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 301ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.4798 - val_loss: -0.3696\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 226ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 246ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 253ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 262ms/step - loss: -0.4798 - val_loss: -0.3696\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 249ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 243ms/step - loss: -0.4798 - val_loss: -0.3696\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 277ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: -0.4797 - val_loss: -0.3696\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.4336 - val_loss: -0.6196\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.4336 - val_loss: -0.6196\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4336 - val_loss: -0.6196\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.4336 - val_loss: -0.6196\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 251ms/step - loss: -0.4335 - val_loss: -0.6196\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 247ms/step - loss: -0.4336 - val_loss: -0.6196\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 393ms/step - loss: -0.3670 - val_loss: 0.0286\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 278ms/step - loss: -0.3670 - val_loss: 0.0286\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 239ms/step - loss: -0.3670 - val_loss: 0.0286\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 237ms/step - loss: -0.3670 - val_loss: 0.0286\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 267ms/step - loss: -0.3670 - val_loss: 0.0286\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.3670 - val_loss: 0.0286\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.1148 - val_loss: -0.8965\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.1151 - val_loss: -0.8965\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 203ms/step - loss: -0.1149 - val_loss: -0.8965\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.1149 - val_loss: -0.8965\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.1149 - val_loss: -0.8965\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.1148 - val_loss: -0.8965\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 217ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 160ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 177ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.2268 - val_loss: 0.0021\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 201ms/step - loss: -0.1727 - val_loss: -0.5229\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 161ms/step - loss: -0.1726 - val_loss: -0.5229\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.1727 - val_loss: -0.5229\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 225ms/step - loss: -0.1726 - val_loss: -0.5229\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.1726 - val_loss: -0.5229\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.1727 - val_loss: -0.5229\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.1726 - val_loss: -0.5229\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.1727 - val_loss: -0.5229\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 188ms/step - loss: -0.1727 - val_loss: -0.5229\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 164ms/step - loss: -0.1726 - val_loss: -0.5229\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 208ms/step - loss: -0.1788 - val_loss: 0.1094\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 159ms/step - loss: -0.1788 - val_loss: 0.1094\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 156ms/step - loss: -0.1789 - val_loss: 0.1094\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -0.1788 - val_loss: 0.1094\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 178ms/step - loss: -0.1788 - val_loss: 0.1094\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.1789 - val_loss: 0.1094\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 194ms/step - loss: -0.2922 - val_loss: -0.3256\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.2922 - val_loss: -0.3256\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 196ms/step - loss: -0.2922 - val_loss: -0.3256\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.2922 - val_loss: -0.3256\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.2922 - val_loss: -0.3256\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 172ms/step - loss: -0.2922 - val_loss: -0.3256\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 215ms/step - loss: -0.1674 - val_loss: -0.1524\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.1674 - val_loss: -0.1524\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -0.1674 - val_loss: -0.1524\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: -0.1674 - val_loss: -0.1524\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 163ms/step - loss: -0.1674 - val_loss: -0.1524\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.1674 - val_loss: -0.1524\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 304ms/step - loss: -0.1925 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 271ms/step - loss: -0.1925 - val_loss: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.1925 - val_loss: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 197ms/step - loss: -0.1925 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 242ms/step - loss: -0.1925 - val_loss: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 252ms/step - loss: -0.1925 - val_loss: 0.0000e+00\n",
            "Found best params for RNN!\n",
            "Training optimal model for RNN...\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: -0.2638\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.3023\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 193ms/step - loss: -0.3256\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 179ms/step - loss: -0.3550\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.3897\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 192ms/step - loss: -0.4050\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.4443\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 180ms/step - loss: -0.4711\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 174ms/step - loss: -0.5203\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 220ms/step - loss: -0.5937\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: -0.6445\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 176ms/step - loss: -0.7021\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -0.7437\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 190ms/step - loss: -0.7898\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 167ms/step - loss: -0.8441\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 189ms/step - loss: -0.8822\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -0.9545\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.9826\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 168ms/step - loss: -0.9901\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 170ms/step - loss: -1.0221\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 165ms/step - loss: -1.1262\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 157ms/step - loss: -0.9545\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 166ms/step - loss: -1.0525\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: -1.0487\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -0.9893\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -0.8436\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -0.9789\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -1.0539\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -0.8925\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 133ms/step - loss: -1.1054\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 142ms/step - loss: -1.0593\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 171ms/step - loss: -0.9402\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -1.1417\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -1.1325\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 139ms/step - loss: -1.1119\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: -1.2274\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -1.2683\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 140ms/step - loss: -1.2684\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: -1.2550\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 129ms/step - loss: -1.2249\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 149ms/step - loss: -1.2991\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 132ms/step - loss: -1.2376\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 131ms/step - loss: -1.2722\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 137ms/step - loss: -1.2978\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -1.2810\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 154ms/step - loss: -1.3176\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -1.3229\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 128ms/step - loss: -1.3621\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 136ms/step - loss: -1.3850\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 138ms/step - loss: -1.2722\n",
            "5/5 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Done training RNN!!!\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAIjCAYAAAD1OgEdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADj7UlEQVR4nOzdd3gUZcPF4d9ueg8JJZQEQi/SexWQjijSOwGkKKiIKGLhFRv2gqJY6EVARBRQJChIDzXSkd5DC+ltk53vj5VoPooJJmzKua8r18vOPjt7Njzy5mRmnjEZhmEgIiIiIiIi2cps7wAiIiIiIiL5kcqWiIiIiIhIDlDZEhERERERyQEqWyIiIiIiIjlAZUtERERERCQHqGyJiIiIiIjkAJUtERERERGRHKCyJSIiIiIikgNUtkRERERERHKAypaIiGTZK6+8gslkytLYq1ev5nCqzJs9ezYmk4lTp07ZO0q+ERISQpkyZewdQ0QkV1HZEhHJ5ZYsWYLJZOL777+/6bmaNWtiMplYt27dTc8FBQXRpEmTexERgDfffJPly5dn+35DQkLw9PTM9v3a08qVK+nQoQP+/v64urpSsWJFxo8fz7Vr1+wdLQOTyZSpr/Xr19s7qohIruRo7wAiInJnzZo1A2DTpk088sgj6dtjYmLYv38/jo6ObN68mVatWqU/d/bsWc6ePUufPn3uWc4333yTHj160LVr13v2nnnR+PHjef/996lZsyYTJkzAz8+P3bt38+mnn7Jo0SJ+/fVXKlWqZO+YAMybNy/D47lz5xIaGnrT9ipVqvDVV19htVrvZTwRkVxPZUtEJJcrUaIEwcHBbNq0KcP2rVu3YhgGPXv2vOm5G49vFDXJHb755hvef/99evfuzYIFC3BwcEh/LiQkhFatWtGzZ092796No+O9+7/o+Ph4PDw8bto+YMCADI+3bdtGaGjoTdtFROTWdBqhiEge0KxZM/bs2UNiYmL6ts2bN1OtWjU6duzItm3bMhxV2Lx5MyaTiaZNm6Zvmz9/PnXr1sXNzQ0/Pz/69OnD2bNnM7zPxo0b6dmzJ0FBQbi4uBAYGMjTTz+d4X1vxWQyER8fz5w5c9JPLQsJCckwJioqipCQEHx9ffHx8WHIkCEkJCTc1fejTJkyPPjgg2zatIkGDRrg6upK2bJlmTt37k1jDxw4QOvWrXFzc6NUqVK8/vrrtz0C8/PPP9O8eXM8PDzw8vKic+fOHDhwIP353377DbPZzKRJkzK8buHChZhMJj7//PM75p48eTKFChXiyy+/zFC0ABo0aMCECRPYt28fS5cuBWDMmDF4enre8vvUt29fAgICSEtLy3R++Pu0zOPHj9OpUye8vLzo37//HXNnxv+/ZuvUqVOYTCbee+89pk2bRtmyZXF3d6ddu3acPXsWwzB47bXXKFWqFG5ubjz88MNERkbetN/MfCYRkdxKZUtEJA9o1qwZFouFsLCw9G2bN2+mSZMmNGnShOjoaPbv35/hucqVK+Pv7w/AG2+8waBBg6hQoQIffPABY8eO5ddff6VFixZERUWlv+7bb78lISGBxx57jE8++YT27dvzySefMGjQoDvmmzdvHi4uLjRv3px58+Yxb948Ro4cmWFMr169iI2NZcqUKfTq1YvZs2czefLku/6eHDt2jB49etC2bVvef/99ChUqREhISIYfxCMiImjVqhXh4eE8//zzjB07lrlz5/Lxxx/f8jN07twZT09P3n77bV5++WUOHjxIs2bN0hfSaN26NY8//jhTpkxh9+7dAFy8eJEnnniCNm3aMGrUqNvmPXr0KEeOHOHhhx/G29v7lmNufJ9XrlwJQO/evYmPj2fVqlUZxiUkJLBixQp69OiRXtoyk/+G1NRU2rdvT9GiRXnvvffo3r37Hb7T/82CBQv47LPPeOKJJ3jmmWf4/fff6dWrFy+99BKrV69mwoQJjBgxghUrVjB+/PgMr83KZxIRyZUMERHJ9Q4cOGAAxmuvvWYYhmFYLBbDw8PDmDNnjmEYhlGsWDFj2rRphmEYRkxMjOHg4GAMHz7cMAzDOHXqlOHg4GC88cYbGfa5b98+w9HRMcP2hISEm957ypQphslkMk6fPp2+7X//+5/x//8vxMPDwxg8ePBNr78xdujQoRm2P/LII4a/v/+/fvbBgwcbHh4eGbaVLl3aAIwNGzakb7t8+bLh4uJiPPPMM+nbxo4dawBGWFhYhnE+Pj4GYJw8edIwDMOIjY01fH19079nN0RERBg+Pj4ZtsfHxxvly5c3qlWrZiQlJRmdO3c2vL29M3x/bmX58uUGYHz44Yd3HOft7W3UqVPHMAzDsFqtRsmSJY3u3btnGLNkyZIMnz8r+QcPHmwAxvPPP3/HHLcyevTom/7e/7nf0qVLpz8+efKkARhFihQxoqKi0rdPnDjRAIyaNWsaFoslfXvfvn0NZ2dnIykpKcufSUQkt9KRLRGRPKBKlSr4+/unX4v1xx9/EB8fn77aYJMmTdi8eTNgu5YrLS0t/XqtZcuWYbVa6dWrF1evXk3/CggIoEKFChlWMnRzc0v/c3x8PFevXqVJkyYYhsGePXv+02f4/0d9mjdvzrVr14iJibmr/VWtWpXmzZunPy5SpAiVKlXixIkT6dt++uknGjVqRIMGDTKM+/+nzYWGhhIVFUXfvn0zfI8cHBxo2LBhhu+Ru7s7s2fP5tChQ7Ro0YJVq1bx4YcfEhQUdMe8sbGxAHh5ed1xnJeXV/r3xGQy0bNnT3766Sfi4uLSxyxevJiSJUum/x1nJf8Njz322B1zZJeePXvi4+OT/rhhw4aA7Xqwf16X1rBhQ1JSUjh//jxwd59JRCS30QIZIiJ5gMlkokmTJmzYsAGr1crmzZspWrQo5cuXB2xl69NPPwVIL103fhA/evQohmFQoUKFW+7byckp/c9nzpxh0qRJ/Pjjj1y/fj3DuOjo6P/0Gf5/GSlUqBAA169fv+1pdVnZ3419/jP36dOn03+4/6f/v9rf0aNHAdtpgrfy//M1bdqUxx57jGnTptG+fXuGDh36r3lvlKwbpet2YmNjKVq0aPrj3r1789FHH/Hjjz/Sr18/4uLi+Omnnxg5cmT6vc6ymt/R0ZFSpUr9a+bs8P//nm4Ur8DAwFtuv/H3l9XPJCKSG6lsiYjkEc2aNWPFihXs27cv/XqtG5o0acKzzz7L+fPn2bRpEyVKlKBs2bIAWK1WTCYTP//8802LMgDp97BKS0ujbdu2REZGMmHCBCpXroyHhwfnz58nJCTkPy/rfav3BjAMw+77u/HZ5s2bR0BAwE3P//+VAZOTk9PvLXX8+HESEhJwd3e/43tUqVIFgL179952zOnTp4mJiaFq1arp2xo1akSZMmVYsmQJ/fr1Y8WKFSQmJtK7d++7zu/i4oLZfG9Obrnd39O//f1l9TOJiORG+pdKRCSP+Of9tjZv3szYsWPTn6tbty4uLi6sX7+esLAwOnXqlP5cuXLlMAyD4OBgKlaseNv979u3jz///JM5c+ZkWBAjNDQ0U/luHGXJTUqXLp1+hOSfjhw5kuFxuXLlAChatCht2rT51/3+73//49ChQ7z33ntMmDCB559/nqlTp97xNRUrVqRixYosX76cjz/++JanE95YTfHBBx/MsL1Xr158/PHHxMTEsHjxYsqUKUOjRo3uOn9ekB8/k4gUPLpmS0Qkj6hXrx6urq4sWLCA8+fPZziy5eLiQp06dZg2bRrx8fEZ7q/VrVs3HBwcmDx58k1HfQzD4Nq1a8DfRxr+OcYwjFuu3HcrHh4eGVY2zA06derEtm3b2L59e/q2K1eusGDBggzj2rdvj7e3N2+++SYWi+Wm/Vy5ciX9z2FhYbz33nuMHTuWZ555hmeffZZPP/2U33///V/zTJo0ievXrzNq1KgMS7YD7Nq1i7fffpv77rvvptUBe/fuTXJyMnPmzGH16tX06tXrrvPnFfnxM4lIwaMjWyIieYSzszP169dn48aNuLi4ULdu3QzPN2nShPfffx/IeDPjcuXK8frrrzNx4kROnTpF165d8fLy4uTJk3z//feMGDGC8ePHU7lyZcqVK8f48eM5f/483t7efPfddzddu3U7devWZe3atXzwwQfpN2K+1fVS99Jzzz3HvHnz6NChA0899RQeHh58+eWXlC5dOsPpfN7e3nz++ecMHDiQOnXq0KdPH4oUKcKZM2dYtWoVTZs25dNPPyUpKYnBgwdToUIF3njjDcB276wVK1YwZMgQ9u3bd8ubA9/Qv39/duzYwccff8zBgwfp378/hQoVYvfu3cycORN/f3+WLl2a4To6gDp16lC+fHlefPFFkpOTM5xCmJX8eUl+/EwiUvDoyJaISB5yo0TdOG3wn27cwNjLy4uaNWtmeO7555/nu+++w2w2M3nyZMaPH8+PP/5Iu3bteOihhwDbQhkrVqygVq1aTJkyhcmTJ1OhQoVb3ij4Vj744APq1q3LSy+9RN++ff/1Br/3QvHixVm3bh01atTgrbfe4qOPPmLQoEE89dRTN43t168fv/76KyVLluTdd9/lqaeeYtGiRdSqVYshQ4YA8MILL3Ds2DHmzJmDq6srYCvBc+bM4ezZszz77LP/mumjjz5i+fLlFClShDfffJPRo0ezZs0aRo8eTXh4+E2Ld9zQu3dvYmNjKV++PHXq1Lmr/HlNfvxMIlKwmIy7vTJZREREREREbktHtkRERERERHKAypaIiIiIiEgOUNkSERERERHJASpbIiIiIiIiOUBlS0REREREJAeobImIiIiIiOQA3dQ4k6xWKxcuXMDLywuTyWTvOCIiIiIiYieGYRAbG0uJEiUwm29//EplK5MuXLhAYGCgvWOIiIiIiEgucfbsWUqVKnXb51W2MsnLywuwfUO9vb3tnCYji8XCmjVraNeuHU5OTvaOI3mI5o5khuaJ3C3NHckMzRO5W/acOzExMQQGBqZ3hNtR2cqkG6cOent758qy5e7ujre3t/6RkizR3JHM0DyRu6W5I5mheSJ3KzfMnX+7vEgLZIiIiIiIiOQAlS0REREREZEcoLIlIiIiIiKSA3TNVjYxDIPU1FTS0tLu+XtbLBYcHR1JSkqyy/v/Fw4ODjg6Omo5fRERERHJd1S2skFKSgoXL14kISHBLu9vGAYBAQGcPXs2T5YWd3d3ihcvjrOzs72jiIiIiIhkG5Wt/8hqtXLy5EkcHBwoUaIEzs7O97zwWK1W4uLi8PT0vONN1XIbwzBISUnhypUrnDx5kgoVKuSp/CIiIiIid6Ky9R+lpKRgtVoJDAzE3d3dLhmsVispKSm4urrmubLi5uaGk5MTp0+fTv8MIiIiIiL5Qd76yTwXy2slJzfR905ERERE8iP9lCsiIiIiIpIDVLZERERERERygMqWiIiIiIhIDlDZKsBCQkIwmUyMGjXqpudGjx6NyWQiJCQkfWzXrl1vu68yZcpgMpkwmUx4eHhQp04dvv322xxKLiIiIiKS+6lsFXCBgYEsWrSIxMTE9G1JSUksXLiQoKCgLO3r1Vdf5eLFi+zZs4f69evTu3dvtmzZkt2RRURERETyBJWtHGAYBgkpqff0KzEljYSUVAzDyFLWOnXqEBgYyLJly9K3LVu2jKCgIGrXrp2lfXl5eREQEEDFihWZNm0abm5urFixIkv7EBERERHJL3SfrRyQaEmj6qRf7PLeB19tj7tz1v5ahw4dyqxZs+jfvz8AM2fOZMiQIaxfv/6uczg6OuLk5ERKSspd70NEREREJC/TkS1hwIABbNq0idOnT3P69Gk2b97MgAED7np/KSkpTJkyhejoaFq3bp2NSUVERERE8g4d2coBbk4OHHy1/T17P6vVSmxMLF7eXrg5OWT59UWKFKFz587Mnj0bwzDo3LkzhQsXzvJ+JkyYwEsvvURSUhKenp689dZbdO7cOcv7ERERERH5p8sxSXy76xyPtyyHyWSyd5xMU9nKASaTKcun8v0XVquVVGcH3J0d73ryDR06lDFjxgAwbdq0u9rHs88+S0hICJ6enhQrVixP/YcgIiIiIrnTmWsJDJgRxpnIBEwmeLxleXtHyjSVLQGgQ4cOpKSkYDKZaN/+7o7KFS5cmPLl887kFxEREZHc7UhELANnhHE5NpkgP3cerF7C3pGyRGVLAHBwcODQoUPpf76V6OhowsPDM2zz9/cnMDAwp+OJiIiISAGz+8x1hszaQXSihUrFvJg3rAFFvV3tHStLVLYknbe39x2fX79+/U3LwQ8bNoyvv/46J2OJiIiISAGz8egVRszdRaIljdpBvswKqY+vu7O9Y2WZylYBNnv27Ds+v3z58gxj7zT+1KlT2ZJJRERERAq2n/Zd5KlFe7CkGTSvUJgvBta1rYdgGJDH1gTQ0u8iIiIiIpIrLN5xhjELd2NJM+hcvThfD65nK1p/roEZ7SAxyt4Rs8SuZWvDhg106dKFEiVKYDKZMhxJsVgsTJgwgerVq+Ph4UGJEiUYNGgQFy5cyLCPyMhI+vfvj7e3N76+vgwbNoy4uLgMY/bu3Uvz5s1xdXUlMDCQd9555158PBERERERyaQvfj/OhO/2YTWgT/1ApvatjYujA+xdAov6wrntsGWqvWNmiV3LVnx8PDVr1rzlUuMJCQns3r2bl19+md27d7Ns2TKOHDnCQw89lGFc//79OXDgAKGhoaxcuZINGzYwYsSI9OdjYmJo164dpUuXZteuXbz77ru88sorfPnllzn++URERERE5M4Mw+Dt1YeZ8vNhAEbdX44p3arjYDZB2JewbDhYU6F6L2g50c5ps8au12x17NiRjh073vI5Hx8fQkNDM2z79NNPadCgAWfOnCEoKIhDhw6xevVqduzYQb169QD45JNP6NSpE++99x4lSpRgwYIFpKSkMHPmTJydnalWrRrh4eF88MEHGUqZiIiIiIjcW2lWg5d/2M/CsDMATOhQmcdalrNdn7X+LVg/xTawwUjo8BaY89ZVUHlqgYzo6GhMJhO+vr4AbN26FV9f3/SiBdCmTRvMZjNhYWE88sgjbN26lRYtWuDs/PfqJe3bt+ftt9/m+vXrFCpU6JbvlZycTHJycvrjmJgYwHZ6o8ViSd9usVgwDAOr1YrVas3Oj5tphmGk/6+9MvwXVqsVwzCwWCy3XXZecsaNufzPOS3y/2meyN3S3JHM0DwpuFJSrTz73T5+2n8Jkwlee6gqveuVwpKSjHnNCzjstK14ndZiAtZm4yEtzfb1F3vOncy+Z54pW0lJSUyYMIG+ffumL1EeERFB0aJFM4xzdHTEz8+PiIiI9DHBwcEZxhQrViz9uduVrSlTpjB58uSbtq9ZswZ3d/cM7xcQEEBcXBwpKSl3/wGzQWxsrF3f/26lpKSQmJjIhg0bSE1NtXecAun/H0UWuRXNE7lbmjuSGZonBUtyGsz608yhKDMOJoOBFax4Xd7Lz6t2U/v0VwRe3wrA3lIDORlbDX7++bb7ssfcSUhIyNS4PFG2LBYLvXr1wjAMPv/883vynhMnTmTcuHHpj2NiYggMDKRdu3YZ7keVlJTE2bNn8fT0xNXVPjdZMwyD2NhYvLy8MOWx5TDB9j10c3OjRYsWdvseFlQWi4XQ0FDatm2Lk5OTveNILqV5IndLc0cyQ/Ok4IlOtDBi/h4ORUXh5mRmWt9aNK9QGCwJOHw3FPP1rRhmR9K6fEqV+3pQ5Tb7sefcuXHW27/J9WXrRtE6ffo0v/32W4aiExAQwOXLlzOMT01NJTIykoCAgPQxly5dyjDmxuMbY27FxcUFFxeXm7Y7OTll+MtMS0vDZDJhNpsx2+kc0hunDt7IkdeYzWZMJtNN31u5d/S9l8zQPJG7pbkjmaF5UjBcjk1i0MydHI6IxdvVkVlDGlC3dCHbku7f9Iaz28DRDVOvuThWbJepfdpj7mT2/XL1T+Y3itbRo0dZu3Yt/v7+GZ5v3LgxUVFR7Nq1K33bb7/9htVqpWHDhuljNmzYkOG8ytDQUCpVqnTbUwhFRERERCR7nY1MoOf0rRyOiKWIlwuLRza2Fa3YCJjd2Va0XH1g0HLIZNHK7exatuLi4ggPDyc8PByAkydPEh4ezpkzZ7BYLPTo0YOdO3eyYMEC0tLSiIiIICIiIv3aqCpVqtChQweGDx/O9u3b2bx5M2PGjKFPnz6UKFECgH79+uHs7MywYcM4cOAAixcv5uOPP85wiqCIiIiIiOScPy/F0mP6Fk5fSyDQz42loxpTpbg3RJ6Eme3h0n7wLAYhP0FQI3vHzTZ2LVs7d+6kdu3a1K5dG4Bx48ZRu3ZtJk2axPnz5/nxxx85d+4ctWrVonjx4ulfW7ZsSd/HggULqFy5Mg888ACdOnWiWbNmGe6h5ePjw5o1azh58iR169blmWeeYdKkSVr2/R8iIiJ44oknKFu2LC4uLgQGBtKlSxd+/fVXAMqUKYPJZGLbtm0ZXjd27FhatmyZ/viVV17BZDIxatSoDOPCw8MxmUycOnUqpz+KiIiIiOQye85cp9cXW7kUk0zFYp4sHdWE0v4ecOmArWhdPwWFysDQ1RBwn73jZiu7XrPVsmXL9GXLb+VOz93g5+fHwoUL7zimRo0abNy4Mcv5CoJTp07RtGlTfH19effdd6levToWi4VffvmF0aNHc/iw7eZyrq6uTJgwgd9///2O+3N1dWXGjBk888wzVKhQ4V58BBERERHJpTYdvcqIeTtJSEmjVqAvs4fUx9fdGc6EwcKekBQNRavBwGXgdfv1FPKqXL9ARp5kGGDJ3HKQ2cJqtb1figO4eEIWViR8/PHHMZlMbN++HQ8Pj/Tt1apVY+jQoemPR4wYwfTp0/npp5/o1KnTbfdXqVIlihYtyosvvsiSJUvu7vOIiIiISJ63ev9FnvwmnJQ0K83KF+aLgXXxcHGEo2th8QBITYTAhtBvMbjlz7UUVLZygiUB3ixxz97ODPjeePDCBXD2uP3gf4iMjGT16tW88cYbGYrWDTduHg0QHBzMqFGjmDhxIh06dLjjqodvvfUW9evXZ+fOnRluOC0iIiIiBcOSHWd5ftlerAZ0vC+Aj/rUwsXRAfYthe9HgjUVyreBXnMz/bNrXpSrVyOUnHXs2DEMw6By5cqZGv/SSy9x8uRJFixYcMdxderUoVevXkyYMCE7YoqIiIhIHvLVhhM8952taPWuF8gnfWvbitb2r+C7R21F674e0OebfF20QEe2coaTu+0I0z1itVqJiY3F28sLs5N7pl+XmWvi/qlIkSKMHz+eSZMm0bt37zuOff3116lSpQpr1qyhaNGiWXofEREREcl7DMPgvTVHmLbuOAAjWpRlYsfKmADWvw3r37QNrP8odHwX8uD9YbMq/39CezCZbC39Xn45udv+NwvXa1WoUAGTyZS+CEZmjBs3jsTERD777LM7jitXrhzDhw/n+eefz3KpExEREZG8Jc1q8NLy/elF67kOlWxFyzBg9fN/F637J0Cn9wpE0QKVrQLNz8+P9u3bM23aNOLj4296Pioq6qZtnp6evPzyy7zxxhvExsbecf+TJk3izz//ZNGiRdkVWURERERymZRUK2MXh7Mg7AwmE7zxyH083rI8JmsqLB8FYdNtAzu8Da1eyNLBgbxOZauAmzZtGmlpaTRo0IDvvvuOo0ePcujQIaZOnUrjxo1v+ZoRI0bg4+Pzr0vuFytWjHHjxjF16tSciC4iIiIidpaYksaIeTtZ8ccFHM0mpvapTf+GpcGSaFtxcO9iMDlAt6+g0ah/32E+o7JVwJUtW5bdu3fTqlUrnnnmGe677z7atm3Lr7/+yueff37L1zg5OfHaa6+RlJT0r/sfP348np6e2R1bREREROwsOtHCwBlhrD9yBVcnM18PrkeXmiUgMQrmdYM/V4OjK/T9Bmr0sndcu9ACGULx4sX59NNP+fTTT2/5/KlTp27a1rdvX/r27Zth2yuvvMIrr7ySYZu3tzdXrlzJrqgiIiIikgtciU1m0MztHLoYg5erI7NC6lOvjB/EXbYVrUv7wMXbdg+t0k3sHdduVLZERERERCTTzkYmMHBGGKeuJVDY04W5QxtQtYQ3XD8F8x6ByBPgURQGfAfFa9g7rl2pbImIiIiISKYcvRTLwBnbiYhJolQhN+YPa0iZwh5w6aCtaMVFgG8QDFwO/uXsHdfuVLZERERERORf/XE2isGzthOVYKFCUU/mDWtIgI8rnN0OC3pCUhQUqQIDvwfv4vaOmyuobImIiIiIyB1tOXaV4XN3Ep+SRs1AX2aH1KeQhzMcWwuLB4IlAUrVh35LwN3P3nFzDZUtERERERG5rV8ORPDEwj2kpFlpWt6fLwbWw9PFEfZ/B8tGgtUC5R6A3vPA2cPecXMVlS0REREREbmlb3eeZcJ3e7Ea0L5aMab2rY2LowPsmAGrngEMqNYNHvkCHJ3tHTfXUdkSEREREZGbzNh0ktdWHgSgZ91STOlWHUezCTa8C7+9bhtUbyh0eg/MDnZMmnupbImIiIiISDrDMPgg9E8++e0YAI82C+bFzlUwGQb88iJsm2Yb2OJZaPUimEx2TJu7qWyJiIiIiAgAVqvBKysOMHfraQCebV+Jx1uWw2RNhR+fgD++sQ1sPwUaP27HpHmDypaIiIiIiGBJszL+2z/4IfwCJhO8+vB9DGxUGiyJ8O0Q+PNnMDnAw9OgVl97x80TzPYOIPYTEhKCyWTCZDLh5OREcHAwzz33HElJSeljTCYTrq6unD59OsNru3btSkhIyE37euuttzKMW758OSYdWhYRERHJ1RJT0hg5bxc/hF/A0Wzio961bEUrKRrmd7cVLQcX6D1fRSsLVLYKuA4dOnDx4kVOnDjBhx9+yBdffMH//ve/DGNMJhOTJk361325urry9ttvc/369ZyKKyIiIiLZLCbJwuCZ2/nt8GVcHM18NageD9cqCXFXYPaDcHozuHjDwGVQuZO94+YpKls5wDAMEiwJ9/QrMTWRBEsChmFkKauLiwsBAQEEBgbStWtX2rRpQ2hoaIYxY8aMYf78+ezfv/+O+2rTpg0BAQFMmTIly98zEREREbn3rsYl0+eLbWw/FYmXqyPzH21Iq8pF4fppmNkeIvaCRxEIWQllmtk7bp6ja7ZyQGJqIg0XNrTLe4f1C8Pdyf2uXrt//362bNlC6dKlM2xv2rQpf/75J88//zwrV6687esdHBx488036devH08++SSlSpW6qxwiIiIikvPOXU9g0IztnLgaT2FPZ+YMbUC1Ej5w+TDMewRiL4BPEAxaDv7l7B03T9KRrQJu5cqVeHp64urqSvXq1bl8+TLPPvvsTeOmTJnC6tWr2bhx4x3398gjj1CrVq2bTkUUERERkdzj2OVYek7fyomr8ZT0dePbUU1sRevcTpjVwVa0ilSGYb+oaP0HOrKVA9wc3QjrF3bP3s9qtRIbG4uXlxdujm5Zem2rVq34/PPPiY+P58MPP8TR0ZHu3bvfNK5q1aoMGjSI559/ns2bN99xn2+//TatW7dm/PjxWcoiIiIiIjlv77koBs/czvUEC+WLejJvWAOK+7jB8d9g0QCwxEPJetD/W3D3s3fcPE1lKweYTKa7PpXvblitVlIdU3F3cs/yyn8eHh6UL18egJkzZ1KzZk1mzJjBsGHDbho7efJkKlasyPLly++4zxYtWtC+fXsmTpyYYcVCEREREbGvLcevMnzOTuJT0qhZyodZQxrg5+EMB5bDd4+C1QJlW9lWHXTxtHfcPE+nEUo6s9nMCy+8wEsvvURiYuJNzwcGBjJmzBheeOEF0tLS7rivt956ixUrVrB169aciisiIiIiWbDmQAQhs3YQn5JGk3L+LBjeyFa0ds6Cb0NsRatqV+i3WEUrm6hsSQY9e/bEwcGBadOm3fL5iRMncuHCBdauXXvH/VSvXp3+/fszderUnIgpIiIiIlnw3a5zPLZgNympVtpVLcbMkPp4OjvAxvdh5VjAgLoh0GMmOLrYOW3+obIlGTg6OjJmzBjeeecd4uPjb3rez8+PCRMmZLjx8e28+uqrWK3WnIgpIiIiIpk0c9NJnvn2D9KsBj3qluKz/nVwdTTDmpfg11dtg5o/Aw9+BGYHu2bNb3TNVgE2e/bsW25//vnnef755wFued+uiRMnMnHixH/dV5kyZUhOTv7POUVEREQk6wzD4MO1R5n661EAhjYN5qXOVTAbafDDkxC+wDaw3RvQZIwdk+ZfKlsiIiIiIvmM1Wrw6sqDzN5yCoBn2lZkTOvymFKTYelQOLIKTA7w0CdQu799w+ZjKlsiIiIiIvmIJc3Kc0v38v2e8wC8+nA1BjUuA0kxsKgfnNoIDi7QcxZU7mzfsPmcypaIiIiISD6RZElj9ILd/Hr4Mo5mE+/3qsnDtUpC/FWY3x0uhoOzF/T9BoKb2ztuvqeyJSIiIiKSD8QkWXh0zk62n4zExdHM5wPq0LpyMYg6C/O6wrVj4O4PA76DErXtHbdAUNkSEREREcnjrsUlM3jWdvafj8HLxZGvB9ejYVl/uHIE5j0CMefBJxAGfg+FK9g7boGhsiUiIiIikoedj0pk4IwwTlyJx9/DmTlDG3BfSR84twsW9IDESChc0Va0fErZO26BorIlIiIiIpJHHb8Sx8Cvw7gQnURJXzfmDWtA2SKecGI9fNMPLPFQog70Xwoe/vaOW+CobImIiIiI5EH7z0czaOZ2IuNTKFfEg3nDGlLC1w0O/gjfDYO0FAi+H/osABcve8ctkFS2RERERETymG0nrvHonJ3EJadSvaQPs4fUx9/TBXbNgZVjwbBClYeg+9fg6GLvuAWWypaIiIiISB6y9uAlRi/cTXKqlYbBfnw9uB5erk6w6SNY+z/boDqD4MGPwOxgz6gFntneAcR+QkJCMJlMN3116NCBPn360KFDhwzjV69ejclk4pVXXsmw/ZVXXiEoKOgeJhcREREpmL7fc46R83eRnGqlTZVizBnaAC8XR1jz8t9Fq+lY6DJVRSsX0JGtAq5Dhw7MmjUrwzYXFxeWLFnC+PHjSU1NxdHRNk3WrVtHYGAg69evzzB+3bp1tGrV6l5FFhERESmQZm8+ySsrDgLQrXZJ3ulRA0es8OMY2DPfNqjtq9D0KTumlH9S2coBhmFgJCbes/ezWq1YExOxOjpi8vDAZDJl+rUuLi4EBATctL1Vq1bExcWxc+dOGjVqBMD69et5/vnneeaZZ0hKSsLV1ZWkpCTCwsIYMmRItn0eEREREfmbYRhM/fUYH679E4CQJmWY9GBVzGnJtoUwDq8Ek9l2NKvOQDunlX9S2coBRmIiR+rUvefvewmotHsXJnf3/7yvihUrUqJECdatW0ejRo2IjY1l9+7drFy5kk8++YStW7fSqlUrtmzZQnJyso5siYiIiOQAq9Xg1ZUHmb3lFABPt6nIkw+Ux5QSB4v6wckN4OAMPWZClS72DSs30TVbBdzKlSvx9PTM8PXmm28CtqNbN04Z3LhxIxUrVqRIkSK0aNEiffv69esJDg6mdOnSdvoEIiIiIvlTapqV8Uv/SC9ar3SpylNtKmBKuAZzutiKlrMnDPhORSuX0pGtHGByc6PS7l337P2sVisxsbF4e3lhcnPL0mtbtWrF559/nmGbn58fAC1btmTs2LFYLBbWr19Py5YtAbj//vv54osvAFvZ0lEtERERkeyVZEljzMI9rD10CQezifd61uCR2qUg+hzM7QrXjoK7v+1mxSXr2Duu3IbKVg4wmUzZcipfplmtmFNTMbu7Z+l6LQAPDw/Kly9/y+datWpFfHw8O3bsYN26dTz77LOArWwNHTqUyMhIwsLCGDly5H/+CCIiIiJiE5tkYfjcnWw7EYmLo5lp/erQpmoxuPInzHsEYs6BdykY+D0UqWjvuHIHKltyW+XKlSMwMJAff/yR8PBw7r//fgBKlixJyZIlef/990lJSdGRLREREZFsci0umZBZO9h3PhpPF0e+HlyPRmX94fxuWNADEq6BfwVb0fINtHdc+RcqWwVccnIyERERGbY5OjpSuHBhwHZ067PPPqN8+fIUK1Ysfcz999/PJ598kr6QhoiIiIj8NxeiEhk4I4zjV+Lx83Bm7tAG3FfSx3Zt1jd9ISUOStS2nTroUdjecSUTtEBGAbd69WqKFy+e4atZs2bpz7dq1YrY2Nj067VuuP/++4mNjdVRLREREZFscOJKHD0+38LxK/GU8HFlycjGtqJ1aAXM724rWmWaw+AVKlp5iMpWATZ79mzbPcH+39fhw4fTx4SEhGAYxk2LaAwePBjDMJg+ffq9ji0iIiKSr+w/H03P6Vu5EJ1E2cIefPtYE8oX9YTd82DJIEhLgcoP2o5ouXjZO65kgU4jFBERERGxk7AT13h0zk5ik1O5r6Q3s4c0oLCnC2yeCqEv2wbVHgAPfgwO+tE9r9HfmIiIiIiIHfx2+BKPzd9NcqqVBsF+zBhcDy8XRwj9H2z+yDaoyZPQ9lXI4orTkjuobImIiIiI3GM/hJ/nmSV/kGo1eKByUab1r4OrA7DiSdg91zaozWRoNtaeMeU/UtkSEREREbmH5m49xf9+PIBhwCO1S/JOjxo4GRb49lE49COYzPDgR1B3sL2jyn+kspVNDMOwd4Q8S987ERERKQgMw+DT347xfuifAIQ0KcOkB6titsTD4v5wYj04OEP3r6Hqw/YNK9nCrqsRbtiwgS5dulCiRAlMJhPLly/P8PyyZcto164d/v7+mEwmwsPDb9pHy5YtMZlMGb5GjRqVYcyZM2fo3Lkz7u7uFC1alGeffZbU1NRs+QxOTk4AJCQkZMv+CqIb37sb30sRERGR/MZqNXht5aH0ovXUAxX4X5eqmBMjYe5DtqLl5AH9lqho5SN2PbIVHx9PzZo1GTp0KN26dbvl882aNaNXr14MHz78tvsZPnw4r776avpjd3f39D+npaXRuXNnAgIC2LJlCxcvXmTQoEE4OTnx5ptv/ufP4ODggK+vL5cvX05/b9M9voDRarWSkpJCUlISZnPeWc3fMAwSEhK4fPkyvr6+ODg42DuSiIiISLZLTbPy/LJ9LN11DoBJD1ZlaLNgiD4P8x6Bq0fAzc+2tHupunZOK9nJrmWrY8eOdOzY8bbPDxw4EIBTp07dcT/u7u4EBATc8rk1a9Zw8OBB1q5dS7FixahVqxavvfYaEyZM4JVXXsHZ2fmu899w471vFK57zTAMEhMTcXNzu+dFLzv4+vre9u9PREREJC9LsqTx5Dd7WHPwEg5mE+90r0H3uqXg6lFb0Yo+C14lYNByKFLJ3nElm+WLa7YWLFjA/PnzCQgIoEuXLrz88svpR7e2bt1K9erVKVasWPr49u3b89hjj3HgwAFq1659y30mJyeTnJyc/jgmJgYAi8WCxWK5aXzhwoUpVKgQqamp9/wapNTUVLZs2UKTJk1wdMw7f6UmkwlHR0ccHByy7bROyZobc/lWc1rkBs0TuVuaO5IZ+XmexCWn8tiCPWw7eR1nRzNTe9XggSpFsZzZieOi3pgSrmL4lSO131LwCYR8+D3ISfacO5l9z7zzk/lt9OvXj9KlS1OiRAn27t3LhAkTOHLkCMuWLQMgIiIiQ9EC0h9HRETcdr9Tpkxh8uTJN21fs2ZNhtMUc5MNGzbYO4LkUaGhofaOIHmA5oncLc0dyYz8Nk/iLPDFIQfOxJtwcTAYXtFC8smdhO09RMMTH2KyJhHlVoatJZ4mZfM+YJ+9I+dZ9pg7mV2vIc+XrREjRqT/uXr16hQvXpwHHniA48ePU65cubve78SJExk3blz645iYGAIDA2nXrh3e3t7/KXN2s1gshIaG0rZtWy0yIVmiuSOZoXkid0tzRzIjP86Ti9FJDJmzizPx8RRyd2LGoDpUL+mD6chPOHz/ASZrMtbSTfHoOZ82Ll72jptn2XPu3Djr7d/k+bL1/zVs2BCAY8eOUa5cOQICAti+fXuGMZcuXQK443VCLi4uuLi43LTdyckp1/5DkJuzSe6muSOZoXkid0tzRzIjv8yTk1fjGfD1Ds5HJVLcx5V5wxpQvqgXhC+EH8aAkQaVOmPuMROzk6u94+YL9pg7mX2/vLN0XSbdWB6+ePHiADRu3Jh9+/ZlWLwiNDQUb29vqlatao+IIiIiIpIPHbgQTc/pWzgflUhwYQ++HdXYVrS2fArLH7MVrVr9oddcUNEqEOx6ZCsuLo5jx46lPz558iTh4eH4+fkRFBREZGQkZ86c4cKFCwAcOXIEsB2RCggI4Pjx4yxcuJBOnTrh7+/P3r17efrpp2nRogU1atQAoF27dlStWpWBAwfyzjvvEBERwUsvvcTo0aNveeRKRERERCSrdpyKZOjsHcQmpVK1uDdzhzWgsIcz/PoqbHzfNqjxGGj7GuShW/XIf2PXv+mdO3dSu3bt9BUBx40bR+3atZk0aRIAP/74I7Vr16Zz584A9OnTh9q1azN9+nQAnJ2dWbt2Le3ataNy5co888wzdO/enRUrVqS/h4ODAytXrsTBwYHGjRszYMAABg0alOG+XCIiIiIid2vd4csMnBFGbFIqDcr4sWhkIwq7O8LKsX8XrQcmQbvXVbQKGLse2WrZsuUdl0kPCQkhJCTkts8HBgby+++//+v7lC5dmp9++uluIoqIiIiI3NYP4ed5ZskfpFoNWlcuyrR+dXAzp8LSR+HgcsAED34I9YbYO6rYQb5bIENERERE5F6Yt+00k37Yj2HAw7VK8F7PmjilJsDCAXBiHZidoPtXUO0Re0cVO1HZEhERERHJAsMw+Gz9cd79xbaewKDGpXmlSzXMSddhQU84vxOcPKDPfCjX2s5pxZ5UtkREREREMskwDN786RBfbTwJwJOty/N024qYYi/CvEfgymFwKwT9l0KpenZOK/amsiUiIiIikgmpaVZe+H4fS3aeA+DlB6syrFkwXDsOc7tC9BnwKg4Dv4eiVewbVnIFlS0RERERkX+RZEnjqUV7+OXAJcwmeLt7DXrWC4SLf8D87hB/BfzK2YpWodL2jiu5hMqWiIiIiMgdxCWnMnLeTjYfu4azg5lP+tWmfbUAOLUZvukDyTEQUB0GLAPPovaOK7mIypaIiIiIyG1cj08hZPYO/jgbhYezA18NqkeT8oXhyM/wbQikJkHpptD3G3D1sXdcyWVUtkREREREbiEiOomBM8I4ejmOQu5OzB7SgJqBvhD+DfwwGow0qNgRes4CJzd7x5VcSGVLREREROT/OXU1ngEzwjh3PZEAb1fmDWtAhWJesPUz+GWibVDNvvDQJ+DgZN+wkmupbImIiIiI/MPBCzEMmrmdq3HJlPF3Z96whgQWcoPfXocN79oGNXoc2r0BZrN9w0quprIlIiIiIvKXnaciGTJ7B7FJqVQt7s2coQ0o4uEIq56BnTNsg1q/BM3Hg8lk37CS66lsiYiIiIgA649cZtT8XSRZrNQvU4ivB9fHx8mA7x6FA8sAE3R+H+oPs3dUySNUtkRERESkwFvxxwXGLQnHkmbQslIRPu9fFzeS4JuBcPxXMDtBty/gvu72jip5iMqWiIiIiBRoC8JO89Ly/RgGdKlZgvd71sQ5JQoW9oZz28HJHXrPg/Jt7B1V8hiVLREREREpkAzD4PPfj/PO6iMADGgUxOSH7sMhLgLmd4PLB8HVF/p/C4EN7BtW8iSVLREREREpcAzD4K2fD/PFhhMAjGlVnmfaVcQUeQLmdYWoM+AZAAO/h2JV7RtW8iyVLREREREpUNKsBi8s28finWcBeKlzFR5tXhYi9sG8bhB/GQoFw6DlUKiMXbNK3qayJSIiIiIFRnJqGmMXhfPz/gjMJnirWw161Q+E01tgYR9IjoZi1WHgMvAsau+4ksepbImIiIhIgRCfnMqo+bvYePQqzg5mpvatRYf7isOfv8CSQZCaBEGNoe8icPO1d1zJB1S2RERERCTfi0pIIWTWDsLPRuHu7MBXg+rRtHxh2LsEvh8FRhpUaA89Z4Ozu73jSj6hsiUiIiIi+dqlmCQGzdjOkUux+Lo7MSukPrWDCsG26bB6gm1Qjd7w8DRwcLJvWMlXVLZEREREJN86fS2eATPCOBuZSDFvF+YNa0jFop6w7k34/W3boIajoP0UMJvtG1byHZUtEREREcmXDkfEMHDGdq7EJlPa3535wxoS6OsKPz0LO76yDWr1IrR4Fkwm+4aVfEllS0RERETynV2nrzNk1nZiklKpHODF3GENKOpmhmXDYf9SwASd3oUGw+0dVfIxlS0RERERyVc2/HmFkfN2kWhJo27pQswcXB8fRwssGgDHQsHsCI98AdV72Duq5HMqWyIiIiKSb6zae5Gxi/dgSTO4v2IRPh9QB/e0WJjXG86GgaMb9J4PFdrYO6oUACpbIiIiIpIvfLP9DC9+vw+rAQ/WKM4HvWrhnHgZ5nWDywfA1Qf6fQtBDe0dVQoIlS0RERERyfOm/36ct34+DEC/hkG89vB9OESdgnld4fop8CwGA5ZBwH32jCkFjMqWiIiIiORZhmHw9uojTP/9OACPtyzHs+0rYbp0AOZ3g7hLUKgMDFwOfsF2zSoFj8qWiIiIiORJaVaDl5bv45vtZwF4oVNlRrQoB2e2wYJekBwNRavBwGXgFWDntFIQqWyJiIiISJ6TnJrGuMV/sGrfRcwmmNKtOr3rB8Gfa2DJIEhNhMBG0G8RuBWyd1wpoFS2RERERCRPSUhJZeS8XWw8ehVnBzMf96lFx+rFYe+3sHwUWFOhfFvoNRec3e0dVwowlS0RERERyTOiEywMmb2d3WeicHd24IuBdWleoQhs/wp+ehYwoHpP6Po5ODjZO64UcCpbIiIiIpInXI5JYtDM7RyOiMXHzYlZQ+pTJ9AX1r8N69+0DWowAjq8DWazXbOKgMqWiIiIiOQBZ64lMGBGGGciEyjq5cK8YQ2pVNQDfp4A27+wDWo5Ee6fACaTfcOK/EVlS0RERERytSMRsQycEcbl2GSC/NyZP6whQb5O8P1I2LfENqjjO9BwpH2Divw/KlsiIiIikmvtPnOdIbN2EJ1ooXKAF3OHNqCoqxUW9Yejv4DZ0XZ9Vo1e9o4qchOVLRERERHJlTYevcLIebtISEmjTpAvs0Ia4GOKh/l94MxWcHS1rThYsb29o4rcksqWiIiIiOQ6P++7yJOL9mBJM2heoTBfDKyLe/I1mN8NLu0HFx/otxhKN7Z3VJHbUtkSERERkVxl8Y4zTFy2D6sBnasX54PeNXGJPQtzu8L1k+BRFAYug4Dq9o4qckcqWyIiIiKSa3y54Thv/nQYgL4NAnm9a3UcrhyEed0gLgJ8S8Og5eBX1r5BRTJBZUtERERE7M4wDN5ZfZjP1h8HYNT95ZjQoRKmcztgQQ9IioaiVWHAMvAubue0IpmjsiUiIiIidmU1YNKKQyzacQ6ACR0q81jLcnBsLSweCJYEKNUA+i8Bt0J2TiuSeSpbIiIiImI3KalW5h41s+faOUwmePOR6vRtEAT7v4NlI8FqgfJtbKsOOnvYO65IlqhsiYiIiIhdJKak8djCPey5ZsbJwcRHvWvTuUZx2PE1rBoPGHBfd+g6HRyd7R1XJMtUtkRERETknotOsDB0zg52nb6Os9lgev86tK4SAL+/A+vesA2qNww6vQtmB/uGFblLKlsiIiIick9djk1i0IztHI6IxdvVkaHlk2he3g9WT4Swz22DWjwHrV4Ak8m+YUX+A7O9A4iIiIhIwXE2MoGe07dyOCKWIl4uLBxWn7KeqTisGPN30erwFrR+UUVL8jwd2RIRERGRe+LPS7EMnBHGpZhkAv3cmD+sISXc0vA/8QnmmD1gcoCun0PN3vaOKpItVLZEREREJMftPnOdIbN2EJ1ooVIxL+YOa0Ax52SsC3pRPGYPhqMrpp5zoFIHe0cVyTYqWyIiIiKSo37/8wqj5u0i0ZJG7SBfZoXUx9caBbO7YY7Yh8XshqnvYhzL3W/vqCLZStdsiYiIiEiO+fGPCzw6ZweJljTur1iEBY82xDf5IsxsDxH7MDyKsKnCCxhBTewdVSTbqWyJiIiISI6Yt/UUTy3agyXNoEvNEnw1qB7uUUdtRSvyBPgEkTpoJTHupe0dVSRH6DRCEREREclWhmEw9ddjfLj2TwAGNS7NK12qYT6/Exb0gKQoKFIFBi4DtyLAEbvmFckpKlsiIiIikm2sVoNXVx5k9pZTADz1QAXGtqmA6dhaWDwQUhOhZD3o/y24+4HFYt/AIjlIZUtEREREsoUlzcr4b//gh/ALAEx+qBqDm5SBPxbDD4+DNRXKPQC95oKLp33DitwDdr1ma8OGDXTp0oUSJUpgMplYvnx5hueXLVtGu3bt8Pf3x2QyER4eftM+kpKSGD16NP7+/nh6etK9e3cuXbqUYcyZM2fo3Lkz7u7uFC1alGeffZbU1NQc/GQiIiIiBUtiShrD5+7kh/ALOJpNfNynlq1obfkUvh9hK1rVe0HfRSpaUmDYtWzFx8dTs2ZNpk2bdtvnmzVrxttvv33bfTz99NOsWLGCb7/9lt9//50LFy7QrVu39OfT0tLo3LkzKSkpbNmyhTlz5jB79mwmTZqU7Z9HREREpCCKTrAwYEYY649cwdXJzFeD6/FwzRIQOgnWvGgb1Gg0PPIFODrbN6zIPWTX0wg7duxIx44db/v8wIEDATh16tQtn4+OjmbGjBksXLiQ1q1bAzBr1iyqVKnCtm3baNSoEWvWrOHgwYOsXbuWYsWKUatWLV577TUmTJjAK6+8grOz/oMXERERuVuXYpIYNGM7Ry7F4u3qyKwh9albyht+GA3hC2yD2rwCTceCyWTPqCL3XJ6+ZmvXrl1YLBbatGmTvq1y5coEBQWxdetWGjVqxNatW6levTrFihVLH9O+fXsee+wxDhw4QO3atW+57+TkZJKTk9Mfx8TEAGCxWLDksgs5b+TJbbkk99PckczQPJG7pbmT/52+lkDInF2cu55IUS8XZg6qQyV/B6zf9MV8bA2GyUxapw8xavWH21zCoXkid8uecyez75mny1ZERATOzs74+vpm2F6sWDEiIiLSx/yzaN14/sZztzNlyhQmT5580/Y1a9bg7u7+H5PnjNDQUHtHkDxKc0cyQ/NE7pbmTv50Lh6mH3Ig1mKisKvBqPLxnNm+muInPsA//ihpJid2Bo8m4kIhuPDTv+5P80Tulj3mTkJCQqbG5emylZMmTpzIuHHj0h/HxMQQGBhIu3bt8Pb2tmOym1ksFkJDQ2nbti1OTk72jiN5iOaOZIbmidwtzZ38a/upSF6cH06cJZUqAV7MHFyHwtZIHBf1xBR/FMPVB6PnfOoENf7XfWmeyN2y59y5cdbbv8nTZSsgIICUlBSioqIyHN26dOkSAQEB6WO2b9+e4XU3Viu8MeZWXFxccHFxuWm7k5NTrv2HIDdnk9xNc0cyQ/NE7pbmTv6y9uAlRi/cTXKqlQbBfnw9uB7esSdhfjeIPgtexTEN+A7HYtWytF/NE7lb9pg7mX0/u65G+F/VrVsXJycnfv311/RtR44c4cyZMzRubPtNSuPGjdm3bx+XL19OHxMaGoq3tzdVq1a955lFRERE8qrvdp1j5PxdJKdaaVOlGHOHNsD76l6Y2d5WtPzLw9BfIItFSyS/suuRrbi4OI4dO5b++OTJk4SHh+Pn50dQUBCRkZGcOXOGCxdsN8Y7cuQIYDsiFRAQgI+PD8OGDWPcuHH4+fnh7e3NE088QePGjWnUqBEA7dq1o2rVqgwcOJB33nmHiIgIXnrpJUaPHn3LI1ciIiIicrOvN57g9VWHAOhepxRvd6+O48l1sHggWOKhRG3ovxQ8Cts5qUjuYdcjWzt37qR27drpKwKOGzeO2rVrp98D68cff6R27dp07twZgD59+lC7dm2mT5+evo8PP/yQBx98kO7du9OiRQsCAgJYtmxZ+vMODg6sXLkSBwcHGjduzIABAxg0aBCvvvrqPfykIiIiInmTYRi8s/pwetEa3jyYd3vUwPHgMljYy1a0yraEwStUtET+H7se2WrZsiWGYdz2+ZCQEEJCQu64D1dXV6ZNm3bbGyMDlC5dmp9++vdVcERERETkb2lWg5eW7+Ob7WcBmNChMqPuL4sp7AtYPcE26L7u0HW6blYscgt5eoEMEREREckZyalpjF0Uzs/7IzCb4I1HqtO3fiD89hpsfN82qMFI6PAWmPP0MgAiOUZlS0REREQyiEtOZeS8nWw+dg1nBzMf96lFx6pF4McnYM8826DWL0Hz8WAy2TesSC6msiUiIiIi6SLjUwiZtZ2956LxcHbgq0H1aFLaA5YMgiOrwGSGBz+EuiH2jiqS66lsiYiIiAgA56MSGTgjjBNX4vHzcGb2kPrU8AfmdYMzW8DBBXrMgCpd7B1VJE9Q2RIRERERjl2OZeCM7VyMTqKEjytzhzWkvFsczO4Ol/aDizf0/QbKNLN3VJE8Q2VLREREpID742wUIbO2cz3BQrkiHswb1pASaRdgRleIOgOexWDAdxBQ3d5RRfIUlS0RERGRAmzT0auMmLeThJQ0apbyYdaQBvhFH4D5PSDhKviVhQHLwC/Y3lFF8hyVLREREZEC6qd9Fxm7KJyUNCvNyhdm+sC6eJ7bCIsHQEocBNSwHdHyLGrvqCJ5ksqWiIiISAG0MOwMLy7fh2FAp+oBfNi7Fi6Hf4BlI8BqgeAW0HsBuHrbO6pInqWyJSIiIlKAGIbBZ+uP8+4vRwDo1zCI1x6+D4edX8NPzwIGVO0K3b4ERxe7ZhXJ61S2RERERAoIq9XgjZ8OMWPTSQCeaF2ecW0qYFr/Jmx4xzao/qPQ8R0wO9gxqUj+oLIlIiIiUgBY0qxM+G4vy3afB+DlB6syrEkQrHoads22DWo5Ee6fACaT/YKK5CMqWyIiIiL5XJIljTELd7P20GUczCbe7VGDbtULw7eD4dAKwASd34f6w+wdVSRfUdkSERERyceiEy0Mn7OT7acicXE081n/OjwQ7AoLesCpjeDgDN2+gmpd7R1VJN9R2RIRERHJpy7HJjF45g4OXYzBy9WRGYPr06CwBWZ3hoh94OwFfRfaVh4UkWynsiUiIiKSD525lsDAmWGcvpZAYU8X5g5tQFXXqzDzEbh+CjyK2O6hVbymvaOK5FvZWrYSEhJwd3fPzl2KiIiISBYduhjDoJnbuRKbTKCfG/OHNaR0yjGY0R3ir0ChMjBgGfiXs3dUkXzNnNUXPPDAA5w/f/6m7du3b6dWrVrZkUlERERE7tLOU5H0/mIrV2KTqRzgxXejmlA6ZhfM6mwrWsWqw9A1Kloi90CWy5arqys1atRg8eLFAFitVl555RWaNWtGp06dsj2giIiIiGTOusOXGTAjjJikVOqVLsTiEY0peu4XmN8dUmKhdDMYsgq8itk7qkiBkOXTCFetWsW0adMYOnQoP/zwA6dOneL06dOsXLmSdu3a5URGEREREfkXy/ecZ/y3f5BqNWhVqQif9a+L2945sHIcYECVLtDta3BytXdUkQLjrq7ZGj16NOfOnePtt9/G0dGR9evX06RJk+zOJiIiIiKZMGvzSSavOAjAI7VL8k736jhteg/Wv2kbUDcEOn8AZgf7hRQpgLJ8GuH169fp3r07n3/+OV988QW9evWiXbt2fPbZZzmRT0RERERuwzAMPlhzJL1ohTQpw/vd78Ppl+f+LlotnoMHP1LRErGDLB/Zuu+++wgODmbPnj0EBwczfPhwFi9ezOOPP86qVatYtWpVTuQUERERkX9Isxr878f9zN92BoBn2lZkTItATMuGwcHlgAk6vgMNR9g1p0hBluUjW6NGjWLDhg0EBwenb+vduzd//PEHKSkp2RpORERERG6WkmrlqUV7mL/tDCYTvNb1Pp5oFoBpYS9b0TI7QY8ZKloidpblI1svv/xy+p+TkpJwdbVdZFmqVClCQ0OzL5mIiIiI3CQhJZWR83ax8ehVnBxMfNi7Fg+WdYLZneHiH+DsCb3nQ7lW9o4qUuBl+ciW1Wrltddeo2TJknh6enLixAnAVsJmzJiR7QFFRERExOZ6fAr9vgpj49GruDk5MGNwfR4MTIGZ7WxFy70wDF6hoiWSS2S5bL3++uvMnj2bd955B2dn5/Tt9913H19//XW2hhMRERERm4joJHp9sZXws1H4ujuxcHhDWnhHwIx2EHkCfIJg6C9Qso69o4rIX7JctubOncuXX35J//79cXD4e1WbmjVrcvjw4WwNJyIiIiJw4koc3T/fwtHLcQR4u/LtyMbUth6EWZ0g7hIUrQbD1kDh8vaOKiL/kOVrts6fP0/58jf/h2y1WrFYLNkSSkRERERs9p+PZvDM7VyLT6FsYQ/mDmtAqYjfYOlQSEuGoCbQ9xtw87V3VBH5f7J8ZKtq1aps3Ljxpu1Lly6ldu3a2RJKRERERGDL8av0+XIb1+JTqF7Sh29HNabUiW9hyUBb0arUGQYuU9ESyaWyfGRr0qRJDB48mPPnz2O1Wlm2bBlHjhxh7ty5rFy5MicyioiIiBQ4q/dH8OQ3e0hJs9K4rD9fDqyD146p8NtrtgG1B8CDH4NDln+cE5F7JMtHth5++GFWrFjB2rVr8fDwYNKkSRw6dIgVK1bQtm3bnMgoIiIiUqAs2XGWxxfsIiXNSvtqxZgVUhevdS/9XbSajYOHPlXREsnl7uq/0ObNm+ueWiIiIiI5YPrvx3nrZ9uiY73rBfLGQxVx/HEk7P/ONqDDW9DoMTsmFJHM0q9DRERERHIBwzB46+fDfLHBdg/TUfeXY0LrkpgW94Xjv4HZEbpOhxo97ZxURDIrU2WrUKFCmEymTO0wMjLyPwUSERERKWhS06y88P0+luw8B8ALnSozoq4PzHkILuwGJw/oPRfKt7FzUhHJikyVrY8++ij9z9euXeP111+nffv2NG7cGICtW7fyyy+/8PLLL+dISBEREZH8KsmSxpPf7GHNwUuYTfBW9xr0Km/AzPZw7Ri4+UH/pVCqrr2jikgWZapsDR48OP3P3bt359VXX2XMmDHp25588kk+/fRT1q5dy9NPP539KUVERETyodgkC8Pn7mTbiUicHc180rc27QtfgxndIfYi+ATCgGVQpKK9o4rIXcjyaoS//PILHTp0uGl7hw4dWLt2bbaEEhEREcnvrsYl0/erbWw7EYmniyNzhjSgvedJmNXRVrSKVIGhv6hoieRhWS5b/v7+/PDDDzdt/+GHH/D398+WUCIiIiL52bnrCfScvpX952Pw93Bm0YhGNE7dDvO6QlI0BDaEIT+BT0l7RxWR/yDLqxFOnjyZRx99lPXr19OwYUMAwsLCWL16NV999VW2BxQRERHJT/68FMugGduJiEmipK8b84Y1oOy55fDjk2CkQcUO0GMWOLvbO6qI/EdZLlshISFUqVKFqVOnsmzZMgCqVKnCpk2b0suXiIiIiNxs95nrDJm1g+hECxWKejJvaAMC9k+Hta/YBtTsBw9NBQcnu+YUkexxV/fZatiwIQsWLMjuLCIiIiL51u9/XmHUvF0kWtKoHeTLrMF18d34KmybZhvQ9CloMxkyebsdEcn97qpsWa1Wjh07xuXLl7FarRmea9GiRbYEExEREckvVvxxgXFLwrGkGbSoWITpfavj/vOTsHexbUC716HJE/YNKSLZLstla9u2bfTr14/Tp09jGEaG50wmE2lpadkWTkRERCSvm7ftNJN+2I9hQJeaJXj/4fI4fzcAjq0FsyM8PA1q9rF3TBHJAVkuW6NGjaJevXqsWrWK4sWLY9KhbhEREZGbGIbB1F+P8eHaPwEY1Lg0rzxQHPOCrnB+Jzi6Qe95UKGtfYOKSI7Jctk6evQoS5cupXz58jmRR0RERCTPs1oNXl15kNlbTgHw1AMVGFvfFdPsDnD1T3D1hf7fQmADu+YUkZyV5ftsNWzYkGPHjuVEFhEREZE8z5Jm5ekl4elFa/JD1Xi6phXTzL+KlndJ282KVbRE8r0sH9l64okneOaZZ4iIiKB69eo4OWVcmrRGjRrZFk5EREQkL0lMSeOxBbtYf+QKjmYT7/eqycP+52FmT0iKgsKVYOAy8Cll76gicg9kuWx1794dgKFDh6ZvM5lMGIahBTJERESkwIpOsDB0zg52nb6Oq5OZzwfUpZUpHOYMgtREKFUf+i0Bdz97RxWReyTLZevkyZM5kUNEREQkz7oUk8SgGds5cikWb1dHZg2pT93rv8APo8FIg/JtodcccPawd1QRuYeyXLZKly6dEzlERERE8qRTV+MZODOMs5GJFPVyYe6wBlQ+PhtCX7YNqNHbtry7g9Md9yMi+U+my9aPP/6YqXEPPfTQXYcRERERyUsOXIhm8MwdXI1LprS/O/OHNiBw11uwZaptQOMx0PY1MGd5TTIRyQcyXba6du36r2N0zZaIiIgUFGEnrvHonJ3EJqdSpbg3cwfXpsi68fDHQtuANpOh6VOge5KKFFiZLltWqzUnc4iIiIjkGWsPXmL0wt0kp1ppEOzH1/2q4v3jUDj6C5gc4KFPoHZ/e8cUETvL8jVbIiIiIgXZd7vO8dx3e0mzGrSpUpRPHwnGdUlPOBsGjq7QczZU6mjvmCKSC6hsiYiIiGTS1xtP8PqqQwB0r1OKt9v64TivM1w5DK4+tqXdgxrZOaWI5BZ2vVpzw4YNdOnShRIlSmAymVi+fHmG5w3DYNKkSRQvXhw3NzfatGnD0aNHM4wpU6YMJpMpw9dbb72VYczevXtp3rw5rq6uBAYG8s477+T0RxMREZF8xDAM3v3lcHrRerRZMO+2dMVxVgdb0fIqDkNWq2iJSAZ2LVvx8fHUrFmTadOm3fL5d955h6lTpzJ9+nTCwsLw8PCgffv2JCUlZRj36quvcvHixfSvJ554Iv25mJgY2rVrR+nSpdm1axfvvvsur7zyCl9++WWOfjYRERHJH9KsBi98v59p644D8FyHSrxYMx7zrA4Qcw78K8CwNVCsqp2TikhuY9fTCDt27EjHjrc+p9kwDD766CNeeuklHn74YQDmzp1LsWLFWL58OX369Ekf6+XlRUBAwC33s2DBAlJSUpg5cybOzs5Uq1aN8PBwPvjgA0aMGJH9H0pERETyjeTUNJ5eHM5P+yIwm+CNR6rT1+9PmDsQLAlQog70Xwoe/vaOKiK50F2XrZSUFC5fvnzTKoVBQUH/ORTAyZMniYiIoE2bNunbfHx8aNiwIVu3bs1Qtt566y1ee+01goKC6NevH08//TSOjraPtnXrVlq0aIGzs3P6+Pbt2/P2229z/fp1ChUqdMv3T05OJjk5Of1xTEwMABaLBYvFki2fMbvcyJPbcknup7kjmaF5Incrr8+duORURi8MZ8uJSJwcTHzQswYdjQ0YC5/AZE3FWrYVad1ngbMn5NHPmBvk9Xki9mPPuZPZ98xy2Tp69ChDhw5ly5YtGbYbhpGt99mKiIgAoFixYhm2FytWLP05gCeffJI6derg5+fHli1bmDhxIhcvXuSDDz5I309wcPBN+7jx3O3K1pQpU5g8efJN29esWYO7u/vdf7AcFBoaau8Ikkdp7khmaJ7I3cqLcyfOAl8ccuBMvAkXs8GjldIos+MNHM/b7qF1rlAjdnsNxFi7wc5J84+8OE8kd7DH3ElISMjUuCyXrZCQEBwdHVm5ciXFixfHZOcb9Y0bNy79zzVq1MDZ2ZmRI0cyZcoUXFxc7nq/EydOzLDvmJgYAgMDadeuHd7e3v8pc3azWCyEhobStm1bnJyc7B1H8hDNHckMzRO5W3l17lyISmTInF2ciU+gkLsTMwbWpubRT3DYYitaafVHUKzt63Q02fXS93wjr84TsT97zp0bZ739myyXrfDwcHbt2kXlypWzHCorblyDdenSJYoXL56+/dKlS9SqVeu2r2vYsCGpqamcOnWKSpUqERAQwKVLlzKMufH4dtd5Abi4uNyyrDk5OeXafwhyczbJ3TR3JDM0T+Ru5aW5c+xyLANn7OBidBIlfFyZO6Qu5cNehD3zbQMemIRDs3E42PmXzflRXponkrvYY+5k9v2y/CuZqlWrcvXq1SwHyqrg4GACAgL49ddf07fFxMQQFhZG48aNb/u68PBwzGYzRYsWBaBx48Zs2LAhw3mVoaGhVKpU6banEIqIiEjB88fZKHpO38rF6CTKFfFg6fDalF/3mK1omczQZSo0fwZUtEQkkzJ1ZOufh8nefvttnnvuOd58802qV69+U6vLyil2cXFxHDt2LP3xyZMnCQ8Px8/Pj6CgIMaOHcvrr79OhQoVCA4O5uWXX6ZEiRJ07doVsC1+ERYWRqtWrfDy8mLr1q08/fTTDBgwIL1I9evXj8mTJzNs2DAmTJjA/v37+fjjj/nwww8znVNERETyt01HrzJi3k4SUtKoWcqH2X0rUuiHfnBmKzi4QI+ZUOVBe8cUkTwmU2XL19c3w7VZhmHwwAMPZBhzNwtk7Ny5k1atWqU/vnGN1ODBg5k9ezbPPfcc8fHxjBgxgqioKJo1a8bq1atxdXUFbKf6LVq0iFdeeYXk5GSCg4N5+umnM1xr5ePjw5o1axg9ejR169alcOHCTJo0Scu+i4iICAA/7bvI2EXhpKRZaVa+MF90LYHH4ofh8kFw8YG+30CZpvaOKSJ5UKbK1rp163LkzVu2bIlhGLd93mQy8eqrr/Lqq6/e8vk6deqwbdu2f32fGjVqsHHjxrvOKSIiIvnTwrAzvLh8H4YBnaoH8FEbT5zndYLoM+BZDAYsg4D77B1TRPKoTJWt+++/P/3PZ86cITAw8KZVCA3D4OzZs9mbTkRERCQHGIbBZ+uP8+4vRwDo1zCI1+pbcJjTERKugV9ZGPg9FCpj36AikqdleYGM4OBgrly5ctP2yMjIm+5nJSIiIpLbWK0Gr686lF60xrQqzxs1ruIwt4utaBWvBUPXqGiJyH+W5aXfb1yb9f/FxcWlX0slIiIikhtZ0qxM+G4vy3afB+ClzlV4tNAeWDASrBYIvh/6LAAXLzsnFZH8INNl68aiEyaTiZdffhl3d/f059LS0ggLC7vj/a9ERERE7CnJksaYhbtZe+gyDmYT73SvQffUVbB0AmBAtUfgkS/A8eb7bIqI3I1Ml609e/YAtiNb+/btw9nZOf05Z2dnatasyfjx47M/oYiIiMh/FJNk4dHZO9l+KhIXRzPT+tamzaWvYcO7tgH1h0PHt8HsYN+gIpKvZLps3ViRcMiQIXz88cdZup+WiIiIiL1cjk1i8MwdHLoYg5eLIzMG1aHBwddh12zbgFYvQotndbNiEcl2Wb5ma9asWTmRQ0RERCTbnY1MYMCMME5fS6CwpwtzB1Wn6paxcHglmMzQ+X2oN9TeMUUkn8pU2erWrVumd7hs2bK7DiMiIiKSXQ5HxDBoxnYuxyYT6OfGggFVCPplKJzeBA7O0H0GVH3I3jFFJB/LVNny8fHJ6RwiIiIi2WbnqUiGzt5BTFIqlQO8mN+rNIV/6AmX9oGzF/RdCMEt7B1TRPK5TJUtnTooIiIiecW6w5d5bMEukixW6pUuxKyH/PFa0gWiToNHURiwFIrXtHdMESkAsnzNloiIiEhutXzPecZ/+wepVoNWlYrw+QOOuC7sDPFXoFAwDFwGfmXtHVNECoi7KltLly5lyZIlnDlzhpSUlAzP7d69O1uCiYiIiGTFrM0nmbziIACP1C7Ju3WjcJw/AFJiIaA6DFgGnkXtnFJEChJzVl8wdepUhgwZQrFixdizZw8NGjTA39+fEydO0LFjx5zIKCIiInJbhmHwwZoj6UUrpEkZ3q92CsdvetqKVpnmELJKRUtE7rksl63PPvuML7/8kk8++QRnZ2eee+45QkNDefLJJ4mOjs6JjCIiIiK3lGY1ePmH/Uz97RgAz7StyP8CtmJeGgJpKVClC/RfCq5a7EtE7r0sl60zZ87QpEkTANzc3IiNjQVg4MCBfPPNN9mbTkREROQ2UlKtPLVoD/O3ncFkgtcersYT5qWYfnoGMKDuEOg5B5xc7R1VRAqoLJetgIAAIiMjAQgKCmLbtm0AnDx5EsMwsjediIiIyC0kpKQybM4OVu69iJODiU/61GDgtanw+1u2Afc/Dw9+CGYH+wYVkQItywtktG7dmh9//JHatWszZMgQnn76aZYuXcrOnTuzdPNjERERkbtxPT6FIbN3EH42CjcnB77sdx/N970AB38ATNDpXWgw3N4xRUSyXra+/PJLrFYrAKNHj8bf358tW7bw0EMPMXLkyGwPKCIiInJDRHQSA2eEcfRyHL7uTszuV5lamx+DkxvA7ATdvoT79MtfEckdsly2zGYzZvPfZx/26dOHPn36ZGsoERERkf/vxJU4Bs7YzvmoRAK8XVnYN5iyv/SHiL3g7Al9FkDZlvaOKSKSLsvXbAFs3LiRAQMG0LhxY86fPw/AvHnz2LRpU7aGExEREQHYfz6antO3cj4qkbKFPfi+XwnK/tjNVrTcC0PIShUtEcl1sly2vvvuO9q3b4+bmxt79uwhOTkZgOjoaN58881sDygiIiIF29bj1+jz5TauxadwX0lvvuvmRfGlD8P1k+AbBMPWQIna9o4pInKTLJet119/nenTp/PVV1/h5OSUvr1p06bs3r07W8OJiIhIwfbLgQgGz9pOXHIqjcr6saR9GoUWd4W4S1DsPhgWCv7l7B1TROSWsnzN1pEjR2jRosVN2318fIiKisqOTCIiIiIs2XmW57/bi9WAdlWL8Wnt8zgvHg5pyVC6KfRZCG6+9o4pInJbd3WfrWPHjt20fdOmTZQtWzZbQomIiEjB9sXvx3luqa1o9a4XyOdV9uG8LMRWtCo/CAO+U9ESkVwvy2Vr+PDhPPXUU4SFhWEymbhw4QILFixg/PjxPPbYYzmRUURERAoIwzCY8tMhpvx8GIBRLcryVpHVOKwaC4YV6gyCnnPAyc2+QUVEMiHLpxE+//zzWK1WHnjgARISEmjRogUuLi6MHz+eJ554IicyioiISAGQmmblhe/3sWTnOQBe6FiREfFfwrovbQOaj4fWL4HJZMeUIiKZl+mydfLkSYKDgzGZTLz44os8++yzHDt2jLi4OKpWrYqnp2dO5hQREZF8LMmSxpPf7GHNwUuYTfBO18r0OPM6HFhmG9DxHWg40r4hRUSyKNNlq1y5cpQuXZpWrVrRunVrWrVqRdWqVXMym4iIiBQAsUkWhs/dybYTkTg7mvmsRwXa7B0HJ9aD2QkemQ7Ve9g7pohIlmW6bP3222+sX7+e9evX880335CSkkLZsmXTi1erVq0oVqxYTmYVERGRfOZqXDIhs7az/3wMni6OzOoVTP3Nj8KFPeDkAb3nQfkH7B1TROSuZLpstWzZkpYtWwKQlJTEli1b0svXnDlzsFgsVK5cmQMHDuRUVhEREclHzl1PYOCM7Zy8Go+/hzMLexan0po+EHkc3P2h37dQqq69Y4qI3LUsL5AB4OrqSuvWrWnWrBmtWrXi559/5osvvuDw4cPZnU9ERETyoT8vxTJoxnYiYpIo6evGoq5eBK7sDnER4BMEA5dB4Qr2jiki8p9kqWylpKSwbds21q1bx/r16wkLCyMwMJAWLVrw6aefcv/99+dUThEREckndp+5zpBZO4hOtFChqCeL2hv4f98dkqOhaFXbPbS8S9g7pojIf5bpstW6dWvCwsIIDg7m/vvvZ+TIkSxcuJDixYvnZD4RERHJR37/8wqj5u0i0ZJG7SBf5jW9huf3wyE1CQIbQb9F4FbI3jFFRLJFpsvWxo0bKV68OK1bt6Zly5bcf//9+Pv752Q2ERERyUdW/HGBcUvCsaQZtKhYhK+qH8Jl+VjbzYordoAes8DZ3d4xRUSyjTmzA6Oiovjyyy9xd3fn7bffpkSJElSvXp0xY8awdOlSrly5kpM5RUREJA+bt+00Ty7agyXN4MHqAcwstxGXVU/ailatAdB7gYqWiOQ7mT6y5eHhQYcOHejQoQMAsbGxbNq0iXXr1vHOO+/Qv39/KlSowP79+3MsrIiIiOQthgGfrjvOx78dB2BQw0BecV2Ied3ntgFNx0KbV8BksltGEZGcclerEYKtfPn5+eHn50ehQoVwdHTk0KFD2ZlNRERE8jCr1WDZKTMbImxFa2yrMjwV9yGmsG9tA9q/CY1H2zGhiEjOynTZslqt7Ny5k/Xr17Nu3To2b95MfHw8JUuWpFWrVkybNo1WrVrlZFYRERHJIyxpVp79bj8bImxXLLzesQwDzrwMx38FsyM8/BnU7G3nlCIiOSvTZcvX15f4+HgCAgJo1aoVH374IS1btqRcuXI5mU9ERETymMSUNB5fsIt1R65gNhl81CWQhw48Aed3gZM79JoLFdraO6aISI7LdNl69913adWqFRUrVszJPCIiIpKHRSdYGDpnB7tOX8fVycwTpS/SZdf/4Nox25Lu/b6FwPr2jikick9kumyNHDkyJ3OIiIhIHncpJolBM7Zz5FIs3q6OzO/iSYXVj2GyXAfvUjBwGRSpZO+YIiL3zF0vkCEiIiJyw4EL0Yyav4uzkYkU9XLh285mglb3w2SJwihcEdPA78GnlL1jiojcUypbIiIictf2nYtm6m9HCT14CYDS/u4sbR1LkZUjIDWRSPdyeA1ciZNPMTsnFRG591S2REREJMt2n7nOJ78eZd2RK4DtNlmdqxfnzbL78F75NBhpWMu1YYtHb9q7+9k5rYiIfahsiYiISKaFnbjGJ78dY9OxqwCYTdC1Vkkeb1We8kdnwOpJtoE1+5LW8QPSfgm1Y1oREftS2RIREZE7MgyDLcev8fGvR9l+MhIAR7OJbnVK8njL8pRJPgy/joAjq2wvaPIEtHkV0tLsmFpExP5UtkREROSWDMNg/Z9X+OTXo+w+EwWAs4OZnvVKMapFWQKjd8JP/eDE+r9eYYK2k6HpU7aHKlsiUsCpbImIiEgGhmGw9tBlPvntKHvPRQPg4mimb4MgRrYoQ/GI9bBsLJzfaXuByQFq9IKmY6FoZXvFFhHJdVS2REREBACr1WD1gQg++e0Yhy7GAODm5MCARkEMbxZE0dM/wYJhcOWQ7QWOrlB7oO20wUKl7ZhcRCR3UtkSyeMMwyAxJZWY2Gjioq6REH2VpNjrpMRFkpYQiTUxClNiNObkaExWCw5VH6T+Az1wcnSwd3QRySXSrAYr915g2rpj/HkpDgAPZwcGNSnDo42K4390KczqA1GnbS9w9oIGj0Kjx8GzqB2Ti4jkbipbIrmAYRjEJaUQEx1JfNRVEmOukRx3HUtcJGkJ1zESoiDZVpicUqJxssTilhaLuzUOLyMOL+IJMGXy2oitP3J02xucrfwotdoPztHPJSK5W2qaleXhF/hs3TFOXI0HwMvVkSFNyjC0fhF8D86Dr6dBnO0eWrj72wpW/UfBzdd+wUVE8giVLZFsYrUaxMYnEht9lfjoayTGRJIcd43UuOukJV7HSIzClBSNQ3I0TpZonFNthckjvTAl4mUysv7Gpr//mIqZODyJd/AkycGbFEcvLM7epDn7gKsPpuQYKl5aRQXjNBUOvczFgx8R796B83XrU6ZUiez7ZohIrpaSamXZ7nNMW3+Ms5GJAPi6OzGsaTCDa3nh/ccM+OILSLJdr4V3KWj6pO2UQWd3OyYXEclbVLZE/iE1zUpMbCxxUVeJj7lGUmwkKbHXSI2/TlpiFCRGYU6KwiElBidLDC5/FSZPIw5PIx4fUxI+d/PG/yhMSTgTZ/IgwexFsqMnKY7eWJx9sLrYCpPZvRAOHoVw9vDD1asQbt6F8fAtjLu3H47OnviaTPje4a2SYq6xb9VHlPpzDsW5Rr/EBUR/tZzV/l0p1X4s91WqeDefQETygCRLGt/uPMv0309wPspWsvw9nBneoiwDqzrisWs6TJ8NlgTbC/wrQLOxUL0XODrbLbeISF6lsiX5TooljZjo68RFXyMh5irJMZFY4iOxJFzHGn8dkqIwJ0fjkBKDsyUG19RY3K2xeFjj8SYeP5MFv7t5438UpnjciDN5kujwd2FKdblRmHxxcPfF0cMPZ89CuHr74+blj6dvYVy9CuHq5IZrdn0zbsHV25/qfV/DsLzAodVf4rn7MwKJoEPkApIXLmatextc7n+KJg0a42A2/fsORSTXS0xJ45vtZ/hiw3EuxSQDUMTLhZEtytK/ggW3sA/h80VgtdheULwmNBsHVbqAWdd3iojcLZUtyZWSklOIibpGfPRVEmKu2QpTwnVS4yMxbhxhSonBKSXaVpjSYnFPi8fzr+uXCpusFM7qm/6jV6QZJuJMHsSbvUh08CTZ0QuLkw+pzt4Yrj6Y3HxxcC+UXpjcvPxw9ymMp29hXDwK4eHgiEc2fj9ygsnJjfIdHuentCDS/JMxtkwlOPEAbRJXY/35FzaHNiC+7uPc36YLbs76YUskL4pPTmVB2Gm+3HCCq3EpABT3cWXU/eXoExiFy7bX4LflYFhtLyjdFJqPg3IPgEm/bBER+a9UtiRHGIZBQkICsX8VpsTYa6TERpISf520+OuQeB2SY2zXL6X8ff1S+oIPpsS7O7rzj58NUnAkFk8SzJ4kOXiR7GQrTGl/nY7HX4XJydMPF09f3Lz88fApjKevP05uPviYzXd3SmBeYzJTslF3nJr34drBDUSGvkOF6xtpnhYG28PYs70Spyo9StPOAyjqrWs1RPKC2CQLc7ee5uuNJ7ieYDtaVaqQG4+3LE+PImdx3vosrFnz9wsqtLeVrKBGdkosIpI/2bVsbdiwgXfffZddu3Zx8eJFvv/+e7p27Zr+vGEY/O9//+Orr74iKiqKpk2b8vnnn1OhQoX0MZGRkTzxxBOsWLECs9lM9+7d+fjjj/H09Ewfs3fvXkaPHs2OHTsoUqQITzzxBM8999y9/Kh5kmG1EhsXQ9x12/VLyTHXSI63HV1KS7gOiVGQFI1jSgxOKTG4pMbgZo1LX/DBw5Ryd0d3/lGYEnAhzvR3YUpxunH9kje4+mJyK4SjRyGcPHxx8fLH3fvvwuTs7I6/yYR/Nn0/CgL/qi3wr9qChPMHOLfqXcpcWEFtjlD7yLOcOPwhv5ccQM1OI6hYqoi9o4rILUQnWJi15SQzN50kJikVgDL+7jzeshzdvA/juHkknNliG2wyQ7VHoNnTEFDdjqlFRPIvu5at+Ph4atasydChQ+nWrdtNz7/zzjtMnTqVOXPmEBwczMsvv0z79u05ePAgrq624x79+/fn4sWLhIaGYrFYGDJkCCNGjGDhwoUAxMTE0K5dO9q0acP06dPZt28fQ4cOxdfXlxEjRtzTz2sPaWlpxEVHEhd1lYSYv++/lBp/HWvCdYykaMzJUTgm265fcknLuOCDtykN77t5478Kk9UwEWdy/+v6pb8LU9qNwuTmi9m9EI7uhXD2LJRemDx9/fHw9sfdyQUdS7n33EtWo+KI2aRFX+T4T+8T8OdCynKBshfe4fJXX7LEtxuBbUfTqFo5TDrVSMTuIuNTmLHpBHO2nCYu2Vayyhf1ZEzLYLo47cRhc3+I2GsbbHaCWv2g6VPgX86OqUVE8j+7lq2OHTvSsWPHWz5nGAYfffQRL730Eg8//DAAc+fOpVixYixfvpw+ffpw6NAhVq9ezY4dO6hXrx4An3zyCZ06deK9996jRIkSLFiwgJSUFGbOnImzszPVqlUjPDycDz74IE+WrSvHj7Bm3isElqyIi6cb1pQYjITreEZeYO+fX+GSGvvXgg9xfxWmBHxMxn9aIc9iOBBr8iDB5EmCgyfJjt5YnLxJc/HG6uL71+l4vjh6FMLZ0w83L3/cffzx9CmMu5cv3g6Od1fYxO4cfIpTru97kPw/zq6djseeLyiaeoVe0TOJ+3Yh369oj0uzMbRtXA9nR7O944oUOFdik/l64wnmbTtNQortXnuVA7x4omUQHdM2YN48Dq4dsw12cod6Q6HxaPDWrR5ERO6FXHvN1smTJ4mIiKBNmzbp23x8fGjYsCFbt26lT58+bN26FV9f3/SiBdCmTRvMZjNhYWE88sgjbN26lRYtWuDs/PeSte3bt+ftt9/m+vXrFCpU6Jbvn5ycTHJycvrjmJgYACwWCxaLJbs/bqZtXP4RdRaFA+GkORg4+aTi7ZuCSyELrr6puPhacHD6x72a/ipMiYYzsSZPEswef62Q543FyYs0Fx8Ml7+uX3LzxdHD9+/C5O1nWyHP3Qsvkwmvu8ibajX+Xt1Kcp0bc/lf57TZlYB2Y+GB0Vzavgi2fEKxpBN0S/4By9qVhP7WjKhaI2jbsjW+7k45H1zuqUzPE7lnLsUk8dWmUyzeeY4ki21xi2olvHiyaXEeSFyNw68jMcVeAMBw9cVafzjWesPB/a+1Vu/R36XmjmSG5olkljUhAbP73+c82XPuZPY9c23ZioiIAKBYsWIZthcrViz9uYiICIoWLZrheUdHR/z8/DKMCQ4OvmkfN567XdmaMmUKkydPvmn7mjVrcHe334ltUdFJnCoBxa6CW4oJa6QTUZEZf7hN9vEksVhhkgKKk1SiJKlBwVj9/DK3slQSkJQGVy8Dl3PkM0juExoamoXR/lD5f/hE7aP4+VVUshyik/E77PmdDbtqsNmrM0UDK1PYTacX5jdZmyeSEyKT4dfzZrZdNpFq2P4bK+1p8HDxWDpYvqPcz2twTI0FIMnRl2NFO3C6cCtS49xg/Ta75dbckczQPJHbcbpyhUKbNuO9ezenn3oSS+GMa07bY+4kJCRkalyuLVv2NnHiRMaNG5f+OCYmhsDAQNq1a4e3tx1PiuvUCcMw2BWxg8Ubv+Ta/p2UuWRQ5jJUuOqEd1QKLtFxuETHwZ+n0l9mLlQIl0qVcKlcCZeKlXCuXAnn4GBMjpoCBZnFYiE0NJS2bdvi5JTVI1KdgedJPLubK6HvU/JiKC3Me2kRv5e9B4PZFtCPmm0HUqdMlhfhl1zmv80TyQ5nIhP4YsNJvv/jApY029kL9Ur78nRDbxpdXox59yxMKXEAGL5lsDYeg0ONPlRydKWSHXNr7khmaJ7IrRiGQWJYGFHz5pOwYUP69rrJyfh16gTYd+7cOOvt3+Tan7QDAgIAuHTpEsWLF0/ffunSJWrVqpU+5vLljEdfUlNTiYyMTH99QEAAly5dyjDmxuMbY27FxcUFFxeXm7Y7OTnlin8IGgc1pXH/phyJPMLMfTN599RqrFjxSnCgeWIQD1mrU/qSlZTDR0g+cQLr9eskbttG4ra/f7NpcnbGpUIFXKpUxrVyFVyrVMalUiUc/rGSoxQM/2VeO5VtSNDIJRiRJ7mw+n38jy6hhvkkNS6/wZl5XzLLuwelHxhOm5pldZPkPC63/PtXkJy4Ese0dcdZHn6eNKutZDUp58/4Bm7UPjsX06p5kPbXKe9Fq0KzcZiqPYKDgyO56e54mjuSGZonAmBNSSFm5Soi58wh+cgR20aTCc9WrfAbPBj3BvVvWpzLHnMns++Xa8tWcHAwAQEB/Prrr+nlKiYmhrCwMB577DEAGjduTFRUFLt27aJu3boA/Pbbb1itVho2bJg+5sUXX8RisaR/U0JDQ6lUqdJtTyHMSyr5VeL1Jq9TJbIKFwIusPzEcn5yP8tPnKVkcEkGDxvMQ4EdMZ88T/LhQyQdOkzS4cMkHz6MNT6epAMHSDpwgOh/7NMpKAjXypVt5atyZVyrVMGxWDGtOid3ZPILpkS/TyF+MlfXfYrrnhkEcYURcZ8TuXwec1Z1xrXpSB5uUhMPl1z7T49IrvDnpVg+/e0YK/de4K+ORYuKRXiujsF9J2bC8m/BsC2IQan60PwZ272yzFqoRkTyptTISK5/8w3Xv1lE2tWrAJjc3PB95BH8Bg3EuUwZ+wa8S3b9iScuLo5jx46lPz558iTh4eH4+fkRFBTE2LFjef3116lQoUL60u8lSpRIvxdXlSpV6NChA8OHD2f69OlYLBbGjBlDnz59KFHCttJSv379mDx5MsOGDWPChAns37+fjz/+mA8//NAeHznHFDIXon+9/jxe+3G+OfIN3xz6hvNx53kz7E0+D/+cvlX60vfBvgT06AHY7qFlOXfur/J1iOS/SlhqRASWM2ewnDlD7D9ueOng65vxCFjlyrgEB2PSb6Dk//Pwp/CD/4N2zxIbNoe0TZ/gl3yeoamLSVq/jOW/tyKq5ki6tm5GgM9d3bpaJN86eCGGT9cd5ef9ERh/law2VYryXPV4Kv75MSxf+ffgsq1sJatMs8xdkysikgslHz1K5Ny5RP/wI0ZKCgCOAQH4DeiPb8+eOPjc1ZrauYZdy9bOnTtp1apV+uMb10gNHjyY2bNn89xzzxEfH8+IESOIioqiWbNmrF69Ov0eWwALFixgzJgxPPDAA+k3NZ46dWr68z4+PqxZs4bRo0dTt25dChcuzKRJk/Lksu+Z4evqy2M1HyOkWgjLjy1nzoE5nI87z2fhnzFr/yy6V+jOwKoDKeFZAuegIJyDgvBu3y799anXr5N8+HCGEpZ84gRpUVEkbN1GwtZbnIZYuVKGEqbTEAUAZ3e8mj8GTUeQvG85sb++T+GYA/RhDWnhoazZ04DDZYfQvl1nqpbQzQGkYNt7Loqpvx5j7aG/T3vvULUYEypfJvjQa/Dj739tNUGVB6HZOChZxz5hRUT+I8MwiN+0icjZc4jfvDl9u2v16viFDMa7Xbt88wt9k2EYxr8Pk5iYGHx8fIiOjrbvAhm3YLFY+Omnn+jUqdNN54+mWlMJPR3KzP0zORx5GAAHkwMdgzsSUi2ESn7/fum0NTmZ5GPHbiph1vj4W453CgzEtXLlDEfCHAMCdBpiLnSnuZPtDAPryY1cW/MuRSL+vtB1a1pVNhbtS/22vWlZqajmSS50T+dJAbPr9HU++e0o649cAWwHqLpUD2BC8ElK7v8Mzu+yDTQ7QvVe0GwsFLHnkhdZo7kjmaF5UnBYk5KI/vFHIufOJeXYcdtGsxmvNm3wCxmMW+3aWfo5wJ5zJ7PdQBdO5HOOZkc6BnekQ5kObL24lZn7ZxJ2MYyVJ1ay8sRKmpVsxtD7hlKvWL3bTm6ziwtu1arhVq1a+jbDasVy/jxJhw79o4QdJvXiRSxnz2I5e5bYfyzD6eDjg0uVKv+4FqwKLmV1GmKBYjJhLtuCIqNawKUDRIa+j8+x5TR2OEjjay9zeOGXvOvejeBWg+lSpwyuTrnp8n6R7LXtxDU++e0om49dA8DBbOKRGkUZX/IAAXtfgz8P2QY6ukKdQdDkCfANsmNiEZG7l3rlCpELFxK1aDFp168DYPbwwLdHdwoNHIhzqVJ2TphzVLYKCJPJRJMSTWhSogkHrh5g1oFZhJ4OZdP5TWw6v4nqhasz9L6htApshYP533/INZnNOAcG4hwYCO3+32mIR46QdOhw+oIcycePkxYdTcK2bST8czVEJ6dbr4bodTe3T5Y8pVg1/AbMhOhXif39E5zD51KZs1RO+piLP81j+i+dcW04jF7NquHn4fzv+xPJAwzDYPOxa0z97SjbT0YC4Gg20btWEcYV3YF/+PNw+LRtsIs31H8UGj0GnkXvsFcRkdwr6dAhImfPIfqnn9Jvpu5UsiSFBg7At0ePAnHpicpWAVStcDXeu/89zsScYc6BOSw/tpx9V/fx9PqnKeNdhsHVBtOlXBdcHG5e+v7fOBYqhGOjRng0apS+7U6nISYdPEjSwYMZV0MsVSrDSoiulSvjWLy4Ti/Lj3xK4fXQ29B2IklhM7Bu+YziKVcZa51HzJalLN7chmv3DaNXq/qULZL//0GW/MkwDNb/eYWpvx5lz5koAJwdzAyoXYgnfTbi+8dXcPCva7XcC0Pjx21FyzVvXxQuIgWTYbUSt/53IufMISEsLH27W+3a+IWE4PVA6wJ1n9eC80nlJkHeQbzc+GUeq/UYCw8tZNGRRZyKOcXkrZOZFj6N/lX606tSL7yd/9s1av9+GuIRkg7bSljqhYtYzp3Dcu4csaFr/96Hj4/tFMQb14JVqYJL2bI6DTG/cPPFteUz0GwMqX8sJnH9h3jHnmC4aQUpB37i+33NmRU0iAcfaEmDYD8Vb8kTDMMg9OAlPl13jL3nbL9ScnE0M6yON4+5heL1x0xI+utXTd6loOlTUHsAOLvbMbWIyN2xJiQQtXw51+fOI+XUKdtGBwe827e3XY9Vo4Zd89mLypZQ2K0wT9Z5kmHVh/Hdn98x9+BcLiVc4uPdH/P1vq/pWbEnA6oMoJhHsWx7z9udhpgWFUXS4SMZlqNPPn4ca3Q0CWFhGX5DYnJywrlCedspiP+4L5hOQ8zDHF1wrDsIr9oDMP5cTexv7+N9eSe9HdbT+/x6QmfVYaJfb5q06kKn6sVxdNA9hST3sVoNVh+I4JPfjnHoYgwAbk4OPFbHlUcdVuG+bz5YEmyD/StAs6ehek9w1CmzIpL3WCIiuL5gAdeXfIs12vYLJLOXF769euI3YABOxYvbOaF9qWxJOg8nDwZVG0TfKn35+eTPzNo/i2NRx5h9YDbzD83nwbIPMqTaEMr6ls2xDA6+vng0aohHo4bp26wpKaQcO/b3DZkPHSLp8GGscXEkHzxE8sFDOg0xvzGbMVXuhHflTnB2O3HrPsD9xGraOuymbfRudi/7ikmrulGueS96NSiDl6uOcIr9pVkNVu69wKe/HePo5TgAPJwdGFvbzEDrclz3LQGr7ZoFiteC5uOg8oOQietkRURym8R9+4mcM4eY1ashNRUAp9JB+A0chO8jXTF7eNg5Ye6gsiU3cTI78VC5h3iw7INsOr+JGftmsPvybpYfW87yY8tpFdiKofcNpVbRWvckj9nZGdeqVXGtWjV9m2EYf5+G+FcJu+NpiN7eGVZCdK1S2XYaorN+k5zrBTbAc9AiuHqMpA0f4bhvMXXMx6hjeYcTa+fy4a9dcKnXjwHNq1DS183eaaUAsqRZ+SH8Ap+tO8aJq7ZbYni5OvJczRR6Jy3Gee8KMKy2waWb2UpWuda6EbGI5DlGWhqxv/5K5Jy5JO7alb7dvX59/EIG49myJSYH/QLpn1S25LbMJjMtSrWgRakWhF8OZ9b+Wfx29jfWnV3HurPrqFO0DkPvG0rzUs0xm+7t6VwmkwnnUqVsS4W2bZu+PcNpiH9dC5Z87BjWmBgStm8nYfv2v3fi5IRL+fIZTkF0rVwZh1x2HzX5S+HyuHb7FNpNInXrdNK2f0VZSwST+IorOxczN6wDVyoPoH/LWlQvpYUFJOelpFr5bvc5Plt/jLORiQD4ujvx0n3RPBy3CKc//v6FDxU72G5EHNTwNnsTEcm90uLiiV72HZFz52E5d8620ckJn04dKTRoUIbr8iUjlS3JlFpFa/Fx6485EX2COQfm8OPxH9l9eTe7f9tNed/yhFQLoVNwJ5wc7Hs6121PQzx+PMNKiEmHD2ONjSX50CGSDx0i+vu/9+FUsmSG5ehdK1fGsUQJnYaYW3gWxbHtJBxbjMO6ey4pGz+hSMIFnnFcQvzRH1h8uBXTi/flkVaNaV25KGaz/t4keyVZ0vh251k+X3+cC9FJAPi7O/HqfRF0uL4Qh71bbQNNZqjWzXZNVsB9dkwsInJ3LOfPEzlvPlFLl2KNs50e7eDjg2+fPhTq1w+nYro1xb9R2ZIsKetTlslNJjO61mjmH5zPkj+XcCzqGC9tfolP9nzCwKoD6VGxBx5Ouec8XbOzs+3arSpVgEeAG6chXki/F9iNa8EsFy5gOX8ey/nzxK399e99eHvjWqlSxnuClSun0xDtycUTc+PHcW0wHA4sJ3H9B3hEHmSo42oGXV7Dym8aMdKrJy3vf4DudUrpJsnynyWmpPHN9jN8seE4l2KSAQjwdOT/2rvv+Kiq9PHjn2lJJpM66QkJIZCEHnoNHQERBESpUu1ib6v727Ws61rABq7KqkCoiqJioUiH0EsKgUAKJQmk955J5v7+GBzNF9SIhEngeb9eefHi3jN3nhsOM/PMOec5/2l3lsE5K1HHH7c01NhBl2nQ7zHwaG3DiIUQ4upUxMRQELWc0p9+ArNlGrRdSAjGmTNxHXc7ar1M228oSbbEVfF29OapHk9xX+f7WHt6LSsTV5Jdkc2CIwtYHL+YKeFTmNZuGp56T1uHekWWaYgB2LUIwHn4cOvxuuJiqk6drp+E/TwN8fBhKg4f/uUiOh32rVvXXwvWNhyNq0xhu640Ouh8F/pOd8KZHVTvehf7tN2M1+xjfMU+dv/QiSc3jye0z1hm9gvG0+nP7x8nbm7l1bWsPHCeT/acIa+sBoBAFw1vhp6kT+ZK1MdTLQ11BugxB/o+Ai43d/UtIUTzo9TWUvrTT+RHRVEVF289bujXF+OsWRgGDECllirAf5YkW+IvcbZz5p5O9zCj/Qy+T/2eZSeWca7kHJ8c/4SoE1GMazOO2R1mE+QSZOtQG0Tj6oqhdy8MvXtZj102DfHSWjBzSQnVp05RfeoUxd/+cg2dvz/27drVS8J0ATINsdGpVNB6KPath0JmHKY976NJ/JaBmuMMNB/nRPRy/rNnLA4RE5kzIJRQH9kiQPy+0ioTy/ef59M9ZyissFQRbOOm4s1WsXTLWIHqxEVLQwc36PMQ9LofHI22C1gIIa5CXUkJRV9+RcGqldRezAQs2+u43D4W48xZOISH2TjC5k2SLXFN2GnsmBg2kfFtxrMzfSdLEpYQnxfPl0lf8lXSVwxvOZx7Ot5DB8/mt4Dyt6Yh1l68aKmC+Ku1YKYLFyxTES9epGzbr6YhOjv/siGzTENsfH4R6CYtgcKXMO//L+ajy+nAed7hAzKOf85nMbeSGXIXMwd1oG9rD0mERT3FFSaW7D3L0r1nKamylDPuaDTzRuBBOqStQpVYYGno5Av9HoHus8FeknchRPNSk5ZGwfIVFH39NUqFZe8/jdGI+9SpuE+dgtazac5Oam4k2RLXlEatYVjLYQwNGsrR7KMsSVjCngt72HJ+C1vOb6G3b2/mdJxDP/9+zfoDrkqlQhcQgC4gAOdhw6zH64qLqTp9mmprEnZpGmJp6eXTELVa6zREaxLWNhyNm9v1v6EblXtL1KPfQj34eZTDn1K7/2NaVOXxkm4FRWlfs2LZLXzgMZG7BndjTGd/dLJJ8k2toLyGz6LPELXvPGXVliSrp6eJ13x3E5q2FtXpUktD92Do/4RlXZZWpqUKIZoPRVGoPHKE/GVRlG3fDooCgH1oKMbZs3AZMwa1vbyuXUuSbIlGoVKp6OHbgx6+PUgqTGJZwjI2nt3IwayDHMw6SFtjW+Z0mMOI4BFo1TdON9S4umLo1QtDr1+mISo1NVSfOUNV4ql6a8HMJSVUnz5N9enTsH69tb3W3+9S4nUpCWvXDl1AQLNOTm3O0Yhq0HPo+j0KcWsw7VmEW/EZHtV+y/1FP/LVuoFM2zCBYZH9mNorCFe9bJJ8M8ktreaTPWdYeeA8FTV1AAzyKudfntsJSvsaVYqlGAbeHSx7ZLUfD5ob53VLCHHjU2pqKNm0iYJlUVSdPGk9bhg4AI/Zs3Hs21c+ZzQSebcQjS7MPYz/DPgPj3Z9lOUnl7MueR2nCk7xtz1/Y2HMQma2n8mE0AnotTdmZRuVnZ1l/VbbtsB44PenIdZezKTsYqblG6dL1M7Ol6oh/rIWzK5NG9QyDfHP0emhx1x03WbBqR+p3fMe9plHma7dxtSa7Wze2oMHt91O257DmNu/FYFGR1tHLBpRVnEVi3ensvpgGtW1lmpbo30K+YfrZvzSf0RVakm8aNELBjwNYSNlI2IhRLNSV1RE4RdrKVy1itqcHABU9va4jh+PceYM7FtLxdTGJsmWuG78nPz4W6+/8WDEg6w5tYbViau5UHaB1w+9zkdxHzGt7TSmtp2Km4ObrUNtdL85DfHSaNfPo19VpxKpTr40DfHIESqOHPnlIpdNQ7y0KbNMQ/xjag20vx1tu7GQtp+66PfRJG/iVs1hbuUwBw+v4pUDt+HQbjT3DGxN1yB3W0csrqELRZV8tDOFtYczqKmzJFl3+WbznGEDXhe2QPGlhq2HWpKslv0lyRJCNCvVZ85SsDyK4m/Xo1RZ9gPUennhPn0abpMno3WX97XrRZItcd252rvyYMSDzOowi/Up61l2YhkXyi7wYdyHLD2xlAltJjCzw0wCnAJsHep1p3FxwbFnTxx79rQeU2pqqD57lqrEXzZkrjp1CnNx8ZWnIfr5/aoS4qVpiC1ayPSAK1GpoGU/NC37Qc4plH0LUeLX0ptT9FafIjnpc/6XeBtvBtzG7IFtuaW9DxrZJLnZSsuv4MOdKaw7loGpTgEU5vql8aj997hn7YMiABW0G2uZLujf1bYBCyHEn6AoChUHDlCwLIqyXbusx+3bt8Nj1ixcbr1VCnPZgCRbwmb0Wj1T2k7hzrA72Xp+K0sSlpBYkMjqU6v54vQXjAweydyOcwk3hts6VJtS2dnhEB6OQ3j4z7MQLdMQMzMvTUNMtBbkMGVkUJuZSVlmJmU7dlivoXZywr5tOA7t2+M+aRL2bdrY5maaMu+2qMZ/iGroP+HgR9QdXkJozQXmq/9HdvZalq4ZxSLXMUwe0Ik7u7fA0U5ePpuL1Nwy/rsjhfWxF6kzK6gw85h/Mverv8UpL87SSK2FzpMthS+8pMyxEKL5MNfUUPL9DxQsX275AhZApcJpyBCMs2bh2KunfOFqQ/JpQdicVq1lVKtRjAweyYHMAyxJWMKBzANsOLuBDWc30N+/P3M7zqWnr7xY/EylUqHz90fn74/z0KHW41eahliTnIK5rIzKI0epPHKUwpWrcLvzTrwefQRkyuHlXPzgln+hGfAMHF1G3f4P8SnL5Hnd58wrX8/qH4cybvNYRvTtyqy+wXi7ONg6YvEbkrJL+WB7Cj/EX8SsgIY6XghIYGbd1+gLki2NtA7QbZalhLtb89gPUAghAGrz8yn8/HMKV6+hLj8fAJVej9sdd2CccTd2wcG2DVAAkmyJJkSlUtHXvy99/ftyMv8kSxOW8tP5n9h7cS97L+6lo0dH5nScw7CgYWjUGluH2yT93jTE6lOnKPlpC2XbtlG0di3FP/yA++xZqHx9bRhxE+bgAv0fQ9P7QUj4CnP0+zjnneIB7Y/MVTaxPro/s3ePoV1EH+4b2Iq2vi62jlhccuJiMR9sT2FjQhYA9tTwz4Bj3FX9Nfb5GZZG9i7Q817o8zA4edkwWiGE+HOqkpIoWL6cku++R6mpAUDr64vx7um43XUXGldXG0cofk2SLdEktfdoz/xB83ms5DGiTkbxbcq3JOQn8PSup2np0pJZHWZxe+vbsdfIXhB/5NfTEF3HjaPiyBGy58+nKi6egg8/opWzM8V1dXjcdRcqrbwkXEZrB12moY6YCslbUPa+h+78Xu7U7OZOzW62H+/Cy7Fj0IUM4N6BrRkY6ikjsDYSn1HEwm0pbE3MBsCJCv4VcIixFd+gy8+1NHL0hL4PWxItB/lAIoRoHhRFoTw6moJlUZTv3Ws97tCpk2V/rBEjUOlk25KmSD5ZiSYt0CWQf/T5Bw9FPMSaU2tYc2oN50vO86/9/+K/Mf/l7vZ3Myl8Ei52MqrQUI49ehD8+eeUbtpE9tvvQEYGua/8i+JVq/B+5hmcBg2SZOFKVCoIG4EqbARcOAp7F6IkfsdQTSxDNbHEpoXwv2VjeMNzKHMGtmFcF3/stTICez0cPV/Iou3J7DxtSaiMqhL+47+XW0q/Q5N/qbSgayD0ewy63g12UtJfCNE8mKuqKF7/HQXLl1OTmmo5qFbjPHw4xtmz0HftKu/ZTZwkW6JZ8NB78EjXR5jbcS7rktex/ORyssqzeP/Y+3wS/wl3hd3FjPYz8DH42DrUZkGlUuFy6604DBzI/pdexnfPHmpSUsl48CEce/fG+7ln0XfoYOswm66A7jApClV+Kuz/L+aYVXThDB/aLeRc0Rd8+s1oFm66hSn9wpjeuyXuBqn+1BgOnMln0fZk9qZY1iq0UBfwH9+dRJb8iDq/0tLIMwwin4ROd4FGvvUVQjQPppwcCtesoWjN59QVFQGgNhhwu/NO3GfcjV2LFrYNUDSYJFuiWXHUOTKj/QymtJ3CprObWJKwhJSiFKJORrHq1Cpua3UbczrOobWbbNLXECo7O4oGRNL7+ecpXrqEwhUrqTh4kHMT78Rl7Fi8n3gcXcDNV4K/wTxaw5h3UA/5Oxz6H+ZDnxBcmc2/1UvJN31F1LaRjN4xkuHd23NPZCuCPQ22jrjZUxSFvSn5LNyezKGzBQC0UWfxH59t9Cz+CVWBydLQr4tlj6y2Y0Cttl3AQgjxJ1QlJlKwLIriDRvAZHk90wUE4D7jbtzuvBONk5ONIxR/liRbolnSqXWMbT2WMSFj2HNhD0sSlnA0+yjrU9ezPnU9g1sMZm6nuXT1ln1yGkLj6oLPs89inDaNnPfep+T77yn5/ntKN2/GfcbdeD7wABoXmar5mwyeMOTvqPs/DjGrUPZ/gEfReZ7SfcVDynd8cWQwMw6Opl27Ttw3MIQeLd1l2sefpCgKO0/nsnB7MjFpRQBEaNJ41fMnOhXvQFWoWBoGD7CMZLUeKhsRCyGaBcVspmznLgqWLaPi0CHrcX3Xrhhnz8Z52FBZU92Myb+caNZUKhUDWwxkYIuBxOXGsTRhKdvTtrMzYyc7M3bSxasLczvOZVDgINQq+Xb7j+gCAgiY/xbGmTPJmT+fikOHKPhsCcVfrcPz4YdwnzpVNkT8PXYG6H0/qh5zIXE9yt6F6DNjma39iRmaLWxI7s0riWPQtOjG/QNCGNnBB61G+uXvURSFLSezWbQ9heMXLOuv+mlP84rxJ0JL9sOlJVmE3WrZiDiwl+2CFUKIP8FcUUHRN99QuHwFNefPWw5qNLiMHGlZj9W5s20DFNeEJFvihhHhFcF7Q97jbPFZok5E8V3qd8TmxvLYjscIcQ1hdofZjAkZg07WbfwhfaeOBEUto2zXLnLmL6AmNZXs19+gYOUqvJ9+CueRI2Vk5vdotNBxIqoOd8DZ3bBvIZqUrYzVHGCs5gB7szqw+PMxvO7Sm7mRIUzqGYiTvbwc/5rZrLAxIYtF25M5lVUKKIzQHeefrhsJLIuDEkClho4TLSNZPrLGUAjRPJiysihctYrCL9ZiLikBQO3sjPvkSbhPn47Oz8/GEYprSd7dxQ2nlWsrXu73Mg93eZhViatYe3otZ4rP8OK+F/kg9gNmtp/JxNCJONnJvOffo1KpcB48GKfISIrWfU3uokWY0tO58MST6CMi8P7bczh262brMJs2lQpCBll+shJg3yKUhK/ozwn6a06QWBHE/zbcxqKtA5jUK4TZ/YPxc9XbOmqbqjMr/BB/kQ+2p5CcU4YaM3faH+FZwwZ8KpKgDNDYQZfp0P8xMIbYOmQhhGiQyuPHKVgWRcnmzVBbC4CuZRDGGTNxmzAetUHW9d6IJNkSNyxvR2+e7P4k93a6ly+TvmTlyZXkVOSw4MgCFsctZnLbyUxvNx1PvaetQ23SVFot7pMn4TrmNvKXLCV/yRIq4+I4P206zrcMx+upp7Bv1crWYTZ9vh3hjsWohv4DDnyEciyKdjVpvGv3EReUtSzZO4pR0cMY0jmEeweE0DHg5toDylRnZn3sRf67I4WzeeXoqGWmwz6edNiAe1UaVAA6A/ScC33mgYt88yuEaPqUujpKt22jIGo5lUePWo879uyJcfYsnAYPRqWRbUJuZJJsiRues50zczvO5e52d/PDmR9YmrCUcyXn+PT4pyw/sZzb29zO7A6zaenS0tahNmlqgwGvRx/BbfIk8hZ9QNG6dZRu2Urpjp24T5qE5yPz0BqNtg6z6XMLhFH/QTXoWTiyBOXAxwSU5/BP3SoeV75hRcJw5sSOok1Ia+4b2IrBYd6o1TfulM2aWjPrjmXw4c4U0gsq0VPFPP1uHtJtwKkmB6oAvTv0fhB63Q+O0seEEE1fXVkZxevWUbBiJaaMDMtBnQ7X0bfiPnOmbK9yE5FkS9w07DR23BF6B+PbjGdH+g6WJCwhPjeer5K+Yl3SOoa3HM7cjnPp6NnR1qE2aTpvb/xe/RfGmTPIWfA2Zbt2Ubh6NcXr1+Nx330YZ81Erb+5p8I1iN4dBjyNqs88iP8C9i3CJT+ZedrvuFezga/TBvBa1Gj+4xXOPZGtmNA1AAfdjfPtZ5WpjrVH0vl4ZyoXi6twoYy/6bcxW7sZvakIagBnP+j7CHSfDfYy7VcI0fTVZFygcMUKitatw1xWBoDG1RW3KVNwnzYNnY+3jSMU15skW+Kmo1apGRY0jKGBQzmWc4wlCUvYnbGbLee3sOX8Fnr69mRux7n09+8vRSB+h31oKIGLP6b8wEFy3nqLqpMnyX3vPQrXrMHr8cdxHXe7TI1oCJ0DdJ8FXWdA0kbYuxD79ANM1e5gqnYHPxV2Z/E3Y1iwuRMz+rZkRp+WeDjZ2zrqq1ZZU8fqQ2ks3pVKTmk1XhTyquNPTFZtwa6uAkyAeyuIfAIipoK2+d6rEOLmoCgKlTGxFERFUbplC5jNANiFhGCcORPXcbfLl5A3MUm2xE1LpVLR3ac73X26k1yYzLITy9hwZgOHsw5zOOswYe5hzOk4h1HBo9Cq5b/KbzH06U3wV19S8uOP5Lz7LrUXM8n8+98pWL4c72eewSmyv61DbB7Uamh7m+Un7SDsW4hy6kdGaI4yQnOUI6Yw/rf9Nvrv7MmEbkHcO6AVrb2az2hPeXUtKw+c55M9Z8grqyFQlc07jpsYxw405hpLI5+OlsqC7cdbKjoKIUQTptTWUvrTT+Qvi6IqPt563NCvL8bZszFERqKSTdVvevJuJgQQ6h7Ka5Gv8UiXR1iRuIKvkr4iqTCJF/a8wKJji5jZYSYT2kzAUedo61CbJJVajevYsTiPGEHhypXkfbyY6lOnSL/3Xgz9++P93LM4hIfbOszmI6g3BK1ClZdsqWAYt4YeJNHDLolUsx//OzqG0Yf6E9m2BfcOCKFPiLHJjsKWVJlYvu8cn0WfpbDCRJgqnf8YfmS4eS9qc52lUWBvGPA0hI6QjYiFEE1eXUkJRV9+ScHKVdRmZgKg0ulwuX0sxpmzcAgPs3GEoimRZEuIX/Fz8uO5ns/xQOcH+OL0F6xKXMXF8ou8cegNPo77mKltpzK17VTcHdxtHWqTpLa3x+Oee3C94w7yP/6YgtVrKN+7l7Pj9+E6YQJejz+GzsfH1mE2H56hcPtCVEP+HxxajHL4U1pXZfKm+hOe0a5lafIoHjg1jKAAf+4bEMLoTn7omsgmycUVJpbsPcvSvWcpqaqliyqFRYYfiaw7CJdyLFoPsyRZLftJkiWEaPJq0tIoWL6Coq+/RqmoAEBjNOI+dSruU6eg9ZTqxuJykmwJcQWu9q7c3/l+ZrafyfqU9Sw7sYyMsgw+ivuIpQlLmRA6gZntZ9LCuYWtQ22StO7u+LzwAu7Tp5PzzruUbtpE8ddfU7JhA8ZZs/C47140Ts1nCpzNOfvAsBdRRT4Jx5bD/g/xKsngOd0XzNN+y5rsobz5+a28ubEFs/sHM6VXEC4Ottm8u6C8hk/3nGH5/vOUVZvor07gacOPdKuLv5RkqaD97Zbpgv5dbRKjEEI0lKIoVBw+TEHUcsq2bwdFASzrlo2zZ+EyZgxqe1lbKn6bJFtC/A4HrQOT207mzrA72ZK2hSXHl5BYkMiaU2tYe3otI4JHMLfjXNoa29o61CbJLiiIFu+9S2XcbLLfmk/l0aPkL15M0Zdf4vnIPNzvuguVzjZJQbNk7wx951lKoCd8DfsWYshO4F7tRmZrf+K7ir78b+MYFm4LYXLPQOb0D6aF+/WZ+ppTWsWne86yYv95qkwmblEf5WnDD4TXJVuSLLUWOk+B/o+Dl0yxEUI0bUpNDSWbNpG/bBnVJxOtxw0DB+AxezaOffs22enbommRZEuIBtCoNYwKHsXIliM5mHWQJceXsD9zPxvPbmTj2Y308+/H3I5z6eXbS158r0AfEUHLlSso27aNnPkLqDl/nux/vUrh8hV4P/M0TsOGye/tz9DoIGIydJ4Eqdtg70K0Z3dxhyaaOzTR7KrrzOJ9Yxi0ryO3dvTjvgEhRAS6NUooWcVVfLwrlTWH0qirrWGsej9PGH6kZV2aJcnS6qHbTOj3qGWPMSGEaMJqCwsp+mIthatWUZubC4DK3h7X8eMxzpyBfevWNo5QNDeSbAnxJ6hUKvr49aGPXx8S8xNZmrCUzec3s+/iPvZd3EcHjw7M6TiH4UHD0ail7PmvqVQqnIcPx2nQIArXriXvvx9Sc+4cGY88ir57d3yeexZ9RIStw2xeVCpoM9zyczHWUsHwxDcM0sQzSBPPcXMw/0sYwx3xveke7MW9A1oxvJ3PNdkkOaOwgo93pbL2cAaquiru0uziMccf8TbnWJIse1fodS/0fgicvP7y8wkhRGOqPnOWguVRFH+7HqWqCgCtlxfu06fhNnkyWndZq90U5FXm4Wrnik7TfGbFSLIlxFVq59GOtwa9xWOljxF1IopvU77lRP4Jntn1DIHOgczuMJvbW9+Og9bB1qE2KSqdDuP06biOG0f+J59SsGwZlUePcm7yFJxvHYX3U09hFygjIH+afxe4cwmqYS/C/v/CsRV0qj3HIrsPeE75gk/TR/P4ikH4enowN7IVd3Zrgd7uz38hcD6/nA93pLLuWAYO5nLmarbyoONm3MyFYAYMXtDnYeh5Dzi4XvPbFEKIa0VRFCr27yc/KoryXbutx+3bt8Nj1ixcbr0VlZ2dDSO8udWZ60gpSiE2J5bY3Fhic2LJKMtgycgl9PTtaevwGkySLSH+ohbOLfh/ff4fD3V5iDWn1rDm1BrSS9N59cCr/Df2v0xvN53J4ZNxtZcPnr+mcXLC+8kncJ86hdz3F1L87beUbtxE6dZtGKdNxePBB+WbxKvhHgyj58PgF+Dwp3DwYwIrcnlFF8WTunVEFY3g3W9H8M5PHtzdpyUz+wbj5fzHi7uzK+G5dcf5Lj4LV3Mxj2s3Mdd+Cwal3JJkuQZa1mN1vRt0snmnEKLpMldXU/LDjxRERVGdlGQ5qFLhNGQIxlmzcOzVU6a220BpTSnHc49bE6v4vHjKTeX12qhQcbb4bLNKtlSKcqmsivhdJSUluLq6UlxcjIuLi63DqcdkMrFhwwZGjx6NTooN2FyFqYJvUr4h6kQUmeWW/TcctY7cGXYnM9rPwNfga+MIf9GU+k7VqVPkzF9A+d69AKidnfF88AHc775bKj39FaZKiF0N+xZB4VkAqrFjbe1APq0bTaban/Fd/bl3QAhhPs6XPTwpu5T3tyax4XgmvhRwv/YHpul2Yq9UWxp4hkHkU9DpTstaMiF+pSm9xoim63r1k9r8fArXfE7hmjXU5ecDoHJ0xG3CBIwz7sYuOLjRnlvUpygK6aXp1sQqNjeWlMIUFOqnJQadgc6eneni3YUuXl3o5NUJZ7tf3qts+RrT0NxARraEuMYcdY5MbzedSeGT2HR2E0tPLCW5MJnlJ5ezOnE1o0NGM6fDHNq4t7F1qE2KQ9u2BH32KWXRe8mZP5/q06fJmb+AwlWr8XryCVxuuw2VumnsIdWs6PSWKX3dZ0Pi97D3fewvHmOGdivTtdvYWNeT/x0dw4gjGQwK8+K+ASH0b+PBycwSPtiewsaELFqpMnlD+z0TtdFoqQUFS9n2AU9D+G0g/y5CiCasKimJgqgoSr7/AaWmBgCtry/Gu6fjdtddaFxl5kljq6qt4mT+SWtyFZcbR0FVwWXtWji1sCZWXby70MatTbNfAy/JlhCNRKfWMbb1WMaEjCH6QjRLTyzlcNZhvkv9ju9Sv2NQi0HM7TiXrt5dZbrCrzhF9sfQtw/F678j9/33MV28yMVnn6NgWRTezz6LoU9vW4fYPKk10GE8tB8H5/fC3oWokzdzm+YQt2kOccDcjsUpY5iRFIG/m4ELRZV0UJ3jA916RmsOof7528bgATDgKQgZIhsRCyGaLMVspjw6moJlUZTv22c97tCpk2V/rBEjZOuRRpRTkWMdsYrLieNkwUlqzbX12ujUOjp4dLAmVxHeEXjqb7yNoSXZEqKRqVQqBrQYwIAWA4jPjWdpwlK2pW1jV8YudmXsIsIrgrkd5zI4cDBqlYwQAKg0GtzumIDLraMoiFpO/iefUHXiBGmzZ+M0eDDezzyNfRsZGbwqKhUER1p+chIt0wvj19KHRPrYJZKstGB16RAG2cUzWB1nfVima1e8JryONrivDYMXQojfZ66spHj9dxQsX07NmTOWg2o1zsOHY5w9C31X+YLzWqs115JUmFQvubpYfvGydh4OHnT17koX7y5EeEXQ3qM9dpobvwCJJFtCXEedvTrz7pB3OVd8jmUnlvFd6nfE5cbx+I7HaeXaijkd5nBbyG03xYtPQ6j1ejwffAC3u+4k77//pfCLtZTt3EnZ7t243Xknno/MQ+ftbeswmy/vdjD+Qxj6DzjwERxZSmhNBi/pVljOq9TQcSKmPo9y6Mg5Rgf0sG28QgjxG0w5ORSuXk3R519QV1QEgNpgwO3OO3GfcTd2LVrYNsAbSHF1MXG5cdbpgMfzjlNZW1mvjVqlJsw9jAivCOvIVYBTwE2Z6EqyJYQNBLsG83K/l5nXZR6rElfxxekvOFt8lhf3vcgHMR9wd/u7uSvsLpzsnGwdapOg9fDA98UXcb97BrnvvkPplq0UrV1L8Q8/4DF3Lh5zZqM2GGwdZvPl4g8jXoWBz8DRZZa1XT4dof9jYAwBkwk4Z+MghRDiclWJiRQsi6J4w4ZLr1WgCwjAfcbduN15JxoneR/9KxRF4VzJOWtiFZsTS2px6mXtnHXOdPbubF1r1cmzEwadvC+DJFtC2JSXoxdPdH+Cezvdy1dJX7Hi5ApyKnN45+g7fBL/CZPCJzG93XS8HGVTWAD7kFa0WLSIiqNHyX7rLari4sn74AMKv/gcr0cfxe2OO1Bp5WXtqjm4Wsq393/c1pEIIcRvUsxmynbupGBZFBWHDlmP67t1wzhrFs7Dhsp7wVWqrK0kIS/BmljF5sZSXF18Wbtgl+B6o1YhbiGyFOI3SE8UoglwsnNidsfZTGs3jR/P/MjSE0s5W3yWzxI+Y/nJ5dze+nZmd5hNsGuwrUNtEhy7dyf4888p3bSJnHfexZSeTtaLL1GwfDnezzyD06BBN+VUBSGEuJGZy8sp+vZbCpYvx3Q+zXJQo8Fl5EjLeqzOnW0bYDOUVZ5Vb9Pg0wWnqVXqF7Kw19hfVsjC6GC0UcTNjyRbQjQhdho7JoROYFybcexM38mShCXE5caxLnkdXyd/zbCgYcztOJdOXp1sHarNqVQqXG69Fadhwyhas4a8Dz+iJiWVjAcfwrF3b7yfexZ9hw62DlMIIcRfZMrMpHDVKgrXfom5pASw7MXoPnkS7tOno/Pzs3GEzYPJbOJ0wel6yVV2RfZl7bz13pbE6lJy1dbYFp3so3jVJNkSoglSq9QMDRrK0KChHMs+xtKEpezM2MnWtK1sTdtKD58ezO04l8iAyJt+BEdtZ4dx1ixcx48n73//o3DFSioOHuTcxDtxGTsW7yceRxcQYOswhRBC/EmV8fEULIuiZPNmqKsDQNcyCOOMmbhNGC9rdf9AYVVhvemAJ/JOUFVXVa+NRqUh3BhuXWvVxasLvgbfm/6zxbUkyZYQTVw3n2508+lGSmEKS08sZcOZDRzJPsKR7COEuocyp8McRrUahU59c3/rpHF1xefZZzFOm0bOe+9T8v33lHz/PaWbN+M+4248H3gAze/s8C6EEML2lLo6SrduoyAqispjx6zHHXv1wjh7lmWauKZ5b3LbGMyKmbPFZ4nJibEWszhXcu6ydi52LvU2De7g0QFHneP1D/gmIsmWEM1EG/c2vBb5Go92fZQVJ1fwVdJXJBcm8/fov7MoZhEz28/kjtA7bvoXTV1AAAHz38I4axY58+dTcfAgBZ8tofirdXg+/BDuU6eispPS+kII0ZSoq6ooWrGC4lWrMV24YDmo0+E6+laMs2bh0L69bQNsYipMFRzPO/7L3la5cZTWlF7WLsQ1pN5aq2CXYClkcZ1JsiVEM+Nr8OXZns9yf+f7WXt6LSsTV5JZnsmbh9/k4/iPmRI+hWntpt30i1f1HTsQtGwpZbt2kbNgATUpqWS//gYFK1fh/fRTOI8cKdMkhBDCxmoyLpAXFUWrtWvJq64GLDMV3KZMwX3aNHQ+speioihcLL9oSawujVqdLjyNWTHXa6fX6unk2claJTDCKwJXe1cbRS1+JsmWEM2Uq70r93W+jxntZ/Bd6ncsO7GM9NJ0FscvJupEFOPbjGdmh5kEOgfaOlSbUalUOA8ejFNkJEVff03uwkWY0tO58MST6CMi8P7bczh262brMIUQ4qaiKAqVMbEULFtG6datYDajAXStWuExaxau425HrdfbOkybqamrIbEgsd7eVrmVuZe18zP4WUesunh3Idw9HK1aPto3NU3+X6S0tJR//vOffPPNN+Tk5NC1a1fef/99evbsCcDs2bOJioqq95iRI0eyadMm698LCgp49NFH+f7771Gr1UycOJH3338fJ9noTtwAHLQOTAqfxMTQiWxN28qShCWczD/J56c/Z23SWka2HMmcjnNo59HO1qHajEqrxX3SJFxvu438JUvJX7KEyrg4zk+bjvMtw/F66insW7WydZhCCHHDK9u7l9yFC6mKi7ce0/ftS3Lbtgx64nHs7O1tGJ1t5FXmEZcbR1xOnLWQRY25pl4brUpLO4929UatfA2+NopY/BlNPtm69957SUhIYMWKFfj7+7Ny5UqGDx/OyZMnCbhUYWzUqFEsXbrU+hj7//Mfdfr06WRmZrJlyxZMJhNz5szh/vvvZ/Xq1df1XoRoTBq1hpHBIxnRcgSHsg6xNGEpey/uZeO5jWw8t5G+fn2Z3XE2PX173rTFNNQGA16PPoLb5EnkLfqAonXrKN2yldIdO3GfNAnPR+ahNd7c0y+FEKIxVJ85Q86bb1G2axcAKp0Ol9vHYpw5C01IK+I2bEClvvHXEtWZ60gpSqlXJTC9NP2ydu727pYRq18VsnDQOtggYvFXNelkq7KyknXr1rF+/XoGDhwIwMsvv8z333/PRx99xL///W/Aklz5+l45u09MTGTTpk0cPnyYHj16ALBo0SJGjx7NggUL8Pf3vz43I8R1olKp6O3Xm95+vTlVcIqlCUvZfG4z+zP3sz9zP1q1lhDXEMLcwwhxCaHIVESPih74u/jfNGuYdN7e+L36L4wzZ5Cz4G3Kdu2icPVqitevx+O++zDOmnlTT2ERQohrpbawkLz/fkjh559DbS1otbhPm4rn/fej9fQEwGQy2TjKxlNWU0Z8Xrx1vVV8XjzlpvJ6bVSoaO3Wul6VwCDnoJvmPflG16STrdraWurq6nBwqJ/J6/V6oqOjrX/fuXMn3t7euLu7M3ToUP7973/j4eEBwP79+3Fzc7MmWgDDhw9HrVZz8OBBJkyYcMXnrq6upvrSQk2Akkub6JlMpib3ovBzPE0tLmF7rZ1b8+++/+ahTg+x8tRKfjz7I2WmMpIKk0gqTLK2W/7tclztXGnj1oZQt1BC3UJp49aGNm5t0Gtv3KRDHRyM7weLqDh0iPwFb1OdmEjue+9RsHo1Ho8+ivPYMVJiGHmNEVdP+s7NSzGZKP7iCwo++ti6EbHjoIF4Pv00dq1aoXB5/2ju/URRFDLKMojLiyM+N564vDhSilJQUOq1c9Q60smzE509OxPhGUEnz0442znXa1NbW3s9Q2+2bNl3GvqcKkVRlD9uZjv9+vXDzs6O1atX4+Pjw5o1a5g1axZt2rTh9OnTfP755zg6OtKqVStSU1P5+9//jpOTE/v370ej0fCf//yHqKgoTp8+Xe+63t7evPLKKzz00ENXfN6XX36ZV1555bLjq1evxtHx5i6tLZovRVEoUorIrssmqy7L+me+OR8z5svaq1DhrnbHV+OLj9rH8qfGB6PaeOOVjjWbcY6Lw3PTZnRFRQBU+fmRN/pWKsLCbBubEEI0F4qC4dQpvH74Ebu8PACqfX3IHTOGitBQGwd3bZkUExfrLpJWm0ZaXRpptWmUK+WXtXNXuxOkCSJIa/nxUfvceO+hN6GKigqmTZtGcXExLr+zj2eTT7ZSU1OZO3cuu3fvRqPR0K1bN8LCwjh69CiJiYmXtT9z5gytW7dm69atDBs27KqTrSuNbAUGBpKXl/e7v1BbMJlMbNmyhVtuuQWd7uZciyOuzs99Z+DQgWRUZJBSlEJyUTLJRcmkFKWQV5V3xcc5aBxo7draOhL285/uDu7X+Q6uPXN1NcWrV1P4yaeYSy17luj79cPzqaewD785ky55jRFXS/rOzaU6KYm8+QuoPHAAAI3RHeO8R3C5YwIq7W9Ppmou/SS3Mtc6YhWXG0diYSK15vojUDq1jnbGdkR4RtDZqzOdPTvjpfeyUcQ3Plv2nZKSEjw9Pf8w2WrS0wgBWrduza5duygvL6ekpAQ/Pz8mT55MSEjIFduHhITg6elJSkoKw4YNw9fXl5ycnHptamtrKSgo+M11XmBZB/Z/C20A6HS6JvtC0JRjE02bk4MTnZw70cmnU73jBVUFJBcmk1SYZP0zpSiFqroqThSc4ETBiXrtvfRehLqHEuYeZv0zxDUEO00z2kRYp8P7/vsx3nUX+R9/TMHqNVTu20f6/v24jh+P1+OPofud144bmbzGiKslfefGVpufT+77Cyn66iswm1HpdBhnzcTjgQfQODv/8QUuaUr9pNZcS3JhMrG5v+xtdaHswmXtPBw86q21aufRDnvNzVdR0dZs0Xca+nxNPtn6mcFgwGAwUFhYyObNm3nrrbeu2C4jI4P8/Hz8/PwA6Nu3L0VFRRw9epTu3bsDsH37dsxmM717975u8QvRHBkdjNZiGz+rM9eRXppuScCKkkkqsPyZXppObmUuuZW57Lu4z9peo9IQ7BJcLwELcw/D1+DbpBf/at3d8XnhBdynTyfn3Xcp3biJ4m++oWTjRoyzZuFx371oZPsIIcRNzFxTQ+Hy5eR99DHmcsv0OeeRI/F+5mnsApvXHo/F1cXE58YTmxtLXE4c8XnxVNZW1mujVqkJdQu1ll7v4t2FFk4tmvR7mbC9Jp9sbd68GUVRCA8PJyUlhWeffZa2bdsyZ84cysrKeOWVV5g4cSK+vr6kpqby3HPP0aZNG0aOHAlAu3btGDVqFPfddx8ff/wxJpOJRx55hClTpkglQiGugkatIdg1mGDXYEYwwnq8wlRhmYL4f0bCSmpKSC1OJbU4lY3nNlrbO+ucCXUPrTcSFuoWipNd00pg7IKCaPHuu1TOnk32W/OpPHqU/MWLKfrySzznPYz7pEmomsg3sUIIcT0oikLp5p/IWbAAU0YGAA7t2+PzwvM4XtoHtSlTFIVzJefqbRqcWpx6WTsnnRMRXhHWEuydPDs1ufco0fQ1+WSruLiYF154gYyMDIxGIxMnTuS1115Dp9NRW1tLfHw8UVFRFBUV4e/vz4gRI3j11VfrTQFctWoVjzzyCMOGDbNuarxw4UIb3pUQNx5HnaPlTckrwnpMURRyKnKs1Q+TiywJ2Nnis5SaSjmWc4xjOcfqXSfAKcBSEfFXo2BBLkFo1bZ9udJHRNBy5QrKtm0jZ/4Cas6fJ/vVf1O4YiXezzyN07Bh8u2mEOKGV5lwguw3XqfyyFEAtF5eeD31FK7jbm+y+2RV1lZyIu9EvSmBRdVFl7Vr6dLSOmLVxasLIa4haNRSkVb8NU0+2Zo0aRKTJk264jm9Xs/mzZv/8BpGo1E2MBbCBlQqFT4GH3wMPgxoMcB63FRn4mzJ2XojYMmFyWRXZHOh7AIXyi6wM2Ontb2d2o7Wbq0vWw/mqfe87vfjPHw4ToMGUbh2LXn//ZCac+fIeORR9N274/Pcs+gjIv74QkII0cyYsnPIffdditevB0VBZW+Pxz1z8bjnHtQGg63DqyerPMs6HTA2J5ZTBaeoVeoXsrBT29HRs6M1sers1RkPvYeNIhY3siafbAkhbjw6jc46avVrxdXF1uTr55Gw5MJkKmsrSSxIJLGgfgVSo4PROv3w5+u1dmuNg7b+3nzXmkqnwzh9Oq7jxpH/yacULFtG5dGjnJs8BedbR+H91FPNbr2CEEJcibmykvwlS8j/9DOUSssaJpexY/F+6kl0l9bH25LJbCKpIMk6ahWbG0tWedZl7bz0XvULWRjbodPIFHDR+CTZEkI0Ga72rvTw7UEP3182ITcrZi6UXbhsFCytNI2CqgIOZh7kYOZBa3u1Sk2Qc9Blo2ABTgHXfF8TjZMT3k8+gfvUKeS+v5Dib7+ldOMmSrduwzhtKh4PPojWvfmXwxdC3HwUs5mSH38k5+13qM2yJC/6Ll3weeF5m47gF1UVWdZZXUquEvISqKqrqtdGo9IQ5h5WL7nyM/jJVG9hE5JsCSGaNLVKTaBzIIHOgQwLGmY9XllbyZmiM/XXgxUkUVhdyLmSc5wrOceW81us7R21jrRxb2NJwNx+ScRc7V3/cow6X1/8X/8PxlkzyZm/gPK9eymIWk7R19/g+eADuN99N+orbCUhhBBNUUVMDNmvv0FVfDwAWn8/vJ9+GpfRo69rwmJWzJwtPmsdsYrNieVcybnL2jnbOVuTqi5eXejo2RFHneN1i1OI3yPJlhCiWdJr9XTw7EAHzw7WY4qikF+Vf9koWGpRKhW1FcTnxhOfG1/vOj6OPvWKcYS6h9LKpdVVTS9xaNuWoM8+pSx6Lznz51N9+jQ58xdQuGo1Xk8+gctttzXZBeRCCGG6cIGct9+hZMMGAFSOjnjefz/G2bNQOzTu9GywVLU9lXfKmlzF5cZRWlN6WbtWrq3qJVfBrsHXfOaCENeKJFtCiBuGSqXCU++Jp96Tfv79rMdrzbWklaT9MgpWmExyUTIXyi6QXZFNdkU20Reire21ai2tXFv9koBdGgnzdvRu0Le6TpH9MfTtQ/H678h9/31MFy9y8dnnKFgWhfezz2LoI3v8CSGajrqycvI/+YSCZctQqqtBpcL1jgl4Pf44Om/vRnlORVHILM8kNieWY9nH2F26mxe/ehGzYq7XzkHjYC1k0dW7K509O+Pm4NYoMQnRGCTZEkLc8LRqLSFuIYS4hTCq1Sjr8dKaUlKKUi7bG6zMVGZJyAqT+ZEfre1d7Fwu25y5jVubK05XUWk0uN0xAZdbR1EQtZz8Tz6h6sQJ0mbPxmnQILyffQb7Nm2uy/0LIcSVKHV1FH/7LTnvvUddbh4Ajr164fP833Bo3/6aP19BVQG70ncRfSGa2JxYcipzLmvja/CtN2oVZgxDp5ZCFqL5kmRLCHHTcrZzpqt3V7p6d7Ue+/nb1v+bgJ0rOUdJTQlHso9wJPtIvesEOgdaRr+Mv4yEBToHolFrUOv1eD74AG533Unefz+k8IsvKNu1i7I9e3C78048H5nXaN8cCyHEbyk/eIjsN96gOtFS5VUXFITPc89e8z0D00rS2JG+g+1p24nNja03cqVVaWlrbEsnz06Y083MumUWgW5SyVXcWCTZEkKIX1GpVPg7+ePv5M+gwEHW4zV1NZwpPnPZerDcylzSS9NJL01ne/p2a3sHjQOt3VrXGwkLfW4eIXffTe6771C6ZStFa9dS/MMPeMyZg8fcOU1urxohxI2n5vx5sufPp2zrNgDUzs54PvQQ7ndPR21n95evb1bMnMg7YU2wUotT651vZ2zH4MDB9PLtRQfPDui1ekwmExuyN+Br8P3Lzy9EUyPJlhBCNICdxo62xra0Nbatd7ywqrD+3mCFyaQUpVBVV8WJ/BOcyD9Rr72n3pOw28Po1fs2un4Zj/50Onn//S+Fa7/A69FHcbvjDlRaeWkWQlxbdSUl5H30MQUrV4LJBGo1bpMn4fXoo2iNxr907Zq6Gg5lHWJH2g52pO8gtzLXek6j0tDDtwdDAocwJHAI/k7+f/VWhGhW5B1dCCH+AncHd3r59aKXXy/rsTpzHRllGfVGwZIKk8gozSCvMo+8yjz2AUxQ6HtKzbSdZnxy88h68SVS/7eQmgcn03LkHfg7+cu+MEKIv0SpraXoyy/JXbiIusJCAAz9++Pz/N+wDw296uuW1JSwJ2MP29O2s/fiXspN5dZzjlpHIgMiGRI0hAEBA67JFhtCNFeSbAkhxDWmUWto6dKSli4tuaXlLdbjFaaK+gU5ipI56ZDEk6FFjDimMHGvGeeMfAz/+JB9n3zEVyMM2Ldv90tFRKOlIIeznbMN704I0VyU7Ykm5603qU5OAcAuJASfvz2HYeDAq/oiJ7Msk+3p29mRvoOjWUepVWqt57z0XgwOHMyQwCH09uuNneavT0kU4kYgyZYQQlwnjjpHOnt1prNXZ+sxRVHIqcgheVQyiRnxOK7eSPi2VDqeV+j4SRl7OhxhzaBjfOH6ywcjf4N//bVg7qG0dGmJVi0v6UIIqE5NJfvNNynfvQcAjasrno8+ivvkSah0Da/spygKSYVJbE+zJFiJBYn1zrd2bc2QoCEMDRxKB88OsteVEFcg78xCCGFDKpUKH4MPPgYfIgMioffDmC5cIOvddyn74UcGnFDolwSxg/xY27uOs+YcLpZf5GL5RXZm7LRex05tR4hbSP29wYxheDh4yFREIW4StYWF5H3wXwo//xzq6kCrxTh9Op4PP4TGtWFT+UxmE8eyj7EjfQc70nZwsfyi9ZwKFV29u1rWXwUNoaVLy8a6FSFuGJJsCSFEE6MLCCBwwQIqZ88hZ/58Kg4epPvWdHoddsVw/yNkjexCUtkvlRGTC5OpqK3gVMEpThWcqnctd3v3y/YGC3ELQa/V2+juhBDXmlJTQ8Hq1eR9+BHmkhIAnIYOtezn16rVHz6+wlRB9IVodqTvYHfGbkpqSqznHDQO9PHvw9DAoQwKHITR4a8V0xDiZiPJlhBCNFH6jh0IWraUsl27yFmwgJqUVErmv4fr54Hc9tSTTBn1IiqVCrNi5mLZxXoVEZMKk0grTaOwupCDWQc5mHXQel0VKlq6tCTUPfSXJMwtjADnAJkGJEQzoigKZTt2kPPmW9ScPw+AfXg4Ps//DUPfvr/72LzKPOvo1cHMg9SYa6zn3O3dGdhiIEODhtLXv698OSPEXyDJlhBCNGEqlQrnwYNxioyk6OuvyV20CFN6OheefAqHZcvwee45HLt3p4VzC1o4t2Bo0FDrY6tqq0gtTr2sNH1BVQHnSs5xruQcW85vsbbXa/WEulkSsE6eneji3YVWrn/8rbgQ4vqrOn2a7NffoOLAAQA0Hh54Pf4YbhMnotJorviYM8VnrOuv4nPj650LdA5kaOBQhgQNoYtXFzTqK19DCPHnSLIlhBDNgEqrxX3SJFxvu438pcvI/+wzquLiOT/9bpxvGY7XU09dNl3IQetAB48OdPDoUO94XmVevY2ZkwqTSC1KpbK2kvi8eOLz4lmXvA4AFzsXOnt2xqHKAZ9sHyJ8I+RbbiFsqDYvj9z3F1K0bh2Yzajs7DDOmoXHA/ejcXKq17bOXEd8Xrx1/6tzJefqne/k2cm6/1Vrt9ayvlOIRiDJlhBCNCNqgwGvR+bhNuku8hZ9QNG6dZRu2Urp9h24T56E57x5aD08fvcannpPPPWe9PX/ZZpRrbmWtNI0kgqTOF1wmrjcOI7nHqekpoToi9EAbN22Fa1KS1tjW7p4d6GLdxe6enfF29G7Ue9ZCAHm6moKopaTv3gx5nLLnlbOo0bh/czT2LVoYW1XVVvFgcwD7Ejfwc70nRRUFVjPadVaevv1ZmjgUAYHDpb/u0JcB5JsCSFEM6Tz9sbv1X9hnDmDnAVvU7ZrF4Wr11C8/js87rsP46yZqPUNH4HSqrWEuIYQ4hrCqOBRgKUqWVJBEkcyj7Dp+CZytDnkVOaQkJ9AQn4CKxNXAhDgFECEVwRdvbvSxbsLoW6hMgVJiGtEURRKN28mZ/4CTBcuAODQsSM+LzyPY/fuABRVFbErYxc70new7+I+KmsrrY931jkzoMUAhgQNIdI/Eic7pys+jxCicUiyJYQQzZh9aCiBiz+m/MBBct56i6qTJ8l97z0K16zB6/HHcR13+2+u3/gjOrWODp4dCHMNw+2MG7feeiv5NfnE5MQQkxNDXG4cpwtPc6HsAhfKLrDh7AYADDoDnT07W0e/IrwiMOgM1/K2hbgpVB5PIPuNN6g8ehQArbc3Xk89ievtt5NRfoGvTixnR/oOjuUcw6yYrY/zNfhapwf28O2BTt3wvbWEENeWJFtCCHEDMPTpTfBXX1Ly44/kvPsutRczyfz73ymIisL72Wdxiuz/l59DpVLh5+SHn5Mfo0NGA1BuKic+N57Y3Fhic2KJy42j3FTO/sz97M/cD4BapSbULdQ67bCLdxf8Df6yPkSI32DKzib3nXcpXr8eAJWDA8Z75pI7vh8r8vax/fuJpBSl1HtMuHu4dYPhtsa28v9LiCZCki0hhLhBqNRqXMeOxXnECApXriTv48VUnz5N+r33YujfH+/nnsUhPPyaPqdBZ6Cvf1/r+q86cx0pRSnE5sQSmxtLTE4MF8oucLrwNKcLT/PF6S8A8NZ711v3FW4Ml2/fxU3PXFlJ/mdLyP/sM5RKy1TA6uF92Dbajw3l35Kz/X/WthqVhu4+3a0bDAc4BdgqbCHE75BkSwghbjBqe3s87rkH1zvuIP/jjylYvYbyvXs5O34fruPH4/X4Y+h8fRvluTVqDeHGcMKN4UxuOxmA3Ipca+IVlxPHyYKT5FTm8NP5n/jp/E+AZePUjp4drSNfEV4RuNq7NkqMQjQ1itlMyfffk/POu9RmZwOQ3dqd/w02cdz7CORa2um1eiIDIhkSOISBLQbK/xEhmgFJtoQQ4galdXfH54UXcJ8+nZx336V04yaKv/mGko0bLaWi77v3slLRjcHL0YtbWt7CLS1vASzV0hLyEqxTD2NzYymuLuZI9hGOZB+xPi7ENcSafHXx6kJLl5YyNUrccCqOHSPjtVepO3EKgFxXWDlEzf62JaBS4eHgweDAwQwNGkpvv97Ya+xtHLEQ4s+QZEsIIW5wdkFBtHj3XSpnzyb7rflUHj1K/uLFFH35JZ7zHsZ90iRUuus3hc9B60AP3x708O0BWKqtnS05a0m8ciwjYOdKznGm+Axnis9Y9/wyOhiJ8IqwTj1s79FePniKZklRFJISo8maPx/v/ckAVNrBN33V/NhLRQuPEO65tMFwJ89OqFVqG0cshLhakmwJIcRNQh8RQcuVKyjbto2cBW9Tc+4c2a/+m8IVK/F+5mmchg2zyciRSqWylp2/I/QOAAqrConLjSMmJ4bYnFhO5J+goKqAHemWzVnBUi2xvUd7y+iXVxcivCPw1Hte9/iFaIhacy0xOTHsOr0Zu9XfMyi6BO86MAM7IlScuCOCXh1G8HXgEIJdg20drhDiGpFkSwghbiIqlQrn4cNxGjSIwi+/JO+D/1Jz7hwZjzyKvnt3fJ57Fn1EhK3DxN3BncGBgxkcOBgAU52JkwUn641+5VflE5cbR1xunPVxQc5B1sIbXby60NqttYwKCJupMFWw7+I+dqTvYHfaTrodLmLKbjNulj2JyQhzp2beNKYMnCJfFAhxg5JkSwghbkIqnQ7jtGm43n47+Z98SsGyZVQePcq5yVNwvnUUxhkz0HfujErbNN4mdBodEV4RRHhFMKvDLBRFIaMsw5p4xebGklKYQlppGmmlaXyX+h0AznbOlqmHXpaphx09O+Koc7Tx3YgbWV5lHrvSLRsMH8g8QHVdNR3Om/n7VjPBOZY2tf5e+P3tedqOuFXWIQpxg2sa76JCCCFsQuPkhPeTT+A+dQq57y+k+NtvKd24idKNm1A7O2Po1w99v75oq6ptHWo9KpWKQOdAAp0DGdt6LAAlNSUczz1unXoYnxdPaU0p0Reiib4QDVjKZYcbw61TD7t4d8HX0DiVGcXN42zxWcsU17QdxOXGoaAA4FugcN9uOzolWsq4q52d8Xz4YYzTp6Gys7NlyEKI60SSLSGEEOh8ffF//T8YZ80k/9PPKN+zh7riYko3b6Z082ZCgLQv1+I0YCBOAyLR9+iBuol9WHSxc6F/QH/6B1g2cK4115JUmGQtOR+TG0NWeRYn809yMv8kqxJXAeBn8LMmXl28uxDmHoZWLW+P4reZFTPxufHWNYRni8/WO99dH870g3a02HwcaitBo8F98mQ8H30Erbu7jaIWQtiCvJsIIYSwcmjbloAF81Hq6qhKSKBsTzSlu3dTdfw4NSmpFKSkUrB0KSq9HkOvXhgGDMBpQCR2LVvaOvTLaNVa2nu0p71He6a3mw5AVnlWvamHpwtOk1meSWZ5JhvPbQTAUetIJ69O1qmHnb0642znbMtbEU1AdV01BzMPsj1tO7sydpFXmWc9p1Vr6eXbiyH+g+hzqJiad5ZTV1QEgGHAAHz+9hz2bdrYKHIhhC1JsiWEEOIyKo0GfUQE+ogI3B64n01ffkl/Z2eq9h+gfM8eanNzKdu1i7Jdu8gGdEFBOEVGYhgQiaFXL9QGg61v4Yp8Db6MajWKUa1GAZYCBsfzjlsSsNwY4nPiKTWVcjDzIAczDwKgQkUb9zZ09epqHf1q4dRC1trcBIqri9mdsZsd6TuIvhBNZW2l9ZyTzokBAQMYGjSU/gH9UR2MJfu5N6lMTQXArnVrfJ7/G04DBtgqfCFEEyDJlhBCiD9kNhhwHjUK49ixKIpCdVIS5Xv2ULYnmopjxzClpVG4ejWFq1ej0unQ9+iOU+QADAMisQ8NbbKJiaPOkd5+vent1xuwTA9LLUq1TD28VHo+vTSd5MJkkguTWZu0FgBPvad16mFX7660M7ZDp7l+e5WJxnOh7AI70nawPX07x7KPUafUWc95O3ozJHAIQ4OG0tOnJzqNjuqUFLLnPU35nj0AaNzc8Hz0EdwnT24yBWaEELYjrwJCCCH+FJVKhUN4OA7h4Xjcey91ZeVUHDpI2Z49lO/eg+nCBSr2H6Bi/wGYPx+tjw+GAZGWka++fdG4utr6Fn6TWqUm1D2UUPdQJoVPAizV5eJy4qxTD0/knyCvMo+taVvZmrYVAHuNPR08OlgKb1wqO+/m4GbDOxENpSgKiQWJ7Ejfwfa07SQVJtU7H+oeak2w2hvbW784qC0sJGvRBxR+8QXU1YFOh3H6dDwferBJ93EhxPUlyZYQQoi/RONkwHnoUJyHDkVRFGrOnaN8TzRl0XuoOHSY2uxsir9aR/FX60CtRh8RYUm+BgzAoUMHVOqmvQ+Wp96TYS2HMazlMMCydudE3glic2OtxTcKqws5lnOMYznHrI8Ldgmmq3dXunp3JcI7glYurZrsCN/NxmQ2cSTriLXARVZ5lvWcWqWmu093hgQOYXDgYAKdA+s9VqmpoWDVavI+/BBzaSkATsOH4fPMM9gFB1/P2xBCNAOSbAkhhLhmVCoV9q1aYd+qFcaZMzBXVVFx5Cjl0ZbkqyYllcqYGCpjYshbuAiNuzuG/v1xGhCJoX9/tJ5Nf2NXe4093Xy60c2nG2AZGTlfcr7e1MMzxWc4V3KOcyXn+CblGwDc7N3o4tWFCO8Iunp3pYNHBxy0Dra8lZtKWU0Z0Rej2Z62neiMaEpNpdZzeq2e/v79GRI0hIEBA684KqkoCmXbtpE9fz6m82kA2Ldti8/zz2Po0/t63YYQopmRZEsIIUSjUTs44BTZH6fI/vjwN0wXL1IWHU35nmjK9++nrrCQkh9+oOSHHwBwaN/eUuEwsj/6Ll1Q6Zr+OiiVSkWwazDBrsFMCJ0AQFFVEfF58dY9vxLyEiiqLmJnxk52ZuwELlVLNLa3Ft3o6t0VT33TTzabk5yKHHam72R72nYOZh2k1lxrPWd0MDIkcAhDAofQ26/37ya+VYmJZL/xJhUHLUVTNJ6eeD/xOK4TJqDSaBr7NoQQzZgkW0IIIa4bnb8/7pMm4T5pEorJRGVcHGV7oinfs4eqkyetP/mLF6N2csLQtw+GSEt5eZ2/v63DbzA3BzcGthjIwBYDATDVmThVcMo69TA2J5bcylzi8+KJz4tn+cnlAAQ4Bfwy9dArgjZubdCo5cN8QymKQmpRKtvTt7MjbQcJ+Qn1zge7BDMkaAhDA4fSybPTH/5ua3NzyXn/fYrXfQ2KgsrODuPs2Xjcfz8ap6ZZcVMI0bRIsiWEEMImVDodjj164NijBzz5BLV5eZTv3WtJvqKjqSsqonTLVkq3WIpQ2LVufam8/AAce/ZAbW9v4ztoOJ1GRyevTnTy6sSM9jNQFIWL5RetiVdsTizJRclcKLvAhbIL/HDGMtLnpHMiwivCOvWwk2cnDDr5kP9rdeY6YnJirOuv0kvTredUqOjs1dkyghU0hBDXkAZd01xdTcGyKPIXL8ZcUQGAy+hb8XrqaexaBDTKfQghbkySbAkhhGgStJ6euI4bh+u4cZZNlU+etFQ43BNNZVwcNampFKSmUhAVhcrBAcdePa3l5e2Cg5tV8QmVSkWAUwABTgGMCRkDWNYUxefFW5Ov+Lx4ykxl7L24l70X9wKW4g3h7uHWioddvbvi5+Rny1uxicraSvZd3MeOtB3szthNYXWh9Zyd2o4+/n2sBS7+zNRMRVEo3biRnAVvY7p4EQCHTp3weeF5HLt1u+b3IYS48UmyJYQQoslRaTToO3VC36kTXg8/TF1xMeX7D1AWbUm+arOzKd9tKTUPoGvRwlrh0LFX72Y5xcvJzol+/v3o598PsIzYJBclWzZcvjQCdrH8IokFiSQWJLLm1BoAfBx9rGu+unh1IcwYhk7d9Ne6/VkFVQXsSt/F9vTtHLh4gKq6Kus5FzsXBrUYxJCgIfT374+jzvFPX78yPp7s19+gMiYGAK2PD95PP4XLmDFNvmKmEKLpkmRLCCFEk6dxdcVl1EhcRo20bKqcnGwtL1955CimjAyK1nxO0ZrPQafDsWtXa/JlHx7erEa9fqZRa2hrbEtbY1umtJ0CQHZ5NrG5sdbRr1MFp8iuyGbzuc1sPrcZsFTW6+TZiQgvy9TDzl6dcbVvnvs+nS85z440y/TA2NxYzIrZei7AKcC6/1VX765o1Vf3kcaUlUXOO+9Q8t33AKj0ejzuvQePuXNR6/XX5D6EEDcvSbaEEEI0KyqVCoewMBzCwvC4Zy7m8nLKDx26lHxFY0pLo+LQISoOHSL37XfQenlhiIy0lJfv1w+Nm5utb+Gq+Rh8GGkYycjgkYBlOl1CXsIvo1+5sZTWlHIo6xCHsg5ZH9fGrU29qYeBzoFNMgE1K2YS8hIs66/SdpBanFrvfDtjO2uBizD3sL90D+aKCvI//Yz8JUtQqiyjZK7jxuH11JPofHz+0n0IIcTPJNkSQgjRrKkNBpyHDMF5yBAAas6f/6W8/MGD1ObmUvzNNxR/841lU+VOnSzl5QdE4tCxY7Mu3a3X6unp25Oevj0BS7JytvjsL4U3cmM5X3KelKIUUopS+CrpK8BS9vznxKuLdxfae7THTmNnk3uoqavhYOZBdqTvYGf6TnIrc63ntCotPXx7MDRoKEMCh+Br8P3Lz6eYzRR/9x2577xLbU4OAPpu3fB54Xn0nTr95esLIcSvSbIlhBDihmLXsiXGli0xTp+OuaaGyqNHreXlq5OTqYyLozIujrwPPkDj6oqhf38MkZEYIvuj8/a2dfh/iVqlprVba1q7tebOsDsBy1qnn6cdxuZa9vwqqCpge/p2tqdvByxFJTp4dqCLVxfrvl9GB2OjxVlcXcyeC3vYkbaD6AvRVNRWWM8ZdAYGBAxgSOAQIltE4mLncs2et+LoUbJff4OqBEtJeF1AAN7PPoPzyJFNcqRPCNH8SbIlhBDihqW2s8PQty+Gvn3huWcxZWVRHh1tSb727aOuuJiSDRso2bABAPu2bS3TDSMH4Ni1Cyo724z2XEtGByNDg4YyNGgoYBlJOpl/st7Uw4KqAmJyYojJiYETlse1dGlpTb66enellWsr1KqrLxSRWZZp2f8qfQdHs45Sq/yywbC33pshQZYNhnv69rzmo2w1GRnkLHib0k2bAMtoqMcDD2CcNbNZbSEghGh+JNkSQghx09D5+uJ255243XknSm0tlfHx1vLyVQkJVJ86RfWpU+R/8ilqR0cc+/a1Jl83yv5Kdho76+jVbGajKArppenWxCs2J5aUohTOl5znfMl51qeuBywV/34uutHFuwsdPTui1/52AQlFUThdeJrtVdtZsXEFpwtP1zvfxq2NtcBFe4/2fymR+y11ZWXkL15MQdRylJoaUKtxmzgRr8cfQ+vZ8JLwQghxtSTZEkIIcVNSabU4dutm2T/p8cepzc+nfN8+S/IVvZe6ggLKtm2jbNs2AOxatfqlvHzPnqgdHGx8B9eGSqUiyCWIIJcgxrUZB1im+cXnxhOTE0NcbhzH845TUlPCngt72HPBUm5fq9LS1tjWmrh19e6Ku4M7x7KPWQtcXCy37FVFlWWKY1fvrpYEK3AogS6BjXZPSl0dRevWkfv+Qury8wFw7NsHn+efxyE8vNGeVwgh/i9JtoQQQghA6+GB69ixuI4di2I2U5WY+Et5+ZhYas6epebsWQqXr0Blb49jz54YIvvjNGAAdiEhN9SaH1d7Vwa0GMCAFgMAMJlNJBUkEZsba51umFORQ0J+Agn5CaxMXAlY1n7VmGus13HQONBK3YrJ3ScztOVQ3B3cGz328v37yX7jTapPW0bS7Fq2xPtvz+E0ZMgN9W8khGgeJNkSQggh/g+VWo2+Qwf0HTrg+eAD1JWWUr5/v7W8fG1mJuXR0ZRHR5Pzxpto/f1wihyAYUAkhr590Tg52foWrimdWkcHzw508OzA9HbTAcsarF9PPTxdeJoacw1GB6Nlg+HAIXT36s6On3YwOmQ0Ol3jbrRcffYsOfMXULbdUvRD7eKC17yHcZ869YZYeyeEaJ4k2RJCCCH+gMbZGZcRI3AZMQJFUahJTbVWOKw4coTai5kUrV1L0dq1oNXi2KWLtby8fdu2qNTXfj2Srfk5+eHn5MfokNEAVJgqyCrPoqVLSzRqSzl9k8nU6HHUFReT9+GHFKxaDbW1oNHgPmUKno/MQ+ve+CNpQgjxeyTZEkIIIf4ElUqFfZs22Ldpg8ec2ZgrK6k4fNiafNWcO0fFkSNUHDlC7rvvovH0xKl/fwwDBmDo3++GTQAcdY6EuIVct+dTTCYKP/+CvA8+oK64GADDoIH4PPcc9q1bX7c4hBDi90iyJYQQQvwFar0ep4EDcRo4EICa9PRfyssfOEBdXh7F69dTvH49qFQ4dOqEU2R/DJED0HfuhEorb8V/hqIolO/eTfabb1Fz5gwAdm1a4/O353EaEGnj6IQQoj55hRdCCCGuIbvAQOymTsV96lSUmhoqjsVQHr2Hsj3RVJ8+TVV8PFXx8eR9+BFqFxcM/fpdKi8fic7Hx9bhN2nVyclkv/Em5Xv3AqBxd8frsUdxu+suSVqFEE2SvDIJIYQQjURlZ4ehT28MfXrj/cwzmLJzLKNe0Xso37cfc3ExpZs2WTfbtQ8Ls5aX13frhloKOwBQW1BA7qJFFH2xFsxm0OkwzpiB54MPoHFxsXV4QgjxmyTZEkIIIa4TnY83bhPvwG3iHZZNlY8ft1Q43BtNVfxxqpOSqE5KouCzJagcHTH07m1JviIjsQsKsnX41525pobCFSvJ+/hjzKWlADjfMhzvZ57BrmVLG0cnhBB/rMmXRyotLeWJJ56gZcuW6PV6+vXrx+HDh63nFUXhxRdfxM/PD71ez/Dhw0lOTq53jYKCAqZPn46Liwtubm7cc889lJWVXe9bEUIIIaxUWi2OXbvi9dijtPriC0L37cX/7QW4jh+PxtMTpaKCsh07yP7Xq6SOGEnKyJFkvfpvSnfuxFxRYevwG5WiKJRs2cKZMWPJmT8fc2kp9u3bERQVRYtFiyTREkI0G01+ZOvee+8lISGBFStW4O/vz8qVKxk+fDgnT54kICCAt956i4ULFxIVFUWrVq345z//yciRIzl58iQODg4ATJ8+nczMTLZs2YLJZGLOnDncf//9rF692sZ3J4QQQlho3d1xve02XG+7DcVspvr06V/Ky8fEYDqfRuH5VRSuWoVKp8OxZw8MkZby8nZt2twwG/ZWnTxJ9htvUnHoEAAaL0+8n3gS1/HjUGk0No5OCCH+nCadbFVWVrJu3TrWr1/PwEtVnl5++WW+//57PvroI1599VXee+89/vGPfzBu3DgAli9fjo+PD99++y1TpkwhMTGRTZs2cfjwYXr06AHAokWLGD16NAsWLMDf399m9yeEEEJciUqtxqFdOxzatcPz/vuoKyuj4sABa/JluniR8n37Kd+3n5y33kLr63upyMYADH37NMt1TKacHHLfe5/ib74BRUFlb49xzmw87r0PjZPB1uEJIcRVadLJVm1tLXV1ddYRqp/p9Xqio6M5e/YsWVlZDB8+3HrO1dWV3r17s3//fqZMmcL+/ftxc3OzJloAw4cPR61Wc/DgQSZMmHDF566urqa6utr695KSEsCyQeP12KTxz/g5nqYWl2j6pO+IhpB+0gTY2+MwaBAOgwbhoSiYzp6jYm80FXv3UXnkCLVZWRR9+RVFX34FGg0OEZ1x7N8fx/6R2Lez3abKDek75qoqipYvp/DTz1AqKwFwunUUHk88gc7fHzNglr53Q5PXGHG1bNl3GvqcTTrZcnZ2pm/fvrz66qu0a9cOHx8f1qxZw/79+2nTpg1ZWVkA+PyfUrk+Pj7Wc1lZWXh7e9c7r9VqMRqN1jZX8vrrr/PKK69cdvynn37C0dHxr95ao9iyZYutQxDNlPQd0RDST5oYDw+4fSyqW0ehP3MWQ9JpHE8nYZ+bS9WxGKqOxVCw6ANqDQYqwkIpDwunIiyUOien6x7qFfuOouAcF4/nxo3oiooAqAwMJHfsGKpatoTYWMuPuGnIa4y4WrboOxUNXDvbpJMtgBUrVjB37lwCAgLQaDR069aNqVOncvTo0UZ93hdeeIGnnnrK+veSkhICAwMZMWIELk1seobJZGLLli3ccsst6HQ6W4cjmhHpO6IhpJ80L6YLF6jYu4+KvXupOHAAbXk5LjGxuMTEAmDfvr1l1CuyPw6dOzfq/lS/1Xeq4uPJe2s+VXFxAGh9fPB44gmcRt9qs1E4YTvyGiOuli37zs+z3v5Ik0+2Wrduza5duygvL6ekpAQ/Pz8mT55MSEgIvr6+AGRnZ+Pn52d9THZ2Nl26dAHA19eXnJycetesra2loKDA+vgrsbe3x97e/rLjOp2uyb4QNOXYRNMmfUc0hPST5kEXHIxjcDBMn2bZVDk21lJePjqa6sREqk+epPrkSQo/+QS1szOGvn2t5eV1v3ovvaYxXeo7psxMct55l5LvvwdApdfjcd+9eMyZg1qvb5TnFs2HvMaIq2WLvtPQ52vyydbPDAYDBoOBwsJCNm/ezFtvvUWrVq3w9fVl27Zt1uSqpKSEgwcP8tBDDwHQt29fioqKOHr0KN27dwdg+/btmM1mevfubavbEUIIIRqdys4OQ69eGHr1wvvppzDl5FC+dx/l0dGUR0dTV1xM6U8/UfrTTwDYh7axFNmI7I9jjx6or/Cl49UwV1SQGxVF/pKlKFVVALhOmIDXE0+g8/H+g0cLIUTz1eSTrc2bN6MoCuHh4aSkpPDss8/Stm1b5syZg0ql4oknnuDf//43oaGh1tLv/v7+jB8/HoB27doxatQo7rvvPj7++GNMJhOPPPIIU6ZMkUqEQgghbio6b2/cJozHbcJ4lLo6qk6coGzPHsr3RFMZH091cgrVySkULF2KysEBx969cLpUXl7XsuWfLi+vmM24HDnC+QVvU5ebC4C+R3d8nn8BfccOjXGLQgjRpDT5ZKu4uJgXXniBjIwMjEYjEydO5LXXXrMO3T333HOUl5dz//33U1RURGRkJJs2bapXwXDVqlU88sgjDBs2DLVazcSJE1m4cKGtbkkIIYSwOZVGg75zZ/SdO+M1bx51RUWU799vLS9fm5tL+a7dlO/aTTagCwz8pbx8716oDb9fjr3iyBGy/vM6vidPUgfoWrTA+9lncR5xyw2zJ5gQQvyRJp9sTZo0iUmTJv3meZVKxb/+9S/+9a9//WYbo9EoGxgLIYQQv0Pj5obLrbficuutKIpCdVIS5Xv2ULYnmopjxzClp1O4eg2Fq9eATodj9+7W5Ms+LNSaQNWkp5Mzf4F1amKdvT3eDz+E5+zZ12xaohBCNBdNPtkSQgghxPWlUqlwCA/HITwcj3vvpa6snIpDB61TDk0ZGVQcOEDFgQMwfwFab28MkZGonQwUrfkcxWQCtRqXiROJaRtO+KRJqKXwgRDiJiTJlhBCCCF+l8bJgPPQoTgPHYqiKJjOn6dsTzRl0XuoOHiI2pwcir/+2tre0K8v3n97Hk1IK+o2bLBh5EIIYVuSbAkhhBCiwVQqFXbBwRiDgzHOuBtzdTUVR45YRrwuXMD1jgk4DR6MSqXCZDLZOlwhhLApSbaEEEIIcdXU9vY49e+PU//+tg5FCCGaHNmmXQghhBBCCCEagSRbQgghhBBCCNEIJNkSQgghhBBCiEYgyZYQQgghhBBCNAJJtoQQQgghhBCiEUiyJYQQQgghhBCNQJItIYQQQgghhGgEkmwJIYQQQgghRCOQZEsIIYQQQgghGoEkW0IIIYQQQgjRCCTZEkIIIYQQQohGIMmWEEIIIYQQQjQCSbaEEEIIIYQQohFIsiWEEEIIIYQQjUCSLSGEEEIIIYRoBJJsCSGEEEIIIUQjkGRLCCGEEEIIIRqBJFtCCCGEEEII0Qi0tg6guVAUBYCSkhIbR3I5k8lERUUFJSUl6HQ6W4cjmhHpO6IhpJ+IqyV9RzSE9BNxtWzZd37OCX7OEX6LJFsNVFpaCkBgYKCNIxFCCCGEEEI0BaWlpbi6uv7meZXyR+mYAMBsNnPx4kWcnZ1RqVS2DqeekpISAgMDSU9Px8XFxdbhiGZE+o5oCOkn4mpJ3xENIf1EXC1b9h1FUSgtLcXf3x+1+rdXZsnIVgOp1WpatGhh6zB+l4uLi7xIiasifUc0hPQTcbWk74iGkH4irpat+s7vjWj9TApkCCGEEEIIIUQjkGRLCCGEEEIIIRqBJFs3AHt7e1566SXs7e1tHYpoZqTviIaQfiKulvQd0RDST8TVag59RwpkCCGEEEIIIUQjkJEtIYQQQgghhGgEkmwJIYQQQgghRCOQZEsIIYQQQgghGoEkW0IIIYQQQgjRCCTZakSvv/46PXv2xNnZGW9vb8aPH8/p06frtamqqmLevHl4eHjg5OTExIkTyc7Otp6Pi4tj6tSpBAYGotfradeuHe+//369a0RHR9O/f388PDzQ6/W0bduWd9999w/jUxSFF198ET8/P/R6PcOHDyc5Oblem6SkJMaNG4enpycuLi5ERkayY8eOv/BbEX/kRug3x44d45ZbbsHNzQ0PDw/uv/9+ysrK/sJvRVxJU+8rX3/9NSNGjMDDwwOVSkVsbOxlbf4oPnHt3Qj95n//+x+DBw/GxcUFlUpFUVHRVf0uxG9r7v2koKCARx99lPDwcPR6PUFBQTz22GMUFxdf/S9FNMj16ju/tnfvXrRaLV26dPnD+BryOea1116jX79+ODo64ubm9qfu/0pPKBrJyJEjlaVLlyoJCQlKbGysMnr0aCUoKEgpKyuztnnwwQeVwMBAZdu2bcqRI0eUPn36KP369bOe/+yzz5THHntM2blzp5KamqqsWLFC0ev1yqJFi6xtjh07pqxevVpJSEhQzp49q6xYsUJxdHRUFi9e/LvxvfHGG4qrq6vy7bffKnFxccrtt9+utGrVSqmsrLS2CQ0NVUaPHq3ExcUpSUlJysMPP6w4OjoqmZmZ1/A3JX6tufebCxcuKO7u7sqDDz6onDp1Sjl06JDSr18/ZeLEidf4NyWael9Zvny58sorryiffPKJAigxMTGXtfmj+MS1dyP0m3fffVd5/fXXlddff10BlMLCwr/8exH1Nfd+cvz4ceWOO+5QvvvuOyUlJUXZtm2bEhoaKu9F18H16js/KywsVEJCQpQRI0YoERERfxhfQz7/vvjii8o777yjPPXUU4qrq+tf+n1IsnUd5eTkKICya9cuRVEUpaioSNHpdMqXX35pbZOYmKgAyv79+3/zOg8//LAyZMiQ332uCRMmKHffffdvnjebzYqvr68yf/5867GioiLF3t5eWbNmjaIoipKbm6sAyu7du61tSkpKFEDZsmXL79+suGaaW79ZvHix4u3trdTV1VnbxMfHK4CSnJz8+zcr/pKm1Fd+7ezZs1f8MHS18Ylrq7n1m1/bsWOHJFvXSXPuJz9bu3atYmdnp5hMpgZdW1wbjd13Jk+erPzjH/9QXnrppT9MthryOebXli5d+peTLZlGeB39PHRtNBoBOHr0KCaTieHDh1vbtG3blqCgIPbv3/+71/n5GlcSExPDvn37GDRo0G+2OXv2LFlZWfWe29XVld69e1uf28PDg/DwcJYvX055eTm1tbUsXrwYb29vunfv3rCbFn9Zc+s31dXV2NnZoVb/8vKi1+sBy3QR0XiaUl9piKuNT1xbza3fCNu4EfpJcXExLi4uaLXaa35t8dsas+8sXbqUM2fO8NJLLzUoloZ8jrnWpLddJ2azmSeeeIL+/fvTsWNHALKysrCzs7tsLqiPjw9ZWVlXvM6+ffv44osv+PHHHy8716JFC3Jzc6mtreXll1/m3nvv/c14fr6+j4/Pbz63SqVi69atjB8/HmdnZ9RqNd7e3mzatAl3d/cG37u4es2x3wwdOpSnnnqK+fPn8/jjj1NeXs7zzz8PQGZmZsNuXPxpTa2vNMTVxCeurebYb8T1dyP0k7y8PF599VXuv//+a3pd8fsas+8kJyfz/PPPs2fPngYn0A35HHOtycjWdTJv3jwSEhL4/PPPr/oaCQkJjBs3jpdeeokRI0Zcdn7Pnj0cOXKEjz/+mPfee481a9YAsGrVKpycnKw/e/bsadDzKYrCvHnz8Pb2Zs+ePRw6dIjx48czduxY+dB8nTTHftOhQweioqJ4++23cXR0xNfXl1atWuHj41NvtEtcW82xrwjbk34jGqK595OSkhJuu+022rdvz8svv3zV9yD+vMbqO3V1dUybNo1XXnmFsLCwKz6uybzG/KVJiKJB5s2bp7Ro0UI5c+ZMvePbtm274lzzoKAg5Z133ql37MSJE4q3t7fy97//vUHP+eqrryphYWGKoljWWSUnJ1t/KioqlNTU1CvOcR44cKDy2GOPKYqiKFu3blXUarVSXFxcr02bNm2U119/vUFxiKvXXPvNr2VlZSmlpaVKWVmZolarlbVr1zYoDvHnNMW+8mu/tabiz8Qnrr3m2m9+TdZsNb7m3k9KSkqUvn37KsOGDatXAEE0vsbsO4WFhQqgaDQa649KpbIe27Zt2zX5HHMt1mxJstWIzGazMm/ePMXf319JSkq67PzPCwS/+uor67FTp05dtkAwISFB8fb2Vp599tkGP/crr7yitGzZ8ndj8/X1VRYsWGA9VlxcXG+B4Hfffaeo1WqltLS03mPDwsKU1157rcGxiD+nufebK/nss88UR0dH+UB0jTXlvvJrf1Qg44/iE9dWc+83vybJVuO5EfpJcXGx0qdPH2XQoEFKeXl5g59f/DXXo+/U1dUpx48fr/fz0EMPKeHh4crx48frVT78v7H9mc8xkmw1cQ899JDi6uqq7Ny5U8nMzLT+/PpbmQcffFAJCgpStm/frhw5ckTp27ev0rdvX+v548ePK15eXsrdd99d7xo5OTnWNh988IHy3XffKUlJSUpSUpLy6aefKs7Ozsr/+3//73fje+ONNxQ3Nzdl/fr1Snx8vDJu3Lh6pS9zc3MVDw8P5Y477lBiY2OV06dPK88884yi0+mU2NjYa/zbEj9r7v1GURRl0aJFytGjR5XTp08rH3zwgaLX65X333//Gv6WhKI0/b6Sn5+vxMTEKD/++KMCKJ9//rkSExNTb+uIP4pPXHs3Qr/JzMxUYmJirGW/d+/ercTExCj5+fnX8Dd1c2vu/aS4uFjp3bu30qlTJyUlJaXe89fW1l7j35b4tevVd/6vhlQjVJSGfY45f/68EhMTo7zyyiuKk5OTEhMTo8TExFw2ANEQkmw1IuCKP0uXLrW2qaysVB5++GHF3d1dcXR0VCZMmFDvDeWll1664jV+/Y3PwoULlQ4dOiiOjo6Ki4uL0rVrV+XDDz+sV3r7Ssxms/LPf/5T8fHxUezt7ZVhw4Ypp0+frtfm8OHDyogRIxSj0ag4Ozsrffr0UTZs2HBNfj/iym6EfjNjxgzFaDQqdnZ2SufOnZXly5dfk9+NqK+p95WlS5de8dovvfRSg+MT196N0G9+6/l/fQ/ir2nu/eTnUc8r/Zw9e/Ya/qbE/3W9+s7/1dBkqyGfY2bNmnXF59+xY8ef/G0oikpRFAUhhBBCCCGEENeUlAYTQgghhBBCiEYgyZYQQgghhBBCNAJJtoQQQgghhBCiEUiyJYQQQgghhBCNQJItIYQQQgghhGgEkmwJIYQQQgghRCOQZEsIIYQQQgghGoEkW0IIIYQQQgjRCCTZEkIIIYQQQohGIMmWEEKIm87s2bNRqVSoVCp0Oh0+Pj7ccsstLFmyBLPZ3ODrLFu2DDc3t8YLVAghRLMmyZYQQoib0qhRo8jMzOTcuXNs3LiRIUOG8PjjjzNmzBhqa2ttHZ4QQogbgCRbQgghbkr29vb4+voSEBBAt27d+Pvf/8769evZuHEjy5YtA+Cdd96hU6dOGAwGAgMDefjhhykrKwNg586dzJkzh+LiYuso2csvvwxAdXU1zzzzDAEBARgMBnr37s3OnTttc6NCCCFsRpItIYQQ4pKhQ4cSERHB119/DYBarWbhwoWcOHGCqKgotm/fznPPPQdAv379eO+993BxcSEzM5PMzEyeeeYZAB555BH279/P559/Tnx8PHfddRejRo0iOTnZZvcmhBDi+lMpiqLYOgghhBDiepo9ezZFRUV8++23l52bMmUK8fHxnDx58rJzX331FQ8++CB5eXmAZc3WE088QVFRkbVNWloaISEhpKWl4e/vbz0+fPhwevXqxX/+859rfj9CCCGaJq2tAxBCCCGaEkVRUKlUAGzdupXXX3+dU6dOUVJSQm1tLVVVVVRUVODo6HjFxx8/fpy6ujrCwsLqHa+ursbDw6PR4xdCCNF0SLIlhBBC/EpiYiKtWrXi3LlzjBkzhoceeojXXnsNo9FIdHQ099xzDzU1Nb+ZbJWVlaHRaDh69CgajabeOScnp+txC0IIIZoISbaEEEKIS7Zv387x48d58sknOXr0KGazmbfffhu12rLEee3atfXa29nZUVdXV+9Y165dqaurIycnhwEDBly32IUQQjQ9kmwJIYS4KVVXV5OVlUVdXR3Z2dls2rSJ119/nTFjxjBz5kwSEhIwmUwsWrSIsWPHsnfvXj7++ON61wgODqasrIxt27YRERGBo6MjYWFhTJ8+nZkzZ/L222/TtWtXcnNz2bZtG507d+a2226z0R0LIYS43qQaoRBCiJvSpk2b8PPzIzg4mFGjRrFjxw4WLlzI+vXr0Wg0RERE8M477/Dmm2/SsWNHVq1axeuvv17vGv369ePBBx9k8uTJeHl58dZbbwGwdOlSZs6cydNPP014eDjjx4/n8OHDBAUF2eJWhRBC2IhUIxRCCCGEEEKIRiAjW0IIIYQQQgjRCCTZEkIIIYQQQohGIMmWEEIIIYQQQjQCSbaEEEIIIYQQohFIsiWEEEIIIYQQjUCSLSGEEEIIIYRoBJJsCSGEEEIIIUQjkGRLCCGEEEIIIRqBJFtCCCGEEEII0Qgk2RJCCCGEEEKIRiDJlhBCCCGEEEI0gv8PY0nqjCakre0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_metrics = pd.DataFrame()\n",
        "test_metrics = pd.DataFrame()\n",
        "train_rets = pd.DataFrame()\n",
        "test_rets = pd.DataFrame()\n",
        "\n",
        "for model_type in ['MLP', 'CNN', 'RNN']:\n",
        "    print(f'Training: {model_type}...')\n",
        "\n",
        "    if model_type == 'MLP':\n",
        "        input_shape = df_trainval.iloc[:, :-asset_num].shape[1]\n",
        "        input_shape = (input_shape,)\n",
        "    elif model_type == 'CNN' or model_type == 'RNN':\n",
        "        # need to reshape for CNNs and RNNs\n",
        "        X_train_full = df_trainval.iloc[:, :-asset_num]\n",
        "        X_train_reshaped = np.reshape(X_train_full.to_numpy(), (X_train_full.shape[0], X_train_full.shape[1], 1))\n",
        "        input_shape = X_train_reshaped.shape[1:]\n",
        "\n",
        "    param_grid = param_grids[f'{model_type.lower()}_param_grid']\n",
        "\n",
        "    # instantiate the portfolio object\n",
        "    portfolio = PortfolioModelTrainer(model_type=model_type,\n",
        "                                      asset_num=asset_num,\n",
        "                                      input_shape=input_shape,\n",
        "                                      param_grid=param_grid,\n",
        "                                      timestamp=timestamp)\n",
        "\n",
        "    # perform grid_search on the dataset\n",
        "    batch = df_trainval.shape[0]\n",
        "    portfolio.grid_search(n_train, n_val, df_trainval, batch)\n",
        "\n",
        "    print(f'Found best params for {model_type}!')\n",
        "    with open(f\"/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/preds/{timestamp}/{portfolio.model_type}/param_mapping.txt\", \"a\") as f:\n",
        "        f.write(f'The best params for {portfolio.model_type} were: {str(portfolio.best_params)}\\n')\n",
        "\n",
        "    print(f'Training optimal model for {model_type}...')\n",
        "\n",
        "    # train optimal\n",
        "    portfolio.train_optimal(df_trainval, batch)\n",
        "\n",
        "    for model_version in ['train', 'test']:\n",
        "        if model_version == 'train':\n",
        "            df = df_trainval\n",
        "            date_index = trainval_date_index\n",
        "            prices = train_prices\n",
        "        elif model_version == 'test':\n",
        "            df = df_test\n",
        "            date_index = test_date_index\n",
        "            prices = test_prices\n",
        "        pred_wts = portfolio.evaluate(df, date_index, ticker_list)\n",
        "        metrics, rets = portfolio.perform_backtest(prices, initial_amount, timestamp, model_version)\n",
        "\n",
        "        if model_version == 'train':\n",
        "            train_metrics = pd.concat([train_metrics, metrics], axis=1)\n",
        "            train_rets = pd.concat([train_rets, rets], axis=1)\n",
        "        elif model_version == 'test':\n",
        "            test_metrics = pd.concat([test_metrics, metrics], axis=1)\n",
        "            test_rets = pd.concat([test_rets, rets], axis=1)\n",
        "\n",
        "        portfolio.save_model(timestamp, model_version)\n",
        "\n",
        "\n",
        "    print(f'Done training {model_type}!!!\\n\\n\\n')\n",
        "\n",
        "\n",
        "# let's capture performance for both train and test samples\n",
        "for model_version in ['train', 'test']:\n",
        "    if model_version == 'train':\n",
        "        date_index = trainval_date_index\n",
        "        prices = train_prices\n",
        "        metrics = train_metrics\n",
        "        rets = train_rets\n",
        "    elif model_version == 'test':\n",
        "        date_index = test_date_index\n",
        "        prices = test_prices\n",
        "        metrics = test_metrics\n",
        "        rets = test_rets\n",
        "\n",
        "    # get benchmark equal-weighted portfolio performance\n",
        "    ew_portfolio = PortfolioModelTrainer(model_type='EW',\n",
        "                                        asset_num=asset_num,\n",
        "                                        input_shape=None,\n",
        "                                        param_grid=None,\n",
        "                                        timestamp=timestamp)\n",
        "    # ew train performance\n",
        "    ew_portfolio.build_benchmark(date_index, ticker_list)\n",
        "    ew_metrics, ew_rets = ew_portfolio.perform_backtest(prices, initial_amount, timestamp, model_version)\n",
        "\n",
        "    metrics = pd.concat([metrics, ew_metrics], axis=1)\n",
        "    rets = pd.concat([rets, ew_rets], axis=1)\n",
        "\n",
        "    # save metrics and returns to disk\n",
        "    metrics.to_csv(f'/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/{timestamp}/{model_version}_metrics.csv')\n",
        "    rets.to_csv(f'/content/drive/My Drive/CapstoneProject/CapstoneModularity/WQU_5457/data/model_data/{timestamp}/{model_version}_rets.csv')\n",
        "\n",
        "    # plot and save wealth index\n",
        "    plot_wealth_index(rets, initial_amount, timestamp, 'NN_' + model_version)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}